<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Kernel Reference" href="functions.html" /><link rel="prev" title="FAQ" href="../faq.html" />

    <!-- Generated with Sphinx 7.2.6 and Furo 2024.01.29 -->
        <title>Runtime Reference - Warp 1.0.2</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=135e06be" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=36a5483c" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=a91381f3" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  --admonition-title-font-size: 100%;
  --admonition-font-size: 100%;
  --color-api-pre-name: #4e9a06;
  --color-api-name: #4e9a06;
  --color-admonition-title--seealso: #ffffff;
  --color-admonition-title-background--seealso: #448aff;
  --color-admonition-title-background--note: #76b900;
  --color-admonition-title--note: #ffffff;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-admonition-title-background--note: #535353;
  --color-admonition-title--note: #ffffff;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-admonition-title-background--note: #535353;
  --color-admonition-title--note: #ffffff;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">Warp 1.0.2</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo only-light" src="../_static/logo-light-mode.png" alt="Light Logo"/>
    <img class="sidebar-logo only-dark" src="../_static/logo-dark-mode.png" alt="Dark Logo"/>
  </div>
  
  <span class="sidebar-brand-text">Warp 1.0.2</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">User's Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basics.html">Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="devices.html">Devices</a></li>
<li class="toctree-l1"><a class="reference internal" href="allocators.html">Allocators</a></li>
<li class="toctree-l1"><a class="reference internal" href="concurrency.html">Concurrency</a></li>
<li class="toctree-l1"><a class="reference internal" href="generics.html">Generics</a></li>
<li class="toctree-l1"><a class="reference internal" href="interoperability.html">Interoperability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../configuration.html">Runtime Settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../debugging.html">Debugging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../limitations.html">Limitations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Core Reference</span></p>
<ul class="current">
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">Runtime Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="functions.html">Kernel Reference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Simulation Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="sim.html">warp.sim</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse.html">warp.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="fem.html">warp.fem</a></li>
<li class="toctree-l1"><a class="reference internal" href="render.html">warp.render</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Project Links</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/NVIDIA/warp">GitHub</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pypi.org/project/warp-lang">PyPI</a></li>
<li class="toctree-l1"><a class="reference external" href="https://discord.com/channels/827959428476174346/953756751977648148">Discord</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="runtime-reference">
<h1>Runtime Reference<a class="headerlink" href="#runtime-reference" title="Link to this heading">#</a></h1>
<p>This section describes the Warp Python runtime API, how to manage memory, launch kernels, and high-level functionality
for dealing with objects such as meshes and volumes. The APIs described in this section are intended to be used at
the <em>Python Scope</em> and run inside the CPython interpreter. For a comprehensive list of functions available at
the <em>Kernel Scope</em>, please see the <a class="reference internal" href="functions.html"><span class="doc">Kernel Reference</span></a> section.</p>
<section id="kernels">
<h2>Kernels<a class="headerlink" href="#kernels" title="Link to this heading">#</a></h2>
<p>Kernels are launched with the <a class="reference internal" href="#warp.launch" title="warp.launch"><code class="xref py py-func docutils literal notranslate"><span class="pre">wp.launch()</span></code></a> function on a specific device (CPU/GPU):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">simple_kernel</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Kernels may be launched with multi-dimensional grid bounds. In this case threads are not assigned a single index,
but a coordinate in an n-dimensional grid, e.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">complex_kernel</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<p>Launches a 3D grid of threads with dimension 128 x 128 x 3. To retrieve the 3D index for each thread use the following syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">k</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">tid</span><span class="p">()</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Currently kernels launched on CPU devices will be executed in serial.
Kernels launched on CUDA devices will be launched in parallel with a fixed block-size.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Note that all the kernel inputs must live on the target device, or a runtime exception will be raised.</p>
</div>
<dl class="py function">
<dt class="sig sig-object py" id="warp.launch">
<span class="sig-prename descclassname"><span class="pre">warp.</span></span><span class="sig-name descname"><span class="pre">launch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">adj_inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">adj_outputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">adjoint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">record_tape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">record_cmd</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_blocks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.launch" title="Link to this definition">#</a></dt>
<dd><p>Launch a Warp kernel on the target device</p>
<p>Kernel launches are asynchronous with respect to the calling Python thread.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel</strong> – The name of a Warp kernel function, decorated with the <code class="docutils literal notranslate"><span class="pre">&#64;wp.kernel</span></code> decorator</p></li>
<li><p><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.12)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>]</em>) – The number of threads to launch the kernel, can be an integer, or a Tuple of ints with max of 4 dimensions</p></li>
<li><p><strong>inputs</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Sequence" title="(in Python v3.12)"><em>Sequence</em></a>) – The input parameters to the kernel (optional)</p></li>
<li><p><strong>outputs</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Sequence" title="(in Python v3.12)"><em>Sequence</em></a>) – The output parameters (optional)</p></li>
<li><p><strong>adj_inputs</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Sequence" title="(in Python v3.12)"><em>Sequence</em></a>) – The adjoint inputs (optional)</p></li>
<li><p><strong>adj_outputs</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Sequence" title="(in Python v3.12)"><em>Sequence</em></a>) – The adjoint outputs (optional)</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="devices.html#warp.context.Device" title="warp.context.Device"><em>Device</em></a><em> | </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em> | </em><em>None</em>) – The device to launch on (optional)</p></li>
<li><p><strong>stream</strong> (<em>Stream</em><em> | </em><em>None</em>) – The stream to launch on (optional)</p></li>
<li><p><strong>adjoint</strong> – Whether to run forward or backward pass (typically use False)</p></li>
<li><p><strong>record_tape</strong> – When true the launch will be recorded the global wp.Tape() object when present</p></li>
<li><p><strong>record_cmd</strong> – When True the launch will be returned as a <code class="docutils literal notranslate"><span class="pre">Launch</span></code> command object, the launch will not occur until the user calls <code class="docutils literal notranslate"><span class="pre">cmd.launch()</span></code></p></li>
<li><p><strong>max_blocks</strong> – The maximum number of CUDA thread blocks to use. Only has an effect for CUDA kernel launches.
If negative or zero, the maximum hardware value will be used.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<section id="large-kernel-launches">
<h3>Large Kernel Launches<a class="headerlink" href="#large-kernel-launches" title="Link to this heading">#</a></h3>
<p>A limitation of Warp is that each dimension of the grid used to launch a kernel must be representable as a 32-bit
signed integer. Therefore, no single dimension of a grid should exceed <span class="math notranslate nohighlight">\(2^{31}-1\)</span>.</p>
<p>Warp also currently uses a fixed block size of 256 (CUDA) threads per block.
By default, Warp will try to process one element from the Warp grid in one CUDA thread.
This is not always possible for kernels launched with multi-dimensional grid bounds, as there are
<a class="reference external" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#features-and-technical-specifications-technical-specifications-per-compute-capability">hardware limitations</a>
on CUDA block dimensions.</p>
<p>Warp will automatically resort to using
<a class="reference external" href="https://developer.nvidia.com/blog/cuda-pro-tip-write-flexible-kernels-grid-stride-loops/">grid-stride loops</a> when
it is not possible for a CUDA thread to process only one element from the Warp grid
When this happens, some CUDA threads may process more than one element from the Warp grid.
Users can also set the <code class="docutils literal notranslate"><span class="pre">max_blocks</span></code> parameter to fine-tune the grid-striding behavior of kernels, even for kernels that are otherwise
able to process one Warp-grid element per CUDA thread.</p>
</section>
<section id="runtime-kernel-specialization">
<h3>Runtime Kernel Specialization<a class="headerlink" href="#runtime-kernel-specialization" title="Link to this heading">#</a></h3>
<p>It is often desirable to specialize kernels for different types, constants, or functions.
We can achieve this through the use of runtime kernel specialization using Python closures.</p>
<p>For example, we might require a variety of kernels that execute particular functions for each item in an array.
We might also want this function call to be valid for a variety of data types. Making use of closure and generics, we can generate
these kernels using a single kernel definition:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_kernel</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">closure_kernel_fn</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),</span> <span class="n">out</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)):</span>
        <span class="n">tid</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">tid</span><span class="p">()</span>
        <span class="n">out</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">tid</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">wp</span><span class="o">.</span><span class="n">Kernel</span><span class="p">(</span><span class="n">closure_kernel_fn</span><span class="p">)</span>
</pre></div>
</div>
<p>In practice, we might use our kernel generator, <code class="docutils literal notranslate"><span class="pre">make_kernel()</span></code> as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@wp</span><span class="o">.</span><span class="n">func</span>
<span class="k">def</span> <span class="nf">sqr</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span>

<span class="nd">@wp</span><span class="o">.</span><span class="n">func</span>
<span class="k">def</span> <span class="nf">cube</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">sqr</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span>

<span class="n">sqr_float</span> <span class="o">=</span> <span class="n">make_kernel</span><span class="p">(</span><span class="n">sqr</span><span class="p">,</span> <span class="n">wp</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">cube_double</span> <span class="o">=</span> <span class="n">make_kernel</span><span class="p">(</span><span class="n">cube</span><span class="p">,</span> <span class="n">wp</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

<span class="n">arr</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]</span>
<span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>

<span class="n">data_float</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">data_double</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="n">out_float</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">out_double</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">sqr_float</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">data_float</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">out_float</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">cube_double</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">data_double</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">out_double</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p>We can specialize kernel definitions over warp constants similarly. The following generates kernels that add a specified constant
to a generic-typed array value:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_add_kernel</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">constant</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">closure_kernel_fn</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">Any</span><span class="p">),</span> <span class="n">out</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">Any</span><span class="p">)):</span>
        <span class="n">tid</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">tid</span><span class="p">()</span>
        <span class="n">out</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+</span> <span class="n">constant</span>

    <span class="k">return</span> <span class="n">wp</span><span class="o">.</span><span class="n">Kernel</span><span class="p">(</span><span class="n">closure_kernel_fn</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">key</span><span class="p">)</span>

<span class="n">add_ones_int</span> <span class="o">=</span> <span class="n">make_add_kernel</span><span class="p">(</span><span class="s2">&quot;add_one&quot;</span><span class="p">,</span> <span class="n">wp</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">add_ones_vec3</span> <span class="o">=</span> <span class="n">make_add_kernel</span><span class="p">(</span><span class="s2">&quot;add_ones_vec3&quot;</span><span class="p">,</span> <span class="n">wp</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)))</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">)</span>

<span class="n">a_out</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="n">b_out</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>

<span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">add_ones_int</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">a</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">a_out</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">add_ones_vec3</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">b</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">b</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">b_out</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="arrays">
<h2>Arrays<a class="headerlink" href="#arrays" title="Link to this heading">#</a></h2>
<p>Arrays are the fundamental memory abstraction in Warp; they are created through the following global constructors:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">wp</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="n">wp</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Arrays can also be constructed directly from <code class="docutils literal notranslate"><span class="pre">numpy</span></code> ndarrays as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1024</span><span class="p">)</span>

<span class="c1"># copy to Warp owned array</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

<span class="c1"># return a Warp array wrapper around the NumPy data (zero-copy)</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

<span class="c1"># return a Warp copy of the array data on the GPU</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Note that for multi-dimensional data the <code class="docutils literal notranslate"><span class="pre">dtype</span></code> parameter must be specified explicitly, e.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="c1"># initialize as an array of vec3 objects</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>If the shapes are incompatible, an error will be raised.</p>
<p>Arrays can be moved between devices using the <code class="docutils literal notranslate"><span class="pre">array.to()</span></code> method:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">host_array</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

<span class="c1"># allocate and copy to GPU</span>
<span class="n">device_array</span> <span class="o">=</span> <span class="n">host_array</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Additionally, arrays can be copied directly between memory spaces:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">src_array</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">dest_array</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">host_array</span><span class="p">)</span>

<span class="c1"># copy from source CPU buffer to GPU</span>
<span class="n">wp</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">dest_array</span><span class="p">,</span> <span class="n">src_array</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="warp.array">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">warp.</span></span><span class="sig-name descname"><span class="pre">array</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">typing.Any</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ptr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">capacity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pinned</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">owner</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deleter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ndim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.array" title="Link to this definition">#</a></dt>
<dd><p>Constructs a new Warp array object</p>
<p>When the <code class="docutils literal notranslate"><span class="pre">data</span></code> argument is a valid list, tuple, or ndarray the array will be constructed from this object’s data.
For objects that are not stored sequentially in memory (e.g.: a list), then the data will first
be flattened before being transferred to the memory space given by device.</p>
<p>The second construction path occurs when the <code class="docutils literal notranslate"><span class="pre">ptr</span></code> argument is a non-zero uint64 value representing the
start address in memory where existing array data resides, e.g.: from an external or C-library. The memory
allocation should reside on the same device given by the device argument, and the user should set the length
and dtype parameter appropriately.</p>
<p>If neither <code class="docutils literal notranslate"><span class="pre">data</span></code> nor <code class="docutils literal notranslate"><span class="pre">ptr</span></code> are specified, the <code class="docutils literal notranslate"><span class="pre">shape</span></code> or <code class="docutils literal notranslate"><span class="pre">length</span></code> arguments are checked next.
This construction path can be used to create new uninitialized arrays, but users are encouraged to call
<code class="docutils literal notranslate"><span class="pre">wp.empty()</span></code>, <code class="docutils literal notranslate"><span class="pre">wp.zeros()</span></code>, or <code class="docutils literal notranslate"><span class="pre">wp.full()</span></code> instead to create new arrays.</p>
<p>If none of the above arguments are specified, a simple type annotation is constructed.  This is used when annotating
kernel arguments or struct members (e.g.,``arr: wp.array(dtype=float)``).  In this case, only <code class="docutils literal notranslate"><span class="pre">dtype</span></code> and <code class="docutils literal notranslate"><span class="pre">ndim</span></code>
are taken into account and no memory is allocated for the array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)"><em>tuple</em></a><em>, </em><em>ndarray</em><em>]</em>) – </p></li>
<li><p><strong>dtype</strong> (<em>Union</em>) – One of the built-in types, e.g.: <code class="xref py py-class docutils literal notranslate"><span class="pre">warp.mat33</span></code>, if dtype is Any and data an ndarray then it will be inferred from the array data type</p></li>
<li><p><strong>shape</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)"><em>tuple</em></a>) – Dimensions of the array</p></li>
<li><p><strong>strides</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)"><em>tuple</em></a>) – Number of bytes in each dimension between successive elements of the array</p></li>
<li><p><strong>length</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – Number of elements of the data type (deprecated, users should use <cite>shape</cite> argument)</p></li>
<li><p><strong>ptr</strong> (<a class="reference internal" href="functions.html#warp.uint64" title="warp.uint64"><em>uint64</em></a>) – Address of an external memory address to alias (data should be None)</p></li>
<li><p><strong>capacity</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – Maximum size in bytes of the ptr allocation (data should be None)</p></li>
<li><p><strong>device</strong> (<em>Devicelike</em>) – Device the array lives on</p></li>
<li><p><strong>copy</strong> (<a class="reference internal" href="functions.html#warp.bool" title="warp.bool"><em>bool</em></a>) – Whether the incoming data will be copied or aliased, this is only possible when the incoming <cite>data</cite> already lives on the device specified and types match</p></li>
<li><p><strong>owner</strong> (<a class="reference internal" href="functions.html#warp.bool" title="warp.bool"><em>bool</em></a>) – Should the array object try to deallocate memory when it is deleted (deprecated, pass <cite>deleter</cite> if you wish to transfer ownership to Warp)</p></li>
<li><p><strong>deleter</strong> (<em>Callable</em>) – Function to be called when deallocating the array, taking two arguments, pointer and size</p></li>
<li><p><strong>requires_grad</strong> (<a class="reference internal" href="functions.html#warp.bool" title="warp.bool"><em>bool</em></a>) – Whether or not gradients will be tracked for this array, see <a class="reference internal" href="#warp.Tape" title="warp.Tape"><code class="xref py py-class docutils literal notranslate"><span class="pre">warp.Tape</span></code></a> for details</p></li>
<li><p><strong>grad</strong> (<a class="reference internal" href="#warp.array" title="warp.array"><em>array</em></a>) – The gradient array to use</p></li>
<li><p><strong>pinned</strong> (<a class="reference internal" href="functions.html#warp.bool" title="warp.bool"><em>bool</em></a>) – Whether to allocate pinned host memory, which allows asynchronous host-device transfers (only applicable with device=”cpu”)</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="warp.array.grad">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">grad</span></span><a class="headerlink" href="#warp.array.grad" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="warp.array.requires_grad">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">requires_grad</span></span><a class="headerlink" href="#warp.array.requires_grad" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="warp.array.zero_">
<span class="sig-name descname"><span class="pre">zero_</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#warp.array.zero_" title="Link to this definition">#</a></dt>
<dd><p>Zeroes-out the array entries.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="warp.array.fill_">
<span class="sig-name descname"><span class="pre">fill_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.array.fill_" title="Link to this definition">#</a></dt>
<dd><p>Set all array entries to <cite>value</cite></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>value</strong> – The value to set every array entry to. Must be convertible to the array’s <code class="docutils literal notranslate"><span class="pre">dtype</span></code>.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.12)"><strong>ValueError</strong></a> – If <cite>value</cite> cannot be converted to the array’s <code class="docutils literal notranslate"><span class="pre">dtype</span></code>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p><code class="docutils literal notranslate"><span class="pre">fill_()</span></code> can take lists or other sequences when filling arrays of vectors or matrices.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">arr</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">mat22</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">arr</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="go">array([[[0., 0.],</span>
<span class="go">        [0., 0.]],</span>

<span class="go">       [[0., 0.],</span>
<span class="go">        [0., 0.]]], dtype=float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">arr</span><span class="o">.</span><span class="n">fill_</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">arr</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="go">array([[[1., 2.],</span>
<span class="go">        [3., 4.]],</span>

<span class="go">       [[1., 2.],</span>
<span class="go">        [3., 4.]]], dtype=float32)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="warp.array.assign">
<span class="sig-name descname"><span class="pre">assign</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">src</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.array.assign" title="Link to this definition">#</a></dt>
<dd><p>Wraps <code class="docutils literal notranslate"><span class="pre">src</span></code> in an <a class="reference internal" href="#warp.array" title="warp.array"><code class="xref py py-class docutils literal notranslate"><span class="pre">warp.array</span></code></a> if it is not already one and copies the contents to <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="warp.array.numpy">
<span class="sig-name descname"><span class="pre">numpy</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#warp.array.numpy" title="Link to this definition">#</a></dt>
<dd><p>Converts the array to a <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.26)"><code class="xref py py-class docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a> (aliasing memory through the array interface protocol)
If the array is on the GPU, a synchronous device-to-host copy (on the CUDA default stream) will be
automatically performed to ensure that any outstanding work is completed.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="warp.array.cptr">
<span class="sig-name descname"><span class="pre">cptr</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#warp.array.cptr" title="Link to this definition">#</a></dt>
<dd><p>Return a ctypes cast of the array address.</p>
<p>Notes:</p>
<ol class="arabic simple">
<li><p>Only CPU arrays support this method.</p></li>
<li><p>The array must be contiguous.</p></li>
<li><p>Accesses to this object are <strong>not</strong> bounds checked.</p></li>
<li><p>For <code class="docutils literal notranslate"><span class="pre">float16</span></code> types, a pointer to the internal <code class="docutils literal notranslate"><span class="pre">uint16</span></code> representation is returned.</p></li>
</ol>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="warp.array.list">
<span class="sig-name descname"><span class="pre">list</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#warp.array.list" title="Link to this definition">#</a></dt>
<dd><p>Returns a flattened list of items in the array as a Python list.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="warp.array.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.array.to" title="Link to this definition">#</a></dt>
<dd><p>Returns a Warp array with this array’s data moved to the specified device, no-op if already on device.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="warp.array.flatten">
<span class="sig-name descname"><span class="pre">flatten</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#warp.array.flatten" title="Link to this definition">#</a></dt>
<dd><p>Returns a zero-copy view of the array collapsed to 1-D. Only supported for contiguous arrays.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="warp.array.reshape">
<span class="sig-name descname"><span class="pre">reshape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.array.reshape" title="Link to this definition">#</a></dt>
<dd><p>Returns a reshaped array. Only supported for contiguous arrays.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>shape</strong> – An int or tuple of ints specifying the shape of the returned array.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="warp.array.view">
<span class="sig-name descname"><span class="pre">view</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.array.view" title="Link to this definition">#</a></dt>
<dd><p>Returns a zero-copy view of this array’s memory with a different data type.
<code class="docutils literal notranslate"><span class="pre">dtype</span></code> must have the same byte size of the array’s native <code class="docutils literal notranslate"><span class="pre">dtype</span></code>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="warp.array.contiguous">
<span class="sig-name descname"><span class="pre">contiguous</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#warp.array.contiguous" title="Link to this definition">#</a></dt>
<dd><p>Returns a contiguous array with this array’s data. No-op if array is already contiguous.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="warp.array.transpose">
<span class="sig-name descname"><span class="pre">transpose</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">axes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.array.transpose" title="Link to this definition">#</a></dt>
<dd><p>Returns an zero-copy view of the array with axes transposed.</p>
<p>Note: The transpose operation will return an array with a non-contiguous access pattern.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>axes</strong> (<em>optional</em>) – Specifies the how the axes are permuted. If not specified, the axes order will be reversed.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<section id="multi-dimensional-arrays">
<h3>Multi-dimensional Arrays<a class="headerlink" href="#multi-dimensional-arrays" title="Link to this heading">#</a></h3>
<p>Multi-dimensional arrays can be constructed by passing a tuple of sizes for each dimension, e.g.: the following constructs a 2d array of size 1024x16:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>When passing multi-dimensional arrays to kernels users must specify the expected array dimension inside the kernel signature,
e.g. to pass a 2d array to a kernel the number of dims is specified using the <code class="docutils literal notranslate"><span class="pre">ndim=2</span></code> parameter:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@wp</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="nb">input</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">ndim</span><span class="o">=</span><span class="mi">2</span><span class="p">)):</span>
</pre></div>
</div>
<p>Type-hint helpers are provided for common array sizes, e.g.: <code class="docutils literal notranslate"><span class="pre">array2d()</span></code>, <code class="docutils literal notranslate"><span class="pre">array3d()</span></code>, which are equivalent to calling <code class="docutils literal notranslate"><span class="pre">array(...,</span> <span class="pre">ndim=2)`</span></code>, etc. To index a multi-dimensional array use a the following kernel syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># returns a float from the 2d array</span>
<span class="n">value</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span>
</pre></div>
</div>
<p>To create an array slice use the following syntax, where the number of indices is less than the array dimensions:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># returns an 1d array slice representing a row of the 2d array</span>
<span class="n">row</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</pre></div>
</div>
<p>Slice operators can be concatenated, e.g.: <code class="docutils literal notranslate"><span class="pre">s</span> <span class="pre">=</span> <span class="pre">array[i][j][k]</span></code>. Slices can be passed to <code class="docutils literal notranslate"><span class="pre">wp.func</span></code> user functions provided
the function also declares the expected array dimension. Currently only single-index slicing is supported.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Currently Warp limits arrays to 4 dimensions maximum. This is in addition to the contained datatype, which may be 1-2 dimensional for vector and matrix types such as <code class="docutils literal notranslate"><span class="pre">vec3</span></code>, and <code class="docutils literal notranslate"><span class="pre">mat33</span></code>.</p>
</div>
<p>The following construction methods are provided for allocating zero-initialized and empty (non-initialized) arrays:</p>
<dl class="py function">
<dt class="sig sig-object py" id="warp.zeros">
<span class="sig-prename descclassname"><span class="pre">warp.</span></span><span class="sig-name descname"><span class="pre">zeros</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shape=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype=&lt;class</span> <span class="pre">'float'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pinned=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">**kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.zeros" title="Link to this definition">#</a></dt>
<dd><p>Return a zero-initialized array</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.12)"><em>Tuple</em></a><em> | </em><em>None</em>) – Array dimensions</p></li>
<li><p><strong>dtype</strong> – Type of each element, e.g.: warp.vec3, warp.mat33, etc</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="devices.html#warp.context.Device" title="warp.context.Device"><em>Device</em></a><em> | </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em> | </em><em>None</em>) – Device that array will live on</p></li>
<li><p><strong>requires_grad</strong> (<a class="reference internal" href="functions.html#warp.bool" title="warp.bool"><em>bool</em></a>) – Whether the array will be tracked for back propagation</p></li>
<li><p><strong>pinned</strong> (<a class="reference internal" href="functions.html#warp.bool" title="warp.bool"><em>bool</em></a>) – Whether the array uses pinned host memory (only applicable to CPU arrays)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A warp.array object representing the allocation</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#warp.array" title="warp.types.array"><em>array</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="warp.zeros_like">
<span class="sig-prename descclassname"><span class="pre">warp.</span></span><span class="sig-name descname"><span class="pre">zeros_like</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">src</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pinned</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.zeros_like" title="Link to this definition">#</a></dt>
<dd><p>Return a zero-initialized array with the same type and dimension of another array</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>src</strong> (<a class="reference internal" href="#warp.array" title="warp.types.array"><em>array</em></a>) – The template array to use for shape, data type, and device</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="devices.html#warp.context.Device" title="warp.context.Device"><em>Device</em></a><em> | </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em> | </em><em>None</em>) – The device where the new array will be created (defaults to src.device)</p></li>
<li><p><strong>requires_grad</strong> (<a class="reference internal" href="functions.html#warp.bool" title="warp.bool"><em>bool</em></a><em> | </em><em>None</em>) – Whether the array will be tracked for back propagation</p></li>
<li><p><strong>pinned</strong> (<a class="reference internal" href="functions.html#warp.bool" title="warp.bool"><em>bool</em></a><em> | </em><em>None</em>) – Whether the array uses pinned host memory (only applicable to CPU arrays)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A warp.array object representing the allocation</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#warp.array" title="warp.types.array"><em>array</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="warp.full">
<span class="sig-prename descclassname"><span class="pre">warp.</span></span><span class="sig-name descname"><span class="pre">full</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">typing.Any</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pinned</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.full" title="Link to this definition">#</a></dt>
<dd><p>Return an array with all elements initialized to the given value</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.12)"><em>Tuple</em></a><em> | </em><em>None</em>) – Array dimensions</p></li>
<li><p><strong>value</strong> – Element value</p></li>
<li><p><strong>dtype</strong> – Type of each element, e.g.: float, warp.vec3, warp.mat33, etc</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="devices.html#warp.context.Device" title="warp.context.Device"><em>Device</em></a><em> | </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em> | </em><em>None</em>) – Device that array will live on</p></li>
<li><p><strong>requires_grad</strong> (<a class="reference internal" href="functions.html#warp.bool" title="warp.bool"><em>bool</em></a>) – Whether the array will be tracked for back propagation</p></li>
<li><p><strong>pinned</strong> (<a class="reference internal" href="functions.html#warp.bool" title="warp.bool"><em>bool</em></a>) – Whether the array uses pinned host memory (only applicable to CPU arrays)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A warp.array object representing the allocation</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#warp.array" title="warp.types.array"><em>array</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="warp.full_like">
<span class="sig-prename descclassname"><span class="pre">warp.</span></span><span class="sig-name descname"><span class="pre">full_like</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">src</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pinned</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.full_like" title="Link to this definition">#</a></dt>
<dd><p>Return an array with all elements initialized to the given value with the same type and dimension of another array</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>src</strong> (<a class="reference internal" href="#warp.array" title="warp.types.array"><em>array</em></a>) – The template array to use for shape, data type, and device</p></li>
<li><p><strong>value</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.12)"><em>Any</em></a>) – Element value</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="devices.html#warp.context.Device" title="warp.context.Device"><em>Device</em></a><em> | </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em> | </em><em>None</em>) – The device where the new array will be created (defaults to src.device)</p></li>
<li><p><strong>requires_grad</strong> (<a class="reference internal" href="functions.html#warp.bool" title="warp.bool"><em>bool</em></a><em> | </em><em>None</em>) – Whether the array will be tracked for back propagation</p></li>
<li><p><strong>pinned</strong> (<a class="reference internal" href="functions.html#warp.bool" title="warp.bool"><em>bool</em></a><em> | </em><em>None</em>) – Whether the array uses pinned host memory (only applicable to CPU arrays)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A warp.array object representing the allocation</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#warp.array" title="warp.types.array"><em>array</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="warp.empty">
<span class="sig-prename descclassname"><span class="pre">warp.</span></span><span class="sig-name descname"><span class="pre">empty</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shape=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype=&lt;class</span> <span class="pre">'float'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pinned=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">**kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.empty" title="Link to this definition">#</a></dt>
<dd><p>Returns an uninitialized array</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.12)"><em>Tuple</em></a><em> | </em><em>None</em>) – Array dimensions</p></li>
<li><p><strong>dtype</strong> – Type of each element, e.g.: <cite>warp.vec3</cite>, <cite>warp.mat33</cite>, etc</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="devices.html#warp.context.Device" title="warp.context.Device"><em>Device</em></a><em> | </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em> | </em><em>None</em>) – Device that array will live on</p></li>
<li><p><strong>requires_grad</strong> (<a class="reference internal" href="functions.html#warp.bool" title="warp.bool"><em>bool</em></a>) – Whether the array will be tracked for back propagation</p></li>
<li><p><strong>pinned</strong> (<a class="reference internal" href="functions.html#warp.bool" title="warp.bool"><em>bool</em></a>) – Whether the array uses pinned host memory (only applicable to CPU arrays)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A warp.array object representing the allocation</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#warp.array" title="warp.types.array"><em>array</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="warp.empty_like">
<span class="sig-prename descclassname"><span class="pre">warp.</span></span><span class="sig-name descname"><span class="pre">empty_like</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">src</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pinned</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.empty_like" title="Link to this definition">#</a></dt>
<dd><p>Return an uninitialized array with the same type and dimension of another array</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>src</strong> (<a class="reference internal" href="#warp.array" title="warp.types.array"><em>array</em></a>) – The template array to use for shape, data type, and device</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="devices.html#warp.context.Device" title="warp.context.Device"><em>Device</em></a><em> | </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em> | </em><em>None</em>) – The device where the new array will be created (defaults to src.device)</p></li>
<li><p><strong>requires_grad</strong> (<a class="reference internal" href="functions.html#warp.bool" title="warp.bool"><em>bool</em></a><em> | </em><em>None</em>) – Whether the array will be tracked for back propagation</p></li>
<li><p><strong>pinned</strong> (<a class="reference internal" href="functions.html#warp.bool" title="warp.bool"><em>bool</em></a><em> | </em><em>None</em>) – Whether the array uses pinned host memory (only applicable to CPU arrays)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A warp.array object representing the allocation</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#warp.array" title="warp.types.array"><em>array</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="warp.copy">
<span class="sig-prename descclassname"><span class="pre">warp.</span></span><span class="sig-name descname"><span class="pre">copy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dest</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">src</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dest_offset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">src_offset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">count</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.copy" title="Link to this definition">#</a></dt>
<dd><p>Copy array contents from <cite>src</cite> to <cite>dest</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dest</strong> (<a class="reference internal" href="#warp.array" title="warp.types.array"><em>array</em></a>) – Destination array, must be at least as big as source buffer</p></li>
<li><p><strong>src</strong> (<a class="reference internal" href="#warp.array" title="warp.types.array"><em>array</em></a>) – Source array</p></li>
<li><p><strong>dest_offset</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – Element offset in the destination array</p></li>
<li><p><strong>src_offset</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – Element offset in the source array</p></li>
<li><p><strong>count</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – Number of array elements to copy (will copy all elements if set to 0)</p></li>
<li><p><strong>stream</strong> (<em>Stream</em><em> | </em><em>None</em>) – The stream on which to perform the copy (optional)</p></li>
</ul>
</dd>
</dl>
<p>The stream, if specified, can be from any device.  If the stream is omitted, then Warp selects a stream based on the following rules:
(1) If the destination array is on a CUDA device, use the current stream on the destination device.
(2) Otherwise, if the source array is on a CUDA device, use the current stream on the source device.</p>
<p>If neither source nor destination are on a CUDA device, no stream is used for the copy.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="warp.clone">
<span class="sig-prename descclassname"><span class="pre">warp.</span></span><span class="sig-name descname"><span class="pre">clone</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">src</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pinned</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.clone" title="Link to this definition">#</a></dt>
<dd><p>Clone an existing array, allocates a copy of the src memory</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>src</strong> (<a class="reference internal" href="#warp.array" title="warp.types.array"><em>array</em></a>) – The source array to copy</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="devices.html#warp.context.Device" title="warp.context.Device"><em>Device</em></a><em> | </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em> | </em><em>None</em>) – The device where the new array will be created (defaults to src.device)</p></li>
<li><p><strong>requires_grad</strong> (<a class="reference internal" href="functions.html#warp.bool" title="warp.bool"><em>bool</em></a><em> | </em><em>None</em>) – Whether the array will be tracked for back propagation</p></li>
<li><p><strong>pinned</strong> (<a class="reference internal" href="functions.html#warp.bool" title="warp.bool"><em>bool</em></a><em> | </em><em>None</em>) – Whether the array uses pinned host memory (only applicable to CPU arrays)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A warp.array object representing the allocation</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#warp.array" title="warp.types.array"><em>array</em></a></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="matrix-multiplication">
<h3>Matrix Multiplication<a class="headerlink" href="#matrix-multiplication" title="Link to this heading">#</a></h3>
<p>Warp 2D array multiplication is built on NVIDIA’s <a class="reference external" href="https://github.com/NVIDIA/cutlass">CUTLASS</a> library,
which enables fast matrix multiplication of large arrays on the GPU.</p>
<p>If no GPU is detected, matrix multiplication falls back to Numpy’s implementation on the CPU.</p>
<p>Matrix multiplication is fully differentiable, and can be recorded on the tape like so:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tape</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Tape</span><span class="p">()</span>
<span class="k">with</span> <span class="n">tape</span><span class="p">:</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">loss_kernel</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">),</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">D</span><span class="p">,</span> <span class="n">loss</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="n">tape</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">)</span>
<span class="n">A_grad</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
</div>
<p>Using the <code class="docutils literal notranslate"><span class="pre">&#64;</span></code> operator (<code class="docutils literal notranslate"><span class="pre">D</span> <span class="pre">=</span> <span class="pre">A</span> <span class="pre">&#64;</span> <span class="pre">B</span></code>) will default to the same CUTLASS algorithm used in <code class="docutils literal notranslate"><span class="pre">wp.matmul</span></code>.</p>
<dl class="py function">
<dt class="sig sig-object py" id="warp.matmul">
<span class="sig-prename descclassname"><span class="pre">warp.</span></span><span class="sig-name descname"><span class="pre">matmul</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allow_tf32x3_arith</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.matmul" title="Link to this definition">#</a></dt>
<dd><p>Computes a generic matrix-matrix multiplication (GEMM) of the form: <cite>d = alpha * (a &#64; b) + beta * c</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>array2d</em>) – two-dimensional array containing matrix A</p></li>
<li><p><strong>b</strong> (<em>array2d</em>) – two-dimensional array containing matrix B</p></li>
<li><p><strong>c</strong> (<em>array2d</em>) – two-dimensional array containing matrix C</p></li>
<li><p><strong>d</strong> (<em>array2d</em>) – two-dimensional array to which output D is written</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a>) – parameter alpha of GEMM</p></li>
<li><p><strong>beta</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a>) – parameter beta of GEMM</p></li>
<li><p><strong>allow_tf32x3_arith</strong> (<a class="reference internal" href="functions.html#warp.bool" title="warp.bool"><em>bool</em></a>) – whether to use CUTLASS’s 3xTF32 GEMMs, which enable accuracy similar to FP32
while using Tensor Cores</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
</section>
<section id="data-types">
<h2>Data Types<a class="headerlink" href="#data-types" title="Link to this heading">#</a></h2>
<section id="scalar-types">
<h3>Scalar Types<a class="headerlink" href="#scalar-types" title="Link to this heading">#</a></h3>
<p>The following scalar storage types are supported for array structures:</p>
<div class="table-wrapper docutils container">
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p>bool</p></td>
<td><p>boolean</p></td>
</tr>
<tr class="row-even"><td><p>int8</p></td>
<td><p>signed byte</p></td>
</tr>
<tr class="row-odd"><td><p>uint8</p></td>
<td><p>unsigned byte</p></td>
</tr>
<tr class="row-even"><td><p>int16</p></td>
<td><p>signed short</p></td>
</tr>
<tr class="row-odd"><td><p>uint16</p></td>
<td><p>unsigned short</p></td>
</tr>
<tr class="row-even"><td><p>int32</p></td>
<td><p>signed integer</p></td>
</tr>
<tr class="row-odd"><td><p>uint32</p></td>
<td><p>unsigned integer</p></td>
</tr>
<tr class="row-even"><td><p>int64</p></td>
<td><p>signed long integer</p></td>
</tr>
<tr class="row-odd"><td><p>uint64</p></td>
<td><p>unsigned long integer</p></td>
</tr>
<tr class="row-even"><td><p>float16</p></td>
<td><p>half-precision float</p></td>
</tr>
<tr class="row-odd"><td><p>float32</p></td>
<td><p>single-precision float</p></td>
</tr>
<tr class="row-even"><td><p>float64</p></td>
<td><p>double-precision float</p></td>
</tr>
</tbody>
</table>
</div>
<p>Warp supports <code class="docutils literal notranslate"><span class="pre">float</span></code> and <code class="docutils literal notranslate"><span class="pre">int</span></code> as aliases for <code class="docutils literal notranslate"><span class="pre">wp.float32</span></code> and <code class="docutils literal notranslate"><span class="pre">wp.int32</span></code> respectively.</p>
</section>
<section id="vectors">
<span id="vec"></span><h3>Vectors<a class="headerlink" href="#vectors" title="Link to this heading">#</a></h3>
<p>Warp provides built-in math and geometry types for common simulation and graphics problems.
A full reference for operators and functions for these types is available in the <a class="reference internal" href="functions.html"><span class="doc">Kernel Reference</span></a>.</p>
<p>Warp supports vectors of numbers with an arbitrary length/numeric type. The built-in concrete types are as follows:</p>
<div class="table-wrapper docutils container">
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p>vec2 vec3 vec4</p></td>
<td><p>2D, 3D, 4D vector of single-precision floats</p></td>
</tr>
<tr class="row-even"><td><p>vec2b vec3b vec4b</p></td>
<td><p>2D, 3D, 4D vector of signed bytes</p></td>
</tr>
<tr class="row-odd"><td><p>vec2ub vec3ub vec4ub</p></td>
<td><p>2D, 3D, 4D vector of unsigned bytes</p></td>
</tr>
<tr class="row-even"><td><p>vec2s vec3s vec4s</p></td>
<td><p>2D, 3D, 4D vector of signed shorts</p></td>
</tr>
<tr class="row-odd"><td><p>vec2us vec3us vec4us</p></td>
<td><p>2D, 3D, 4D vector of unsigned shorts</p></td>
</tr>
<tr class="row-even"><td><p>vec2i vec3i vec4i</p></td>
<td><p>2D, 3D, 4D vector of signed integers</p></td>
</tr>
<tr class="row-odd"><td><p>vec2ui vec3ui vec4ui</p></td>
<td><p>2D, 3D, 4D vector of unsigned integers</p></td>
</tr>
<tr class="row-even"><td><p>vec2l vec3l vec4l</p></td>
<td><p>2D, 3D, 4D vector of signed long integers</p></td>
</tr>
<tr class="row-odd"><td><p>vec2ul vec3ul vec4ul</p></td>
<td><p>2D, 3D, 4D vector of unsigned long integers</p></td>
</tr>
<tr class="row-even"><td><p>vec2h vec3h vec4h</p></td>
<td><p>2D, 3D, 4D vector of half-precision floats</p></td>
</tr>
<tr class="row-odd"><td><p>vec2f vec3f vec4f</p></td>
<td><p>2D, 3D, 4D vector of single-precision floats</p></td>
</tr>
<tr class="row-even"><td><p>vec2d vec3d vec4d</p></td>
<td><p>2D, 3D, 4D vector of double-precision floats</p></td>
</tr>
<tr class="row-odd"><td><p>spatial_vector</p></td>
<td><p>6D vector of single-precision floats</p></td>
</tr>
<tr class="row-even"><td><p>spatial_vectorf</p></td>
<td><p>6D vector of single-precision floats</p></td>
</tr>
<tr class="row-odd"><td><p>spatial_vectord</p></td>
<td><p>6D vector of double-precision floats</p></td>
</tr>
<tr class="row-even"><td><p>spatial_vectorh</p></td>
<td><p>6D vector of half-precision floats</p></td>
</tr>
</tbody>
</table>
</div>
<p>Vectors support most standard linear algebra operations, e.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@wp</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span> <span class="nf">compute</span><span class="p">(</span> <span class="o">...</span> <span class="p">):</span>

    <span class="c1"># basis vectors</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>

    <span class="c1"># take the cross product</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">cross</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

    <span class="c1"># compute</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>

    <span class="o">...</span>
</pre></div>
</div>
<p>It’s possible to declare additional vector types with different lengths and data types. This is done in outside of kernels in <em>Python scope</em> using <code class="docutils literal notranslate"><span class="pre">warp.types.vector()</span></code>, for example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># declare a new vector type for holding 5 double precision floats:</span>
<span class="n">vec5d</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">vector</span><span class="p">(</span><span class="n">length</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</pre></div>
</div>
<p>Once declared, the new type can be used when allocating arrays or inside kernels:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># create an array of vec5d</span>
<span class="n">arr</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">vec5d</span><span class="p">)</span>

<span class="c1"># use inside a kernel</span>
<span class="nd">@wp</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span> <span class="nf">compute</span><span class="p">(</span> <span class="o">...</span> <span class="p">):</span>

    <span class="c1"># zero initialize a custom named vector type</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">vec5d</span><span class="p">()</span>
    <span class="o">...</span>

    <span class="c1"># component-wise initialize a named vector type</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">vec5d</span><span class="p">(</span><span class="n">wp</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span>
              <span class="n">wp</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">2.0</span><span class="p">),</span>
              <span class="n">wp</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">3.0</span><span class="p">),</span>
              <span class="n">wp</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">4.0</span><span class="p">),</span>
              <span class="n">wp</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">5.0</span><span class="p">))</span>
  <span class="o">...</span>
</pre></div>
</div>
<p>In addition, it’s possible to directly create <em>anonymously</em> typed instances of these vectors without declaring their type in advance. In this case the type will be inferred by the constructor arguments. For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@wp</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span> <span class="nf">compute</span><span class="p">(</span> <span class="o">...</span> <span class="p">):</span>

    <span class="c1"># zero initialize vector of 5 doubles:</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">vector</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

    <span class="c1"># scalar initialize a vector of 5 doubles to the same value:</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">vector</span><span class="p">(</span><span class="n">wp</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span> <span class="n">length</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

    <span class="c1"># component-wise initialize a vector of 5 doubles</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">vector</span><span class="p">(</span><span class="n">wp</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span>
                  <span class="n">wp</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">2.0</span><span class="p">),</span>
                  <span class="n">wp</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">3.0</span><span class="p">),</span>
                  <span class="n">wp</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">4.0</span><span class="p">),</span>
                  <span class="n">wp</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">5.0</span><span class="p">))</span>
</pre></div>
</div>
<p>These can be used with all the standard vector arithmetic operators, e.g.: <code class="docutils literal notranslate"><span class="pre">+</span></code>, <code class="docutils literal notranslate"><span class="pre">-</span></code>, scalar multiplication, and can also be transformed using matrices with compatible dimensions, potentially returning vectors with a different length.</p>
</section>
<section id="matrices">
<span id="mat"></span><h3>Matrices<a class="headerlink" href="#matrices" title="Link to this heading">#</a></h3>
<p>Matrices with arbitrary shapes/numeric types are also supported. The built-in concrete matrix types are as follows:</p>
<div class="table-wrapper docutils container">
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p>mat22 mat33 mat44</p></td>
<td><p>2x2, 3x3, 4x4 matrix of single-precision floats</p></td>
</tr>
<tr class="row-even"><td><p>mat22f mat33f mat44f</p></td>
<td><p>2x2, 3x3, 4x4 matrix of single-precision floats</p></td>
</tr>
<tr class="row-odd"><td><p>mat22d mat33d mat44d</p></td>
<td><p>2x2, 3x3, 4x4 matrix of double-precision floats</p></td>
</tr>
<tr class="row-even"><td><p>mat22h mat33h mat44h</p></td>
<td><p>2x2, 3x3, 4x4 matrix of half-precision floats</p></td>
</tr>
<tr class="row-odd"><td><p>spatial_matrix</p></td>
<td><p>6x6 matrix of single-precision floats</p></td>
</tr>
<tr class="row-even"><td><p>spatial_matrixf</p></td>
<td><p>6x6 matrix of single-precision floats</p></td>
</tr>
<tr class="row-odd"><td><p>spatial_matrixd</p></td>
<td><p>6x6 matrix of double-precision floats</p></td>
</tr>
<tr class="row-even"><td><p>spatial_matrixh</p></td>
<td><p>6x6 matrix of half-precision floats</p></td>
</tr>
</tbody>
</table>
</div>
<p>Matrices are stored in row-major format and support most standard linear algebra operations:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@wp</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span> <span class="nf">compute</span><span class="p">(</span> <span class="o">...</span> <span class="p">):</span>

    <span class="c1"># initialize matrix</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">mat22</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span>
                 <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">)</span>

    <span class="c1"># compute inverse</span>
    <span class="n">minv</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

    <span class="c1"># transform vector</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">minv</span> <span class="o">*</span> <span class="n">wp</span><span class="o">.</span><span class="n">vec2</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">)</span>

    <span class="o">...</span>
</pre></div>
</div>
<p>In a similar manner to vectors, it’s possible to declare new matrix types with arbitrary shapes and data types using <code class="docutils literal notranslate"><span class="pre">wp.types.matrix()</span></code>, for example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># declare a new 3x2 half precision float matrix type:</span>
<span class="n">mat32h</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

<span class="c1"># create an array of this type</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mat32h</span><span class="p">)</span>
</pre></div>
</div>
<p>These can be used inside a kernel:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@wp</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span> <span class="nf">compute</span><span class="p">(</span> <span class="o">...</span> <span class="p">):</span>
    <span class="o">...</span>

    <span class="c1"># initialize a mat32h matrix</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">mat32h</span><span class="p">(</span><span class="n">wp</span><span class="o">.</span><span class="n">float16</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span> <span class="n">wp</span><span class="o">.</span><span class="n">float16</span><span class="p">(</span><span class="mf">2.0</span><span class="p">),</span>
               <span class="n">wp</span><span class="o">.</span><span class="n">float16</span><span class="p">(</span><span class="mf">3.0</span><span class="p">),</span> <span class="n">wp</span><span class="o">.</span><span class="n">float16</span><span class="p">(</span><span class="mf">4.0</span><span class="p">),</span>
               <span class="n">wp</span><span class="o">.</span><span class="n">float16</span><span class="p">(</span><span class="mf">5.0</span><span class="p">),</span> <span class="n">wp</span><span class="o">.</span><span class="n">float16</span><span class="p">(</span><span class="mf">6.0</span><span class="p">))</span>

    <span class="c1"># declare a 2 component half precision vector</span>
    <span class="n">v2</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">vec2h</span><span class="p">(</span><span class="n">wp</span><span class="o">.</span><span class="n">float16</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span> <span class="n">wp</span><span class="o">.</span><span class="n">float16</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))</span>

    <span class="c1"># multiply by the matrix, returning a 3 component vector:</span>
    <span class="n">v3</span> <span class="o">=</span> <span class="n">m</span> <span class="o">*</span> <span class="n">v2</span>
    <span class="o">...</span>
</pre></div>
</div>
<p>It’s also possible to directly create anonymously typed instances inside kernels where the type is inferred from constructor arguments as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@wp</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span> <span class="nf">compute</span><span class="p">(</span> <span class="o">...</span> <span class="p">):</span>
    <span class="o">...</span>

    <span class="c1"># create a 3x2 half precision matrix from components (row major ordering):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span>
        <span class="n">wp</span><span class="o">.</span><span class="n">float16</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span> <span class="n">wp</span><span class="o">.</span><span class="n">float16</span><span class="p">(</span><span class="mf">2.0</span><span class="p">),</span>
        <span class="n">wp</span><span class="o">.</span><span class="n">float16</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span> <span class="n">wp</span><span class="o">.</span><span class="n">float16</span><span class="p">(</span><span class="mf">2.0</span><span class="p">),</span>
        <span class="n">wp</span><span class="o">.</span><span class="n">float16</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span> <span class="n">wp</span><span class="o">.</span><span class="n">float16</span><span class="p">(</span><span class="mf">2.0</span><span class="p">),</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>

    <span class="c1"># zero initialize a 3x2 half precision matrix:</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">wp</span><span class="o">.</span><span class="n">float16</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>

    <span class="c1"># create a 5x5 double precision identity matrix:</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</pre></div>
</div>
<p>As with vectors, you can do standard matrix arithmetic with these variables, along with multiplying matrices with compatible shapes and potentially returning a matrix with a new shape.</p>
</section>
<section id="quaternions">
<span id="quat"></span><h3>Quaternions<a class="headerlink" href="#quaternions" title="Link to this heading">#</a></h3>
<p>Warp supports quaternions with the layout <code class="docutils literal notranslate"><span class="pre">i,</span> <span class="pre">j,</span> <span class="pre">k,</span> <span class="pre">w</span></code> where <code class="docutils literal notranslate"><span class="pre">w</span></code> is the real part. Here are the built-in concrete quaternion types:</p>
<div class="table-wrapper docutils container">
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p>quat</p></td>
<td><p>Single-precision floating point quaternion</p></td>
</tr>
<tr class="row-even"><td><p>quatf</p></td>
<td><p>Single-precision floating point quaternion</p></td>
</tr>
<tr class="row-odd"><td><p>quatd</p></td>
<td><p>Double-precision floating point quaternion</p></td>
</tr>
<tr class="row-even"><td><p>quath</p></td>
<td><p>Half-precision floating point quaternion</p></td>
</tr>
</tbody>
</table>
</div>
<p>Quaternions can be used to transform vectors as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@wp</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span> <span class="nf">compute</span><span class="p">(</span> <span class="o">...</span> <span class="p">):</span>
    <span class="o">...</span>

    <span class="c1"># construct a 30 degree rotation around the x-axis</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">quat_from_axis_angle</span><span class="p">(</span><span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span> <span class="n">wp</span><span class="o">.</span><span class="n">degrees</span><span class="p">(</span><span class="mf">30.0</span><span class="p">))</span>

    <span class="c1"># rotate an axis by this quaternion</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">quat_rotate</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">))</span>
</pre></div>
</div>
<p>As with vectors and matrices, you can declare quaternion types with an arbitrary numeric type like so:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">quatd</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">quaternion</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</pre></div>
</div>
<p>You can also create identity quaternion and anonymously typed instances inside a kernel like so:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@wp</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span> <span class="nf">compute</span><span class="p">(</span> <span class="o">...</span> <span class="p">):</span>
    <span class="o">...</span>

    <span class="c1"># create a double precision identity quaternion:</span>
    <span class="n">qd</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">quat_identity</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="c1"># precision defaults to wp.float32 so this creates a single precision identity quaternion:</span>
    <span class="n">qf</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">quat_identity</span><span class="p">()</span>

    <span class="c1"># create a half precision quaternion from components, or a vector/scalar:</span>
    <span class="n">qh</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">quaternion</span><span class="p">(</span><span class="n">wp</span><span class="o">.</span><span class="n">float16</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span>
                       <span class="n">wp</span><span class="o">.</span><span class="n">float16</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span>
                       <span class="n">wp</span><span class="o">.</span><span class="n">float16</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span>
                       <span class="n">wp</span><span class="o">.</span><span class="n">float16</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))</span>


    <span class="n">qh</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">quaternion</span><span class="p">(</span>
        <span class="n">wp</span><span class="o">.</span><span class="n">vector</span><span class="p">(</span><span class="n">wp</span><span class="o">.</span><span class="n">float16</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span><span class="n">wp</span><span class="o">.</span><span class="n">float16</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span><span class="n">wp</span><span class="o">.</span><span class="n">float16</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)),</span>
        <span class="n">wp</span><span class="o">.</span><span class="n">float16</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="transforms">
<span id="transform"></span><h3>Transforms<a class="headerlink" href="#transforms" title="Link to this heading">#</a></h3>
<p>Transforms are 7D vectors of floats representing a spatial rigid body transformation in format (p, q) where p is a 3D vector, and q is a quaternion.</p>
<div class="table-wrapper docutils container">
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p>transform</p></td>
<td><p>Single-precision floating point transform</p></td>
</tr>
<tr class="row-even"><td><p>transformf</p></td>
<td><p>Single-precision floating point transform</p></td>
</tr>
<tr class="row-odd"><td><p>transformd</p></td>
<td><p>Double-precision floating point transform</p></td>
</tr>
<tr class="row-even"><td><p>transformh</p></td>
<td><p>Half-precision floating point transform</p></td>
</tr>
</tbody>
</table>
</div>
<p>Transforms can be constructed inside kernels from translation and rotation parts:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@wp</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span> <span class="nf">compute</span><span class="p">(</span> <span class="o">...</span> <span class="p">):</span>
    <span class="o">...</span>

    <span class="c1"># create a transform from a vector/quaternion:</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span>
            <span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">),</span>
            <span class="n">wp</span><span class="o">.</span><span class="n">quat_from_axis_angle</span><span class="p">(</span><span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span> <span class="n">wp</span><span class="o">.</span><span class="n">degrees</span><span class="p">(</span><span class="mf">30.0</span><span class="p">)))</span>

    <span class="c1"># transform a point</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">transform_point</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">(</span><span class="mf">10.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>

    <span class="c1"># transform a vector (ignore translation)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">transform_vector</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">(</span><span class="mf">10.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
</pre></div>
</div>
<p>As with vectors and matrices, you can declare transform types with an arbitrary numeric type using <code class="docutils literal notranslate"><span class="pre">wp.types.transformation()</span></code>, for example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">transformd</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">transformation</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</pre></div>
</div>
<p>You can also create identity transforms and anonymously typed instances inside a kernel like so:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@wp</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span> <span class="nf">compute</span><span class="p">(</span> <span class="o">...</span> <span class="p">):</span>

    <span class="c1"># create double precision identity transform:</span>
    <span class="n">qd</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">transform_identity</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="structs">
<h3>Structs<a class="headerlink" href="#structs" title="Link to this heading">#</a></h3>
<p>Users can define custom structure types using the <code class="docutils literal notranslate"><span class="pre">&#64;wp.struct</span></code> decorator as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@wp</span><span class="o">.</span><span class="n">struct</span>
<span class="k">class</span> <span class="nc">MyStruct</span><span class="p">:</span>

    <span class="n">param1</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">param2</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">param3</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">)</span>
</pre></div>
</div>
<p>Struct attributes must be annotated with their respective type. They can be constructed in Python scope and then passed to kernels as arguments:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@wp</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="n">args</span><span class="p">:</span> <span class="n">MyStruct</span><span class="p">):</span>

    <span class="n">tid</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">tid</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">param1</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">param2</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">param3</span><span class="p">[</span><span class="n">tid</span><span class="p">])</span>

<span class="c1"># construct an instance of the struct in Python</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">MyStruct</span><span class="p">()</span>
<span class="n">s</span><span class="o">.</span><span class="n">param1</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">s</span><span class="o">.</span><span class="n">param2</span> <span class="o">=</span> <span class="mf">2.5</span>
<span class="n">s</span><span class="o">.</span><span class="n">param3</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">)</span>

<span class="c1"># pass to our compute kernel</span>
<span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">compute</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">s</span><span class="p">])</span>
</pre></div>
</div>
<p>An array of structs can be zero-initialized as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">MyStruct</span><span class="p">)</span>
</pre></div>
</div>
<p>An array of structs can also be initialized from a list of struct objects:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">MyStruct</span><span class="p">(),</span> <span class="n">MyStruct</span><span class="p">(),</span> <span class="n">MyStruct</span><span class="p">()],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">MyStruct</span><span class="p">)</span>
</pre></div>
</div>
<section id="example-using-a-custom-struct-in-gradient-computation">
<h4>Example: Using a custom struct in gradient computation<a class="headerlink" href="#example-using-a-custom-struct-in-gradient-computation" title="Link to this heading">#</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">warp</span> <span class="k">as</span> <span class="nn">wp</span>

<span class="n">wp</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>


<span class="nd">@wp</span><span class="o">.</span><span class="n">struct</span>
<span class="k">class</span> <span class="nc">TestStruct</span><span class="p">:</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">vec3</span>
    <span class="n">a</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">)</span>
    <span class="n">b</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">)</span>


<span class="nd">@wp</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span> <span class="nf">test_kernel</span><span class="p">(</span><span class="n">s</span><span class="p">:</span> <span class="n">TestStruct</span><span class="p">):</span>
    <span class="n">tid</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">tid</span><span class="p">()</span>

    <span class="n">s</span><span class="o">.</span><span class="n">b</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+</span> <span class="n">s</span><span class="o">.</span><span class="n">x</span>


<span class="nd">@wp</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span> <span class="nf">loss_kernel</span><span class="p">(</span><span class="n">s</span><span class="p">:</span> <span class="n">TestStruct</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)):</span>
    <span class="n">tid</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">tid</span><span class="p">()</span>

    <span class="n">v</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">b</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">atomic_add</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="n">tid</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mf">3.0</span> <span class="o">*</span> <span class="n">v</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>


<span class="c1"># create struct</span>
<span class="n">ts</span> <span class="o">=</span> <span class="n">TestStruct</span><span class="p">()</span>

<span class="c1"># set members</span>
<span class="n">ts</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">)</span>
<span class="n">ts</span><span class="o">.</span><span class="n">a</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">]]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ts</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">tape</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Tape</span><span class="p">()</span>
<span class="k">with</span> <span class="n">tape</span><span class="p">:</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">test_kernel</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">ts</span><span class="p">])</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">loss_kernel</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">ts</span><span class="p">,</span> <span class="n">loss</span><span class="p">])</span>

<span class="n">tape</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tape</span><span class="o">.</span><span class="n">gradients</span><span class="p">[</span><span class="n">ts</span><span class="p">]</span><span class="o">.</span><span class="n">a</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="type-conversions">
<h3>Type Conversions<a class="headerlink" href="#type-conversions" title="Link to this heading">#</a></h3>
<p>Warp is particularly strict regarding type conversions and does not perform <em>any</em> implicit conversion between numeric types.
The user is responsible for ensuring types for most arithmetic operators match, e.g.: <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">=</span> <span class="pre">float(0.0)</span> <span class="pre">+</span> <span class="pre">int(4)</span></code> will result in an error.
This can be surprising for users that are accustomed to C-style conversions but avoids a class of common bugs that result from implicit conversions.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Warp does not currently perform implicit type conversions between numeric types.
Users should explicitly cast variables to compatible types using constructors like
<code class="docutils literal notranslate"><span class="pre">int()</span></code>, <code class="docutils literal notranslate"><span class="pre">float()</span></code>, <code class="docutils literal notranslate"><span class="pre">wp.float16()</span></code>, <code class="docutils literal notranslate"><span class="pre">wp.uint8()</span></code>, etc.</p>
</div>
</section>
</section>
<section id="constants">
<h2>Constants<a class="headerlink" href="#constants" title="Link to this heading">#</a></h2>
<p>In general, Warp kernels cannot access variables in the global Python interpreter state. One exception to this is for compile-time constants, which may be declared globally (or as class attributes) and folded into the kernel definition.</p>
<p>Constants are defined using the <code class="docutils literal notranslate"><span class="pre">wp.constant()</span></code> function. An example is shown below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">TYPE_SPHERE</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">TYPE_CUBE</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">TYPE_CAPSULE</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="nd">@wp</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span> <span class="nf">collide</span><span class="p">(</span><span class="n">geometry</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)):</span>

    <span class="n">t</span> <span class="o">=</span> <span class="n">geometry</span><span class="p">[</span><span class="n">wp</span><span class="o">.</span><span class="n">tid</span><span class="p">()]</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">t</span> <span class="o">==</span> <span class="n">TYPE_SPHERE</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;sphere&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">t</span> <span class="o">==</span> <span class="n">TYPE_CUBE</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;cube&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">t</span> <span class="o">==</span> <span class="n">TYPE_CAPSULE</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;capsule&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="warp.constant">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">warp.</span></span><span class="sig-name descname"><span class="pre">constant</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.constant" title="Link to this definition">#</a></dt>
<dd><p>Function to declare compile-time constants accessible from Warp kernels</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> – Compile-time constant value, can be any of the built-in math types.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="operators">
<h2>Operators<a class="headerlink" href="#operators" title="Link to this heading">#</a></h2>
<section id="boolean-operators">
<h3>Boolean Operators<a class="headerlink" href="#boolean-operators" title="Link to this heading">#</a></h3>
<div class="table-wrapper docutils container">
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p>a and b</p></td>
<td><p>True if a and b are True</p></td>
</tr>
<tr class="row-even"><td><p>a or b</p></td>
<td><p>True if a or b is True</p></td>
</tr>
<tr class="row-odd"><td><p>not a</p></td>
<td><p>True if a is False, otherwise False</p></td>
</tr>
</tbody>
</table>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Expressions such as <code class="docutils literal notranslate"><span class="pre">if</span> <span class="pre">(a</span> <span class="pre">and</span> <span class="pre">b):</span></code> currently do not perform short-circuit evaluation.
In this case <code class="docutils literal notranslate"><span class="pre">b</span></code> will also be evaluated even when <code class="docutils literal notranslate"><span class="pre">a</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code>.
Users should take care to ensure that secondary conditions are safe to evaluate (e.g.: do not index out of bounds) in all cases.</p>
</div>
</section>
<section id="comparison-operators">
<h3>Comparison Operators<a class="headerlink" href="#comparison-operators" title="Link to this heading">#</a></h3>
<div class="table-wrapper docutils container">
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p>a &gt; b</p></td>
<td><p>True if a strictly greater than b</p></td>
</tr>
<tr class="row-even"><td><p>a &lt; b</p></td>
<td><p>True if a strictly less than b</p></td>
</tr>
<tr class="row-odd"><td><p>a &gt;= b</p></td>
<td><p>True if a greater than or equal to b</p></td>
</tr>
<tr class="row-even"><td><p>a &lt;= b</p></td>
<td><p>True if a less than or equal to b</p></td>
</tr>
<tr class="row-odd"><td><p>a == b</p></td>
<td><p>True if a equals b</p></td>
</tr>
<tr class="row-even"><td><p>a != b</p></td>
<td><p>True if a not equal to b</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="arithmetic-operators">
<h3>Arithmetic Operators<a class="headerlink" href="#arithmetic-operators" title="Link to this heading">#</a></h3>
<div class="table-wrapper docutils container">
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p>a + b</p></td>
<td><p>Addition</p></td>
</tr>
<tr class="row-even"><td><p>a - b</p></td>
<td><p>Subtraction</p></td>
</tr>
<tr class="row-odd"><td><p>a * b</p></td>
<td><p>Multiplication</p></td>
</tr>
<tr class="row-even"><td><p>a / b</p></td>
<td><p>Floating point division</p></td>
</tr>
<tr class="row-odd"><td><p>a // b</p></td>
<td><p>Floored division</p></td>
</tr>
<tr class="row-even"><td><p>a ** b</p></td>
<td><p>Exponentiation</p></td>
</tr>
<tr class="row-odd"><td><p>a % b</p></td>
<td><p>Modulus</p></td>
</tr>
</tbody>
</table>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Since implicit conversions are not performed arguments types to operators should match.
Users should use type constructors, e.g.: <code class="docutils literal notranslate"><span class="pre">float()</span></code>, <code class="docutils literal notranslate"><span class="pre">int()</span></code>, <code class="docutils literal notranslate"><span class="pre">wp.int64()</span></code>, etc. to cast variables
to the correct type. Also note that the multiplication expression <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">*</span> <span class="pre">b</span></code> is used to represent scalar
multiplication and matrix multiplication. The <code class="docutils literal notranslate"><span class="pre">&#64;</span></code> operator is not currently supported.</p>
</div>
</section>
</section>
<section id="graphs">
<h2>Graphs<a class="headerlink" href="#graphs" title="Link to this heading">#</a></h2>
<p>Launching kernels from Python introduces significant additional overhead compared to C++ or native programs.
To address this, Warp exposes the concept of <a class="reference external" href="https://developer.nvidia.com/blog/cuda-graphs/">CUDA graphs</a>
to allow recording large batches of kernels and replaying them with very little CPU overhead.</p>
<p>To record a series of kernel launches use the <a class="reference internal" href="#warp.capture_begin" title="warp.capture_begin"><code class="xref py py-func docutils literal notranslate"><span class="pre">wp.capture_begin()</span></code></a> and
<a class="reference internal" href="#warp.capture_end" title="warp.capture_end"><code class="xref py py-func docutils literal notranslate"><span class="pre">wp.capture_end()</span></code></a> API as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># begin capture</span>
<span class="n">wp</span><span class="o">.</span><span class="n">capture_begin</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

<span class="k">try</span><span class="p">:</span>
    <span class="c1"># record launches</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">compute1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="k">finally</span><span class="p">:</span>
    <span class="c1"># end capture and return a graph object</span>
    <span class="n">graph</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">capture_end</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>We strongly recommend the use of the the try-finally pattern when capturing graphs because the <cite>finally</cite>
statement will ensure <a class="reference internal" href="#warp.capture_end" title="warp.capture_end"><code class="xref py py-func docutils literal notranslate"><span class="pre">wp.capture_end</span></code></a> gets called, even if an exception occurs during
capture, which would otherwise trap the stream in a capturing state.</p>
<p>Once a graph has been constructed it can be executed:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">wp</span><span class="o">.</span><span class="n">capture_launch</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>
</pre></div>
</div>
<p>The <a class="reference internal" href="#warp.ScopedCapture" title="warp.ScopedCapture"><code class="xref py py-class docutils literal notranslate"><span class="pre">wp.ScopedCapture</span></code></a> context manager can be used to simplify the code and
ensure that <a class="reference internal" href="#warp.capture_end" title="warp.capture_end"><code class="xref py py-func docutils literal notranslate"><span class="pre">wp.capture_end</span></code></a> is called regardless of exceptions:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">wp</span><span class="o">.</span><span class="n">ScopedCapture</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">capture</span><span class="p">:</span>
    <span class="c1"># record launches</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">compute1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

<span class="n">wp</span><span class="o">.</span><span class="n">capture_launch</span><span class="p">(</span><span class="n">capture</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
</pre></div>
</div>
<p>Note that only launch calls are recorded in the graph, any Python executed outside of the kernel code will not be recorded.
Typically it is only beneficial to use CUDA graphs when the graph will be reused or launched multiple times.</p>
<dl class="py function">
<dt class="sig sig-object py" id="warp.capture_begin">
<span class="sig-prename descclassname"><span class="pre">warp.</span></span><span class="sig-name descname"><span class="pre">capture_begin</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">force_module_load</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">external</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.capture_begin" title="Link to this definition">#</a></dt>
<dd><p>Begin capture of a CUDA graph</p>
<p>Captures all subsequent kernel launches and memory operations on CUDA devices.
This can be used to record large numbers of kernels and replay them with low overhead.</p>
<p>If <cite>device</cite> is specified, the capture will begin on the CUDA stream currently
associated with the device.  If <cite>stream</cite> is specified, the capture will begin
on the given stream.  If both are omitted, the capture will begin on the current
stream of the current device.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<a class="reference internal" href="devices.html#warp.context.Device" title="warp.context.Device"><em>Device</em></a><em> | </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em> | </em><em>None</em>) – The CUDA device to capture on</p></li>
<li><p><strong>stream</strong> – The CUDA stream to capture on</p></li>
<li><p><strong>force_module_load</strong> – Whether or not to force loading of all kernels before capture, in general it is better to use <code class="xref py py-func docutils literal notranslate"><span class="pre">load_module()</span></code> to selectively load kernels.</p></li>
<li><p><strong>external</strong> – Whether the capture was already started externally</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="warp.capture_end">
<span class="sig-prename descclassname"><span class="pre">warp.</span></span><span class="sig-name descname"><span class="pre">capture_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.capture_end" title="Link to this definition">#</a></dt>
<dd><p>Ends the capture of a CUDA graph</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<a class="reference internal" href="devices.html#warp.context.Device" title="warp.context.Device"><em>Device</em></a><em> | </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em> | </em><em>None</em>) – The CUDA device where capture began</p></li>
<li><p><strong>stream</strong> (<em>Stream</em><em> | </em><em>None</em>) – The CUDA stream where capture began</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A Graph object that can be launched with <a class="reference internal" href="#warp.capture_launch" title="warp.capture_launch"><code class="xref py py-func docutils literal notranslate"><span class="pre">capture_launch()</span></code></a></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Graph</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="warp.capture_launch">
<span class="sig-prename descclassname"><span class="pre">warp.</span></span><span class="sig-name descname"><span class="pre">capture_launch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">graph</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.capture_launch" title="Link to this definition">#</a></dt>
<dd><p>Launch a previously captured CUDA graph</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>graph</strong> (<em>Graph</em>) – A Graph as returned by <a class="reference internal" href="#warp.capture_end" title="warp.capture_end"><code class="xref py py-func docutils literal notranslate"><span class="pre">capture_end()</span></code></a></p></li>
<li><p><strong>stream</strong> (<em>Stream</em><em> | </em><em>None</em>) – A Stream to launch the graph on (optional)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="warp.ScopedCapture">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">warp.</span></span><span class="sig-name descname"><span class="pre">ScopedCapture</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">force_module_load</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">external</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.ScopedCapture" title="Link to this definition">#</a></dt>
<dd></dd></dl>

</section>
<section id="bounding-value-hierarchies-bvh">
<h2>Bounding Value Hierarchies (BVH)<a class="headerlink" href="#bounding-value-hierarchies-bvh" title="Link to this heading">#</a></h2>
<p>The <a class="reference internal" href="#warp.Bvh" title="warp.Bvh"><code class="xref py py-class docutils literal notranslate"><span class="pre">wp.Bvh</span></code></a> class can be used to create a BVH for a group of bounding volumes. This object can then be traversed
to determine which parts are intersected by a ray using <a class="reference internal" href="functions.html#warp.bvh_query_ray" title="warp.bvh_query_ray"><code class="xref py py-func docutils literal notranslate"><span class="pre">bvh_query_ray()</span></code></a> and which parts are fully contained
within a certain bounding volume using <a class="reference internal" href="functions.html#warp.bvh_query_aabb" title="warp.bvh_query_aabb"><code class="xref py py-func docutils literal notranslate"><span class="pre">bvh_query_aabb()</span></code></a>.</p>
<p>The following snippet demonstrates how to create a <a class="reference internal" href="#warp.Bvh" title="warp.Bvh"><code class="xref py py-class docutils literal notranslate"><span class="pre">wp.Bvh</span></code></a> object from 100 random bounding volumes:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>

<span class="n">num_bounds</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">lowers</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">num_bounds</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span> <span class="o">*</span> <span class="mf">5.0</span>
<span class="n">uppers</span> <span class="o">=</span> <span class="n">lowers</span> <span class="o">+</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">num_bounds</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span> <span class="o">*</span> <span class="mf">5.0</span>

<span class="n">device_lowers</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">lowers</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
<span class="n">device_uppers</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">uppers</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>

<span class="n">bvh</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Bvh</span><span class="p">(</span><span class="n">device_lowers</span><span class="p">,</span> <span class="n">device_uppers</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="warp.Bvh">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">warp.</span></span><span class="sig-name descname"><span class="pre">Bvh</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lowers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">uppers</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.Bvh" title="Link to this definition">#</a></dt>
<dd><p>Class representing a bounding volume hierarchy.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="warp.Bvh.id">
<span class="sig-name descname"><span class="pre">id</span></span><a class="headerlink" href="#warp.Bvh.id" title="Link to this definition">#</a></dt>
<dd><p>Unique identifier for this bvh object, can be passed to kernels.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="warp.Bvh.device">
<span class="sig-name descname"><span class="pre">device</span></span><a class="headerlink" href="#warp.Bvh.device" title="Link to this definition">#</a></dt>
<dd><p>Device this object lives on, all buffers must live on the same device.</p>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lowers</strong> (<a class="reference internal" href="#warp.array" title="warp.array"><code class="xref py py-class docutils literal notranslate"><span class="pre">warp.array</span></code></a>) – Array of lower bounds <code class="xref py py-class docutils literal notranslate"><span class="pre">warp.vec3</span></code></p></li>
<li><p><strong>uppers</strong> (<a class="reference internal" href="#warp.array" title="warp.array"><code class="xref py py-class docutils literal notranslate"><span class="pre">warp.array</span></code></a>) – Array of upper bounds <code class="xref py py-class docutils literal notranslate"><span class="pre">warp.vec3</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="warp.Bvh.refit">
<span class="sig-name descname"><span class="pre">refit</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#warp.Bvh.refit" title="Link to this definition">#</a></dt>
<dd><p>Refit the BVH. This should be called after users modify the <cite>lowers</cite> and <cite>uppers</cite> arrays.</p>
</dd></dl>

</dd></dl>

<section id="example-bvh-ray-traversal">
<h3>Example: BVH Ray Traversal<a class="headerlink" href="#example-bvh-ray-traversal" title="Link to this heading">#</a></h3>
<p>An example of performing a ray traversal on the data structure is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@wp</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span> <span class="nf">bvh_query_ray</span><span class="p">(</span>
    <span class="n">bvh_id</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">uint64</span><span class="p">,</span>
    <span class="n">start</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">,</span>
    <span class="nb">dir</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">,</span>
    <span class="n">bounds_intersected</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">bool</span><span class="p">),</span>
<span class="p">):</span>
    <span class="n">query</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">bvh_query_ray</span><span class="p">(</span><span class="n">bvh_id</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="nb">dir</span><span class="p">)</span>
    <span class="n">bounds_nr</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">int32</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">while</span> <span class="n">wp</span><span class="o">.</span><span class="n">bvh_query_next</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">bounds_nr</span><span class="p">):</span>
        <span class="c1"># The ray intersects the volume with index bounds_nr</span>
        <span class="n">bounds_intersected</span><span class="p">[</span><span class="n">bounds_nr</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>


<span class="n">bounds_intersected</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">num_bounds</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
<span class="n">query_start</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
<span class="n">query_dir</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>

<span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span>
    <span class="n">kernel</span><span class="o">=</span><span class="n">bvh_query_ray</span><span class="p">,</span>
    <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">bvh</span><span class="o">.</span><span class="n">id</span><span class="p">,</span> <span class="n">query_start</span><span class="p">,</span> <span class="n">query_dir</span><span class="p">,</span> <span class="n">bounds_intersected</span><span class="p">],</span>
    <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>The Warp kernel <code class="docutils literal notranslate"><span class="pre">bvh_query_ray</span></code> is launched with a single thread, provided the unique <a class="reference internal" href="functions.html#warp.uint64" title="warp.uint64"><code class="xref py py-class docutils literal notranslate"><span class="pre">uint64</span></code></a>
identifier of the <a class="reference internal" href="#warp.Bvh" title="warp.Bvh"><code class="xref py py-class docutils literal notranslate"><span class="pre">wp.Bvh</span></code></a> object, parameters describing the ray, and an array to store the results.
In <code class="docutils literal notranslate"><span class="pre">bvh_query_ray</span></code>, <a class="reference internal" href="functions.html#warp.bvh_query_ray" title="warp.bvh_query_ray"><code class="xref py py-func docutils literal notranslate"><span class="pre">wp.bvh_query_ray()</span></code></a> is called once to obtain an object that is stored in the
variable <code class="docutils literal notranslate"><span class="pre">query</span></code>. An integer is also allocated as <code class="docutils literal notranslate"><span class="pre">bounds_nr</span></code> to store the volume index of the traversal.
A while statement is used for the actual traversal using <a class="reference internal" href="functions.html#warp.bvh_query_next" title="warp.bvh_query_next"><code class="xref py py-func docutils literal notranslate"><span class="pre">wp.bvh_query_next()</span></code></a>,
which returns <code class="docutils literal notranslate"><span class="pre">True</span></code> as long as there are intersecting bounds.</p>
</section>
<section id="example-bvh-volume-traversal">
<h3>Example: BVH Volume Traversal<a class="headerlink" href="#example-bvh-volume-traversal" title="Link to this heading">#</a></h3>
<p>Similar to the ray-traversal example, we can perform volume traversal to find the volumes that are fully contained
within a specified bounding box.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@wp</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span> <span class="nf">bvh_query_aabb</span><span class="p">(</span>
    <span class="n">bvh_id</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">uint64</span><span class="p">,</span>
    <span class="n">lower</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">,</span>
    <span class="n">upper</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">,</span>
    <span class="n">bounds_intersected</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">bool</span><span class="p">),</span>
<span class="p">):</span>
    <span class="n">query</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">bvh_query_aabb</span><span class="p">(</span><span class="n">bvh_id</span><span class="p">,</span> <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">)</span>
    <span class="n">bounds_nr</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">int32</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">while</span> <span class="n">wp</span><span class="o">.</span><span class="n">bvh_query_next</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">bounds_nr</span><span class="p">):</span>
        <span class="c1"># The volume with index bounds_nr is fully contained</span>
        <span class="c1"># in the (lower,upper) bounding box</span>
        <span class="n">bounds_intersected</span><span class="p">[</span><span class="n">bounds_nr</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>


<span class="n">bounds_intersected</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">num_bounds</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
<span class="n">query_lower</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">(</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">)</span>
<span class="n">query_upper</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">(</span><span class="mf">6.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">)</span>

<span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span>
    <span class="n">kernel</span><span class="o">=</span><span class="n">bvh_query_aabb</span><span class="p">,</span>
    <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">bvh</span><span class="o">.</span><span class="n">id</span><span class="p">,</span> <span class="n">query_lower</span><span class="p">,</span> <span class="n">query_upper</span><span class="p">,</span> <span class="n">bounds_intersected</span><span class="p">],</span>
    <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>The kernel is nearly identical to the ray-traversal example, except we obtain <code class="docutils literal notranslate"><span class="pre">query</span></code> using
<a class="reference internal" href="functions.html#warp.bvh_query_aabb" title="warp.bvh_query_aabb"><code class="xref py py-func docutils literal notranslate"><span class="pre">wp.bvh_query_aabb()</span></code></a>.</p>
</section>
</section>
<section id="meshes">
<h2>Meshes<a class="headerlink" href="#meshes" title="Link to this heading">#</a></h2>
<p>Warp provides a <code class="docutils literal notranslate"><span class="pre">wp.Mesh</span></code> class to manage triangle mesh data. To create a mesh users provide a points, indices and optionally a velocity array:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mesh</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Mesh</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">velocities</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Mesh objects maintain references to their input geometry buffers. All buffers should live on the same device.</p>
</div>
<p>Meshes can be passed to kernels using their <code class="docutils literal notranslate"><span class="pre">id</span></code> attribute which uniquely identifies the mesh by a unique <code class="docutils literal notranslate"><span class="pre">uint64</span></code> value.
Once inside a kernel you can perform geometric queries against the mesh such as ray-casts or closest point lookups:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@wp</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span> <span class="nf">raycast</span><span class="p">(</span><span class="n">mesh</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">uint64</span><span class="p">,</span>
            <span class="n">ray_origin</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">),</span>
            <span class="n">ray_dir</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">),</span>
            <span class="n">ray_hit</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">)):</span>

    <span class="n">tid</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">tid</span><span class="p">()</span>

    <span class="n">t</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>      <span class="c1"># hit distance along ray</span>
    <span class="n">u</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>      <span class="c1"># hit face barycentric u</span>
    <span class="n">v</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>      <span class="c1"># hit face barycentric v</span>
    <span class="n">sign</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>   <span class="c1"># hit face sign</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">()</span>       <span class="c1"># hit face normal</span>
    <span class="n">f</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>          <span class="c1"># hit face index</span>

    <span class="n">color</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">()</span>

    <span class="c1"># ray cast against the mesh</span>
    <span class="k">if</span> <span class="n">wp</span><span class="o">.</span><span class="n">mesh_query_ray</span><span class="p">(</span><span class="n">mesh</span><span class="p">,</span> <span class="n">ray_origin</span><span class="p">[</span><span class="n">tid</span><span class="p">],</span> <span class="n">ray_dir</span><span class="p">[</span><span class="n">tid</span><span class="p">],</span> <span class="mf">1.e+6</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">sign</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">f</span><span class="p">):</span>

        <span class="c1"># if we got a hit then set color to the face normal</span>
        <span class="n">color</span> <span class="o">=</span> <span class="n">n</span><span class="o">*</span><span class="mf">0.5</span> <span class="o">+</span> <span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>

    <span class="n">ray_hit</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">=</span> <span class="n">color</span>
</pre></div>
</div>
<p>Users may update mesh vertex positions at runtime simply by modifying the points buffer.
After modifying point locations users should call <code class="docutils literal notranslate"><span class="pre">Mesh.refit()</span></code> to rebuild the bounding volume hierarchy (BVH) structure and ensure that queries work correctly.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Updating Mesh topology (indices) at runtime is not currently supported. Users should instead recreate a new Mesh object.</p>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="warp.Mesh">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">warp.</span></span><span class="sig-name descname"><span class="pre">Mesh</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">points</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">velocities</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">support_winding_number</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.Mesh" title="Link to this definition">#</a></dt>
<dd><p>Class representing a triangle mesh.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="warp.Mesh.id">
<span class="sig-name descname"><span class="pre">id</span></span><a class="headerlink" href="#warp.Mesh.id" title="Link to this definition">#</a></dt>
<dd><p>Unique identifier for this mesh object, can be passed to kernels.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="warp.Mesh.device">
<span class="sig-name descname"><span class="pre">device</span></span><a class="headerlink" href="#warp.Mesh.device" title="Link to this definition">#</a></dt>
<dd><p>Device this object lives on, all buffers must live on the same device.</p>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>points</strong> (<a class="reference internal" href="#warp.array" title="warp.array"><code class="xref py py-class docutils literal notranslate"><span class="pre">warp.array</span></code></a>) – Array of vertex positions of type <code class="xref py py-class docutils literal notranslate"><span class="pre">warp.vec3</span></code></p></li>
<li><p><strong>indices</strong> (<a class="reference internal" href="#warp.array" title="warp.array"><code class="xref py py-class docutils literal notranslate"><span class="pre">warp.array</span></code></a>) – Array of triangle indices of type <a class="reference internal" href="functions.html#warp.int32" title="warp.int32"><code class="xref py py-class docutils literal notranslate"><span class="pre">warp.int32</span></code></a>, should be a 1d array with shape (num_tris, 3)</p></li>
<li><p><strong>velocities</strong> (<a class="reference internal" href="#warp.array" title="warp.array"><code class="xref py py-class docutils literal notranslate"><span class="pre">warp.array</span></code></a>) – Array of vertex velocities of type <code class="xref py py-class docutils literal notranslate"><span class="pre">warp.vec3</span></code> (optional)</p></li>
<li><p><strong>support_winding_number</strong> (<a class="reference internal" href="functions.html#warp.bool" title="warp.bool"><em>bool</em></a>) – If true the mesh will build additional datastructures to support <cite>wp.mesh_query_point_sign_winding_number()</cite> queries</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="warp.Mesh.refit">
<span class="sig-name descname"><span class="pre">refit</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#warp.Mesh.refit" title="Link to this definition">#</a></dt>
<dd><p>Refit the BVH to points. This should be called after users modify the <cite>points</cite> data.</p>
</dd></dl>

</dd></dl>

</section>
<section id="hash-grids">
<h2>Hash Grids<a class="headerlink" href="#hash-grids" title="Link to this heading">#</a></h2>
<p>Many particle-based simulation methods such as the Discrete Element Method (DEM), or Smoothed Particle Hydrodynamics (SPH), involve iterating over spatial neighbors to compute force interactions. Hash grids are a well-established data structure to accelerate these nearest neighbor queries, and particularly well-suited to the GPU.</p>
<p>To support spatial neighbor queries Warp provides a <code class="docutils literal notranslate"><span class="pre">HashGrid</span></code> object that may be created as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">grid</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">HashGrid</span><span class="p">(</span><span class="n">dim_x</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">dim_y</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">dim_z</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

<span class="n">grid</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">points</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">radius</span><span class="o">=</span><span class="n">r</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">p</span></code> is an array of <code class="docutils literal notranslate"><span class="pre">wp.vec3</span></code> point positions, and <code class="docutils literal notranslate"><span class="pre">r</span></code> is the radius to use when building the grid.
Neighbors can then be iterated over inside the kernel code using <a class="reference internal" href="functions.html#warp.hash_grid_query" title="warp.hash_grid_query"><code class="xref py py-func docutils literal notranslate"><span class="pre">wp.hash_grid_query()</span></code></a>
and <a class="reference internal" href="functions.html#warp.hash_grid_query_next" title="warp.hash_grid_query_next"><code class="xref py py-func docutils literal notranslate"><span class="pre">wp.hash_grid_query_next()</span></code></a> as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@wp</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span> <span class="nf">sum</span><span class="p">(</span><span class="n">grid</span> <span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">uint64</span><span class="p">,</span>
        <span class="n">points</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">),</span>
        <span class="n">output</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">),</span>
        <span class="n">radius</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>

    <span class="n">tid</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">tid</span><span class="p">()</span>

    <span class="c1"># query point</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">points</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span>

    <span class="c1"># create grid query around point</span>
    <span class="n">query</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">hash_grid_query</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">radius</span><span class="p">)</span>
    <span class="n">index</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="nb">sum</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">()</span>

    <span class="k">while</span><span class="p">(</span><span class="n">wp</span><span class="o">.</span><span class="n">hash_grid_query_next</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">index</span><span class="p">)):</span>

        <span class="n">neighbor</span> <span class="o">=</span> <span class="n">points</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

        <span class="c1"># compute distance to neighbor point</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">length</span><span class="p">(</span><span class="n">p</span><span class="o">-</span><span class="n">neighbor</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">dist</span> <span class="o">&lt;=</span> <span class="n">radius</span><span class="p">):</span>
            <span class="nb">sum</span> <span class="o">+=</span> <span class="n">neighbor</span>

    <span class="n">output</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">=</span> <span class="nb">sum</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">HashGrid</span></code> query will give back all points in <em>cells</em> that fall inside the query radius.
When there are hash conflicts it means that some points outside of query radius will be returned, and users should
check the distance themselves inside their kernels. The reason the query doesn’t do the check itself for each
returned point is because it’s common for kernels to compute the distance themselves, so it would redundant to
check/compute the distance twice.</p>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="warp.HashGrid">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">warp.</span></span><span class="sig-name descname"><span class="pre">HashGrid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dim_x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim_y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim_z</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.HashGrid" title="Link to this definition">#</a></dt>
<dd><p>Class representing a hash grid object for accelerated point queries.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="warp.HashGrid.id">
<span class="sig-name descname"><span class="pre">id</span></span><a class="headerlink" href="#warp.HashGrid.id" title="Link to this definition">#</a></dt>
<dd><p>Unique identifier for this mesh object, can be passed to kernels.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="warp.HashGrid.device">
<span class="sig-name descname"><span class="pre">device</span></span><a class="headerlink" href="#warp.HashGrid.device" title="Link to this definition">#</a></dt>
<dd><p>Device this object lives on, all buffers must live on the same device.</p>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dim_x</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – Number of cells in x-axis</p></li>
<li><p><strong>dim_y</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – Number of cells in y-axis</p></li>
<li><p><strong>dim_z</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – Number of cells in z-axis</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="warp.HashGrid.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">points</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">radius</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.HashGrid.build" title="Link to this definition">#</a></dt>
<dd><p>Updates the hash grid data structure.</p>
<p>This method rebuilds the underlying datastructure and should be called any time the set
of points changes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>points</strong> (<a class="reference internal" href="#warp.array" title="warp.array"><code class="xref py py-class docutils literal notranslate"><span class="pre">warp.array</span></code></a>) – Array of points of type <code class="xref py py-class docutils literal notranslate"><span class="pre">warp.vec3</span></code></p></li>
<li><p><strong>radius</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a>) – The cell size to use for bucketing points, cells are cubes with edges of this width.
For best performance the radius used to construct the grid should match closely to
the radius used when performing queries.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="volumes">
<h2>Volumes<a class="headerlink" href="#volumes" title="Link to this heading">#</a></h2>
<p>Sparse volumes are incredibly useful for representing grid data over large domains, such as signed distance fields
(SDFs) for complex objects, or velocities for large-scale fluid flow. Warp supports reading sparse volumetric grids
stored using the <a class="reference external" href="https://developer.nvidia.com/nanovdb">NanoVDB</a> standard. Users can access voxels directly
or use built-in closest-point or trilinear interpolation to sample grid data from world or local space.</p>
<p>Volume objects can be created directly from Warp arrays containing a NanoVDB grid, from the contents of a
standard <code class="docutils literal notranslate"><span class="pre">.nvdb</span></code> file using <a class="reference internal" href="#warp.Volume.load_from_nvdb" title="warp.Volume.load_from_nvdb"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_from_nvdb()</span></code></a>,
or from a dense 3D NumPy array using <a class="reference internal" href="#warp.Volume.load_from_numpy" title="warp.Volume.load_from_numpy"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_from_numpy()</span></code></a>.</p>
<p>Volumes can also be created using <a class="reference internal" href="#warp.Volume.allocate" title="warp.Volume.allocate"><code class="xref py py-func docutils literal notranslate"><span class="pre">allocate()</span></code></a> or
<a class="reference internal" href="#warp.Volume.allocate_by_tiles" title="warp.Volume.allocate_by_tiles"><code class="xref py py-func docutils literal notranslate"><span class="pre">allocate_by_tiles()</span></code></a>. The values for a Volume object can be modified in a Warp
kernel using <a class="reference internal" href="functions.html#warp.volume_store_f" title="warp.volume_store_f"><code class="xref py py-func docutils literal notranslate"><span class="pre">wp.volume_store_f()</span></code></a>, <a class="reference internal" href="functions.html#warp.volume_store_v" title="warp.volume_store_v"><code class="xref py py-func docutils literal notranslate"><span class="pre">wp.volume_store_v()</span></code></a>, and
<a class="reference internal" href="functions.html#warp.volume_store_i" title="warp.volume_store_i"><code class="xref py py-func docutils literal notranslate"><span class="pre">wp.volume_store_i()</span></code></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Warp does not currently support modifying the topology of sparse volumes at runtime.</p>
</div>
<p>Below we give an example of creating a Volume object from an existing NanoVDB file:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># open NanoVDB file on disk</span>
<span class="n">file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;mygrid.nvdb&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span>

<span class="c1"># create Volume object</span>
<span class="n">volume</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Volume</span><span class="o">.</span><span class="n">load_from_nvdb</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Files written by the NanoVDB library, commonly marked by the <code class="docutils literal notranslate"><span class="pre">.nvdb</span></code> extension, can contain multiple grids with
various compression methods, but a <a class="reference internal" href="#warp.Volume" title="warp.Volume"><code class="xref py py-class docutils literal notranslate"><span class="pre">Volume</span></code></a> object represents a single NanoVDB grid therefore only files with
a single grid are supported. NanoVDB’s uncompressed and zip-compressed file formats are supported.</p>
</div>
<p>To sample the volume inside a kernel we pass a reference to it by ID, and use the built-in sampling modes:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@wp</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span> <span class="nf">sample_grid</span><span class="p">(</span><span class="n">volume</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">uint64</span><span class="p">,</span>
                <span class="n">points</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">),</span>
                <span class="n">samples</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)):</span>

    <span class="n">tid</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">tid</span><span class="p">()</span>

    <span class="c1"># load sample point in world-space</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">points</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span>

    <span class="c1"># transform position to the volume&#39;s local-space</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">volume_world_to_index</span><span class="p">(</span><span class="n">volume</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

    <span class="c1"># sample volume with trilinear interpolation</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">volume_sample_f</span><span class="p">(</span><span class="n">volume</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">wp</span><span class="o">.</span><span class="n">Volume</span><span class="o">.</span><span class="n">LINEAR</span><span class="p">)</span>

    <span class="c1"># write result</span>
    <span class="n">samples</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">=</span> <span class="n">f</span>
</pre></div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="warp.Volume">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">warp.</span></span><span class="sig-name descname"><span class="pre">Volume</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.Volume" title="Link to this definition">#</a></dt>
<dd><p>Class representing a sparse grid.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference internal" href="#warp.array" title="warp.array"><code class="xref py py-class docutils literal notranslate"><span class="pre">warp.array</span></code></a>) – Array of bytes representing the volume in NanoVDB format</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="warp.Volume.CLOSEST">
<span class="sig-name descname"><span class="pre">CLOSEST</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0</span></em><a class="headerlink" href="#warp.Volume.CLOSEST" title="Link to this definition">#</a></dt>
<dd><p>Enum value to specify nearest-neighbor interpolation during sampling</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="warp.Volume.LINEAR">
<span class="sig-name descname"><span class="pre">LINEAR</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#warp.Volume.LINEAR" title="Link to this definition">#</a></dt>
<dd><p>Enum value to specify trilinear interpolation during sampling</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="warp.Volume.array">
<span class="sig-name descname"><span class="pre">array</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#warp.Volume.array" title="Link to this definition">#</a></dt>
<dd><p>Returns the raw memory buffer of the Volume as an array</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#warp.array" title="warp.types.array"><em>array</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="warp.Volume.get_tiles">
<span class="sig-name descname"><span class="pre">get_tiles</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#warp.Volume.get_tiles" title="Link to this definition">#</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#warp.array" title="warp.types.array"><em>array</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="warp.Volume.get_voxel_size">
<span class="sig-name descname"><span class="pre">get_voxel_size</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#warp.Volume.get_voxel_size" title="Link to this definition">#</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.12)"><em>Tuple</em></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)">float</a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)">float</a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)">float</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="warp.Volume.load_from_nvdb">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">load_from_nvdb</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_or_buffer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.Volume.load_from_nvdb" title="Link to this definition">#</a></dt>
<dd><p>Creates a Volume object from a NanoVDB file or in-memory buffer.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A <code class="docutils literal notranslate"><span class="pre">warp.Volume</span></code> object.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="#warp.Volume" title="warp.types.Volume"><em>Volume</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="warp.Volume.load_from_numpy">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">load_from_numpy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_world</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">0.0,</span> <span class="pre">0.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">voxel_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bg_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.Volume.load_from_numpy" title="Link to this definition">#</a></dt>
<dd><p>Creates a Volume object from a dense 3D NumPy array.</p>
<p>This function is only supported for CUDA devices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>min_world</strong> – The 3D coordinate of the lower corner of the volume.</p></li>
<li><p><strong>voxel_size</strong> – The size of each voxel in spatial coordinates.</p></li>
<li><p><strong>bg_value</strong> – Background value</p></li>
<li><p><strong>device</strong> – The CUDA device to create the volume on, e.g.: “cuda” or “cuda:0”.</p></li>
<li><p><strong>ndarray</strong> (<em>array</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <code class="docutils literal notranslate"><span class="pre">warp.Volume</span></code> object.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#warp.Volume" title="warp.types.Volume"><em>Volume</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="warp.Volume.allocate">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">allocate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">min</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">voxel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bg_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">translation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">0.0,</span> <span class="pre">0.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">points_in_world_space</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.Volume.allocate" title="Link to this definition">#</a></dt>
<dd><p>Allocate a new Volume based on the bounding box defined by min and max.</p>
<p>This function is only supported for CUDA devices.</p>
<p>Allocate a volume that is large enough to contain voxels [min[0], min[1], min[2]] - [max[0], max[1], max[2]], inclusive.
If points_in_world_space is true, then min and max are first converted to index space with the given voxel size and
translation, and the volume is allocated with those.</p>
<p>The smallest unit of allocation is a dense tile of 8x8x8 voxels, the requested bounding box is rounded up to tiles, and
the resulting tiles will be available in the new volume.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>min</strong> (<em>array-like</em>) – Lower 3D coordinates of the bounding box in index space or world space, inclusive.</p></li>
<li><p><strong>max</strong> (<em>array-like</em>) – Upper 3D coordinates of the bounding box in index space or world space, inclusive.</p></li>
<li><p><strong>voxel_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a>) – Voxel size of the new volume.</p></li>
<li><p><strong>bg_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em> or </em><em>array-like</em>) – Value of unallocated voxels of the volume, also defines the volume’s type, a <code class="xref py py-class docutils literal notranslate"><span class="pre">warp.vec3</span></code> volume is created if this is <cite>array-like</cite>, otherwise a float volume is created</p></li>
<li><p><strong>translation</strong> (<em>array-like</em>) – translation between the index and world spaces.</p></li>
<li><p><strong>device</strong> (<em>Devicelike</em>) – The CUDA device to create the volume on, e.g.: “cuda” or “cuda:0”.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="#warp.Volume" title="warp.types.Volume"><em>Volume</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="warp.Volume.allocate_by_tiles">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">allocate_by_tiles</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tile_points</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">voxel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bg_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">translation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.0,</span> <span class="pre">0.0,</span> <span class="pre">0.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.Volume.allocate_by_tiles" title="Link to this definition">#</a></dt>
<dd><p>Allocate a new Volume with active tiles for each point tile_points.</p>
<p>This function is only supported for CUDA devices.</p>
<p>The smallest unit of allocation is a dense tile of 8x8x8 voxels.
This is the primary method for allocating sparse volumes. It uses an array of points indicating the tiles that must be allocated.</p>
<dl class="simple">
<dt>Example use cases:</dt><dd><ul class="simple">
<li><p><cite>tile_points</cite> can mark tiles directly in index space as in the case this method is called by <cite>allocate</cite>.</p></li>
<li><p><cite>tile_points</cite> can be a list of points used in a simulation that needs to transfer data to a volume.</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tile_points</strong> (<a class="reference internal" href="#warp.array" title="warp.array"><code class="xref py py-class docutils literal notranslate"><span class="pre">warp.array</span></code></a>) – Array of positions that define the tiles to be allocated.
The array can be a 2D, N-by-3 array of <a class="reference internal" href="functions.html#warp.int32" title="warp.int32"><code class="xref py py-class docutils literal notranslate"><span class="pre">warp.int32</span></code></a> values, indicating index space positions,
or can be a 1D array of <code class="xref py py-class docutils literal notranslate"><span class="pre">warp.vec3</span></code> values, indicating world space positions.
Repeated points per tile are allowed and will be efficiently deduplicated.</p></li>
<li><p><strong>voxel_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a>) – Voxel size of the new volume.</p></li>
<li><p><strong>bg_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em> or </em><em>array-like</em>) – Value of unallocated voxels of the volume, also defines the volume’s type, a <code class="xref py py-class docutils literal notranslate"><span class="pre">warp.vec3</span></code> volume is created if this is <cite>array-like</cite>, otherwise a float volume is created</p></li>
<li><p><strong>translation</strong> (<em>array-like</em>) – Translation between the index and world spaces.</p></li>
<li><p><strong>device</strong> (<em>Devicelike</em>) – The CUDA device to create the volume on, e.g.: “cuda” or “cuda:0”.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="#warp.Volume" title="warp.types.Volume"><em>Volume</em></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference external" href="functions.html#volumes">Reference</a> for the volume functions available in kernels.</p>
</div>
</section>
<section id="differentiability">
<h2>Differentiability<a class="headerlink" href="#differentiability" title="Link to this heading">#</a></h2>
<p>By default, Warp generates a forward and backward (adjoint) version of each kernel definition.
Buffers that participate in the chain of computation should be created with <code class="docutils literal notranslate"><span class="pre">requires_grad=True</span></code>, for example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">vec3</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">wp.Tape</span></code> class can then be used to record kernel launches, and replay them to compute the gradient of a scalar loss function with respect to the kernel inputs:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tape</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Tape</span><span class="p">()</span>

<span class="c1"># forward pass</span>
<span class="k">with</span> <span class="n">tape</span><span class="p">:</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">compute1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">compute2</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">c</span><span class="p">,</span> <span class="n">d</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">d</span><span class="p">,</span> <span class="n">l</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

<span class="c1"># reverse pass</span>
<span class="n">tape</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">l</span><span class="p">)</span>
</pre></div>
</div>
<p>After the backward pass has completed, the gradients with respect to the inputs are available via a mapping in the <a class="reference internal" href="#warp.Tape" title="warp.Tape"><code class="xref py py-class docutils literal notranslate"><span class="pre">wp.Tape</span></code></a> object:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># gradient of loss with respect to input a</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tape</span><span class="o">.</span><span class="n">gradients</span><span class="p">[</span><span class="n">a</span><span class="p">])</span>
</pre></div>
</div>
<p>Note that gradients are accumulated on the participating buffers, so if you wish to reuse the same buffers for multiple backward passes you should first zero the gradients:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tape</span><span class="o">.</span><span class="n">zero</span><span class="p">()</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Warp uses a source-code transformation approach to auto-differentiation.
In this approach, the backwards pass must keep a record of intermediate values computed during the forward pass.
This imposes some restrictions on what kernels can do and still be differentiable:</p>
<ul class="simple">
<li><p>Dynamic loops should not mutate any previously declared local variable. This means the loop must be side-effect free.
A simple way to ensure this is to move the loop body into a separate function.
Static loops that are unrolled at compile time do not have this restriction and can perform any computation.</p></li>
<li><p>Kernels should not overwrite any previously used array values except to perform simple linear add/subtract operations (e.g. via <a class="reference internal" href="functions.html#warp.atomic_add" title="warp.atomic_add"><code class="xref py py-func docutils literal notranslate"><span class="pre">wp.atomic_add()</span></code></a>)</p></li>
</ul>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="warp.Tape">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">warp.</span></span><span class="sig-name descname"><span class="pre">Tape</span></span><a class="headerlink" href="#warp.Tape" title="Link to this definition">#</a></dt>
<dd><p>Record kernel launches within a Tape scope to enable automatic differentiation.
Gradients can be computed after the operations have been recorded on the tape via
<code class="docutils literal notranslate"><span class="pre">tape.backward()</span></code>.</p>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tape</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Tape</span><span class="p">()</span>

<span class="c1"># forward pass</span>
<span class="k">with</span> <span class="n">tape</span><span class="p">:</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">compute1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">compute2</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">c</span><span class="p">,</span> <span class="n">d</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">d</span><span class="p">,</span> <span class="n">l</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

<span class="c1"># reverse pass</span>
<span class="n">tape</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">l</span><span class="p">)</span>
</pre></div>
</div>
<p>Gradients can be accessed via the <code class="docutils literal notranslate"><span class="pre">tape.gradients</span></code> dictionary, e.g.:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">tape</span><span class="o">.</span><span class="n">gradients</span><span class="p">[</span><span class="n">a</span><span class="p">])</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="warp.Tape.backward">
<span class="sig-name descname"><span class="pre">backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.Tape.backward" title="Link to this definition">#</a></dt>
<dd><p>Evaluate the backward pass of the recorded operations on the tape.
A single-element array <code class="docutils literal notranslate"><span class="pre">loss</span></code> or a dictionary of arrays <code class="docutils literal notranslate"><span class="pre">grads</span></code>
can be provided to assign the incoming gradients for the reverse-mode
automatic differentiation pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>loss</strong> (<em>wp.array</em>) – A single-element array that holds the loss function value whose gradient is to be computed</p></li>
<li><p><strong>grads</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.12)"><em>dict</em></a>) – A dictionary of arrays that map from Warp arrays to their incoming gradients</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="warp.Tape.record_func">
<span class="sig-name descname"><span class="pre">record_func</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">backward</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">arrays</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.Tape.record_func" title="Link to this definition">#</a></dt>
<dd><p>Records a custom function to be executed only in the backward pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>backward</strong> (<em>Callable</em>) – A callable Python object (can be any function) that will be executed in the backward pass.</p></li>
<li><p><strong>arrays</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a>) – A list of arrays that are used by the function for gradient tracking.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="warp.Tape.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#warp.Tape.reset" title="Link to this definition">#</a></dt>
<dd><p>Clear all operations recorded on the tape and zero out all gradients.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="warp.Tape.zero">
<span class="sig-name descname"><span class="pre">zero</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#warp.Tape.zero" title="Link to this definition">#</a></dt>
<dd><p>Zero out all gradients recorded on the tape.</p>
</dd></dl>

</dd></dl>

<section id="jacobians">
<h3>Jacobians<a class="headerlink" href="#jacobians" title="Link to this heading">#</a></h3>
<p>To compute the Jacobian matrix <span class="math notranslate nohighlight">\(J\in\mathbb{R}^{m\times n}\)</span> of a multi-valued function <span class="math notranslate nohighlight">\(f: \mathbb{R}^n \to \mathbb{R}^m\)</span>, we can evaluate an entire row of the Jacobian in parallel by finding the Jacobian-vector product <span class="math notranslate nohighlight">\(J^\top \mathbf{e}\)</span>. The vector <span class="math notranslate nohighlight">\(\mathbf{e}\in\mathbb{R}^m\)</span> selects the indices in the output buffer to differentiate with respect to.
In Warp, instead of passing a scalar loss buffer to the <code class="docutils literal notranslate"><span class="pre">tape.backward()</span></code> method, we pass a dictionary <code class="docutils literal notranslate"><span class="pre">grads</span></code> mapping from the function output array to the selection vector <span class="math notranslate nohighlight">\(\mathbf{e}\)</span> having the same type:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># compute the Jacobian for a function of single output</span>
<span class="n">jacobian</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">output_dim</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">tape</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Tape</span><span class="p">()</span>
<span class="k">with</span> <span class="n">tape</span><span class="p">:</span>
    <span class="n">output_buffer</span> <span class="o">=</span> <span class="n">launch_kernels_to_be_differentiated</span><span class="p">(</span><span class="n">input_buffer</span><span class="p">)</span>
<span class="k">for</span> <span class="n">output_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">output_dim</span><span class="p">):</span>
    <span class="c1"># select which row of the Jacobian we want to compute</span>
    <span class="n">select_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">output_dim</span><span class="p">)</span>
    <span class="n">select_index</span><span class="p">[</span><span class="n">output_index</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">select_index</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="c1"># pass input gradients to the output buffer to apply selection</span>
    <span class="n">tape</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">grads</span><span class="o">=</span><span class="p">{</span><span class="n">output_buffer</span><span class="p">:</span> <span class="n">e</span><span class="p">})</span>
    <span class="n">q_grad_i</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradients</span><span class="p">[</span><span class="n">input_buffer</span><span class="p">]</span>
    <span class="n">jacobian</span><span class="p">[</span><span class="n">output_index</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">q_grad_i</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">tape</span><span class="o">.</span><span class="n">zero</span><span class="p">()</span>
</pre></div>
</div>
<p>When we run simulations independently in parallel, the Jacobian corresponding to the entire system dynamics is a block-diagonal matrix. In this case, we can compute the Jacobian in parallel for all environments by choosing a selection vector that has the output indices active for all environment copies. For example, to get the first rows of the Jacobians of all environments, <span class="math notranslate nohighlight">\(\mathbf{e}=[\begin{smallmatrix}1 &amp; 0 &amp; 0 &amp; \dots &amp; 1 &amp; 0 &amp; 0 &amp; \dots\end{smallmatrix}]^\top\)</span>, to compute the second rows, <span class="math notranslate nohighlight">\(\mathbf{e}=[\begin{smallmatrix}0 &amp; 1 &amp; 0 &amp; \dots &amp; 0 &amp; 1 &amp; 0 &amp; \dots\end{smallmatrix}]^\top\)</span>, etc.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># compute the Jacobian for a function over multiple environments in parallel</span>
<span class="n">jacobians</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">num_envs</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">tape</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Tape</span><span class="p">()</span>
<span class="k">with</span> <span class="n">tape</span><span class="p">:</span>
    <span class="n">output_buffer</span> <span class="o">=</span> <span class="n">launch_kernels_to_be_differentiated</span><span class="p">(</span><span class="n">input_buffer</span><span class="p">)</span>
<span class="k">for</span> <span class="n">output_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">output_dim</span><span class="p">):</span>
    <span class="c1"># select which row of the Jacobian we want to compute</span>
    <span class="n">select_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">output_dim</span><span class="p">)</span>
    <span class="n">select_index</span><span class="p">[</span><span class="n">output_index</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="c1"># assemble selection vector for all environments (can be precomputed)</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">select_index</span><span class="p">,</span> <span class="n">num_envs</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">tape</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">grads</span><span class="o">=</span><span class="p">{</span><span class="n">output_buffer</span><span class="p">:</span> <span class="n">e</span><span class="p">})</span>
    <span class="n">q_grad_i</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradients</span><span class="p">[</span><span class="n">input_buffer</span><span class="p">]</span>
    <span class="n">jacobians</span><span class="p">[:,</span> <span class="n">output_index</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">q_grad_i</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">num_envs</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">)</span>
    <span class="n">tape</span><span class="o">.</span><span class="n">zero</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="custom-gradient-functions">
<h3>Custom Gradient Functions<a class="headerlink" href="#custom-gradient-functions" title="Link to this heading">#</a></h3>
<p>Warp supports custom gradient function definitions for user-defined Warp functions.
This allows users to define code that should replace the automatically generated derivatives.</p>
<p>To differentiate a function <span class="math notranslate nohighlight">\(h(x) = f(g(x))\)</span> that has a nested call to function <span class="math notranslate nohighlight">\(g(x)\)</span>, the chain rule is evaluated in the automatic differentiation of <span class="math notranslate nohighlight">\(h(x)\)</span>:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[h^\prime(x) = f^\prime({\color{green}{\underset{\textrm{replay}}{g(x)}}}) {\color{blue}{\underset{\textrm{grad}}{g^\prime(x)}}}\]</div>
</div>
<p>This implies that a function to be compatible with the autodiff engine needs to provide an implementation of its forward version
<span class="math notranslate nohighlight">\(\color{green}{g(x)}\)</span>, which we refer to as “replay” function (that matches the original function definition by default),
and its derivative <span class="math notranslate nohighlight">\(\color{blue}{g^\prime(x)}\)</span>, referred to as “grad”.</p>
<p>Both the replay and the grad implementations can be customized by the user. They are defined as follows:</p>
<div class="table-wrapper colwidths-given docutils container" id="id1">
<table class="docutils align-default" id="id1">
<caption><span class="caption-text">Customizing the replay and grad versions of function <code class="docutils literal notranslate"><span class="pre">myfunc</span></code></span><a class="headerlink" href="#id1" title="Link to this table">#</a></caption>
<colgroup>
<col style="width: 100.0%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>Forward Function</p></td>
</tr>
<tr class="row-even"><td><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@wp</span><span class="o">.</span><span class="n">func</span>
<span class="k">def</span> <span class="nf">myfunc</span><span class="p">(</span><span class="n">in1</span><span class="p">:</span> <span class="n">InType1</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">inN</span><span class="p">:</span> <span class="n">InTypeN</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OutType1</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">OutTypeM</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">out1</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">outM</span>
</pre></div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>Custom Replay Function</p></td>
</tr>
<tr class="row-even"><td><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@wp</span><span class="o">.</span><span class="n">func_replay</span><span class="p">(</span><span class="n">myfunc</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">replay_myfunc</span><span class="p">(</span><span class="n">in1</span><span class="p">:</span> <span class="n">InType1</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">inN</span><span class="p">:</span> <span class="n">InTypeN</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OutType1</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">OutTypeM</span><span class="p">:</span>
    <span class="c1"># Custom forward computations to be executed in the backward pass of a</span>
    <span class="c1"># function calling `myfunc` go here</span>
    <span class="c1"># Ensure the output variables match the original forward definition</span>
    <span class="k">return</span> <span class="n">out1</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">outM</span>
</pre></div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>Custom Grad Function</p></td>
</tr>
<tr class="row-even"><td><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@wp</span><span class="o">.</span><span class="n">func_grad</span><span class="p">(</span><span class="n">myfunc</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">adj_myfunc</span><span class="p">(</span><span class="n">in1</span><span class="p">:</span> <span class="n">InType1</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">inN</span><span class="p">:</span> <span class="n">InTypeN</span><span class="p">,</span> <span class="n">adj_out1</span><span class="p">:</span> <span class="n">OutType1</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">adj_outM</span><span class="p">:</span> <span class="n">OutTypeM</span><span class="p">):</span>
    <span class="c1"># Custom adjoint code goes here</span>
    <span class="c1"># Update the partial derivatives for the inputs as follows:</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">adjoint</span><span class="p">[</span><span class="n">in1</span><span class="p">]</span> <span class="o">+=</span> <span class="o">...</span>
    <span class="o">...</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">adjoint</span><span class="p">[</span><span class="n">inN</span><span class="p">]</span> <span class="o">+=</span> <span class="o">...</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It is currently not possible to define custom replay or grad functions for functions that
have generic arguments, e.g. <code class="docutils literal notranslate"><span class="pre">Any</span></code> or <code class="docutils literal notranslate"><span class="pre">wp.array(dtype=Any)</span></code>. Replay or grad functions that
themselves use generic arguments are also not yet supported.</p>
</div>
<section id="example-1-custom-grad-function">
<h4>Example 1: Custom Grad Function<a class="headerlink" href="#example-1-custom-grad-function" title="Link to this heading">#</a></h4>
<p>In the following, we define a Warp function <code class="docutils literal notranslate"><span class="pre">safe_sqrt</span></code> that computes the square root of a number:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@wp</span><span class="o">.</span><span class="n">func</span>
<span class="k">def</span> <span class="nf">safe_sqrt</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">wp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>To evaluate this function, we define a kernel that applies <code class="docutils literal notranslate"><span class="pre">safe_sqrt</span></code> to an array of input values:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@wp</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span> <span class="nf">run_safe_sqrt</span><span class="p">(</span><span class="n">xs</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">),</span> <span class="n">output</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)):</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">tid</span><span class="p">()</span>
    <span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">safe_sqrt</span><span class="p">(</span><span class="n">xs</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</pre></div>
</div>
<p>Calling the kernel for an array of values <code class="docutils literal notranslate"><span class="pre">[1.0,</span> <span class="pre">2.0,</span> <span class="pre">0.0]</span></code> yields the expected outputs, the gradients are finite except for the zero input:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">xs</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ys</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
<span class="n">tape</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Tape</span><span class="p">()</span>
<span class="k">with</span> <span class="n">tape</span><span class="p">:</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">run_safe_sqrt</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">xs</span><span class="p">),</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">xs</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">ys</span><span class="p">])</span>
<span class="n">tape</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">grads</span><span class="o">=</span><span class="p">{</span><span class="n">ys</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">xs</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">float32</span><span class="p">)})</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ys     &quot;</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;xs.grad&quot;</span><span class="p">,</span> <span class="n">xs</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>

<span class="c1"># ys      [1.   1.4142135   0. ]</span>
<span class="c1"># xs.grad [0.5  0.35355338  inf]</span>
</pre></div>
</div>
<p>It is often desired to catch nonfinite gradients in the computation graph as they may cause the entire gradient computation to be nonfinite.
To do so, we can define a custom gradient function that replaces the adjoint function for <code class="docutils literal notranslate"><span class="pre">safe_sqrt</span></code> which is automatically generated by
decorating the custom gradient code via <code class="docutils literal notranslate"><span class="pre">&#64;wp.func_grad(safe_sqrt)</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@wp</span><span class="o">.</span><span class="n">func_grad</span><span class="p">(</span><span class="n">safe_sqrt</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">adj_safe_sqrt</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">adj_ret</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
        <span class="n">wp</span><span class="o">.</span><span class="n">adjoint</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="o">+=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">2.0</span> <span class="o">*</span> <span class="n">wp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">*</span> <span class="n">adj_ret</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The function signature of the custom grad code consists of the input arguments of the forward function plus the adjoint variables of the
forward function outputs. To access and modify the partial derivatives of the input arguments, we use the <code class="docutils literal notranslate"><span class="pre">wp.adjoint</span></code> dictionary.
The keys of this dictionary are the input arguments of the forward function, and the values are the partial derivatives of the forward function
output with respect to the input argument.</p>
</div>
</section>
<section id="example-2-custom-replay-function">
<h4>Example 2: Custom Replay Function<a class="headerlink" href="#example-2-custom-replay-function" title="Link to this heading">#</a></h4>
<p>In the following, we increment an array index in each thread via <a class="reference internal" href="functions.html#warp.atomic_add" title="warp.atomic_add"><code class="xref py py-func docutils literal notranslate"><span class="pre">wp.atomic_add()</span></code></a> and compute
the square root of an input array at the incremented index:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@wp</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span> <span class="nf">test_add</span><span class="p">(</span><span class="n">counter</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">),</span> <span class="nb">input</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">),</span> <span class="n">output</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)):</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">atomic_add</span><span class="p">(</span><span class="n">counter</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">output</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">input</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">dim</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="n">use_reversible_increment</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="nb">input</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">counter</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">thread_ids</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">tape</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Tape</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">tape</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">use_reversible_increment</span><span class="p">:</span>
            <span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">test_add_diff</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">counter</span><span class="p">,</span> <span class="n">thread_ids</span><span class="p">,</span> <span class="nb">input</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">output</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">test_add</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">counter</span><span class="p">,</span> <span class="nb">input</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">output</span><span class="p">])</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;counter:    &quot;</span><span class="p">,</span> <span class="n">counter</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;thread_ids: &quot;</span><span class="p">,</span> <span class="n">thread_ids</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;input:      &quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;output:     &quot;</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

    <span class="n">tape</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">grads</span><span class="o">=</span><span class="p">{</span>
        <span class="n">output</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">dim</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="p">})</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;input.grad: &quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
<p>The output of the above code is:</p>
<div class="highlight-js notranslate"><div class="highlight"><pre><span></span><span class="nx">counter</span><span class="o">:</span><span class="w">     </span><span class="p">[</span><span class="mf">8</span><span class="p">]</span>
<span class="nx">thread_ids</span><span class="o">:</span><span class="w">  </span><span class="p">[</span><span class="mf">0</span><span class="w"> </span><span class="mf">0</span><span class="w"> </span><span class="mf">0</span><span class="w"> </span><span class="mf">0</span><span class="w"> </span><span class="mf">0</span><span class="w"> </span><span class="mf">0</span><span class="w"> </span><span class="mf">0</span><span class="w"> </span><span class="mf">0</span><span class="p">]</span>
<span class="nx">input</span><span class="o">:</span><span class="w">       </span><span class="p">[</span><span class="mf">1.</span><span class="w"> </span><span class="mf">2.</span><span class="w"> </span><span class="mf">3.</span><span class="w"> </span><span class="mf">4.</span><span class="w"> </span><span class="mf">5.</span><span class="w"> </span><span class="mf">6.</span><span class="w"> </span><span class="mf">7.</span><span class="w"> </span><span class="mf">8.</span><span class="p">]</span>
<span class="nx">output</span><span class="o">:</span><span class="w">      </span><span class="p">[</span><span class="mf">1.</span><span class="w">  </span><span class="mf">1.4142135</span><span class="w">  </span><span class="mf">1.7320508</span><span class="w">  </span><span class="mf">2.</span><span class="w">  </span><span class="mf">2.236068</span><span class="w">  </span><span class="mf">2.4494898</span><span class="w">  </span><span class="mf">2.6457512</span><span class="w">  </span><span class="mf">2.828427</span><span class="p">]</span>
<span class="nx">input</span><span class="p">.</span><span class="nx">grad</span><span class="o">:</span><span class="w">  </span><span class="p">[</span><span class="mf">4.</span><span class="w"> </span><span class="mf">0.</span><span class="w"> </span><span class="mf">0.</span><span class="w"> </span><span class="mf">0.</span><span class="w"> </span><span class="mf">0.</span><span class="w"> </span><span class="mf">0.</span><span class="w"> </span><span class="mf">0.</span><span class="w"> </span><span class="mf">0.</span><span class="p">]</span>
</pre></div>
</div>
<p>The gradient of the input is incorrect because the backward pass involving the atomic operation <code class="docutils literal notranslate"><span class="pre">wp.atomic_add()</span></code> does not know which thread ID corresponds
to which input value.
The index returned by the adjoint of <code class="docutils literal notranslate"><span class="pre">wp.atomic_add()</span></code> is always zero so that the gradient the first entry of the input array,
i.e. <span class="math notranslate nohighlight">\(\frac{1}{2\sqrt{1}} = 0.5\)</span>, is accumulated <code class="docutils literal notranslate"><span class="pre">dim</span></code> times (hence <code class="docutils literal notranslate"><span class="pre">input.grad[0]</span> <span class="pre">==</span> <span class="pre">4.0</span></code> and all other entries zero).</p>
<p>To fix this, we define a new Warp function <code class="docutils literal notranslate"><span class="pre">reversible_increment()</span></code> with a custom <em>replay</em> definition that stores the thread ID in a separate array:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@wp</span><span class="o">.</span><span class="n">func</span>
<span class="k">def</span> <span class="nf">reversible_increment</span><span class="p">(</span>
    <span class="n">buf</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">),</span>
    <span class="n">buf_index</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">value</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">thread_values</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">),</span>
    <span class="n">tid</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">):</span>
    <span class="n">next_index</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">atomic_add</span><span class="p">(</span><span class="n">buf</span><span class="p">,</span> <span class="n">buf_index</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
    <span class="c1"># store which thread ID corresponds to which index for the backward pass</span>
    <span class="n">thread_values</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">=</span> <span class="n">next_index</span>
    <span class="k">return</span> <span class="n">next_index</span>


<span class="nd">@wp</span><span class="o">.</span><span class="n">func_replay</span><span class="p">(</span><span class="n">reversible_increment</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">replay_reversible_increment</span><span class="p">(</span>
    <span class="n">buf</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">),</span>
    <span class="n">buf_index</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">value</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">thread_values</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">),</span>
    <span class="n">tid</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">):</span>
    <span class="k">return</span> <span class="n">thread_values</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span>
</pre></div>
</div>
<p>Instead of running <code class="docutils literal notranslate"><span class="pre">reversible_increment()</span></code>, the custom replay code in <code class="docutils literal notranslate"><span class="pre">replay_reversible_increment()</span></code> is now executed
during forward phase in the backward pass of the function calling <code class="docutils literal notranslate"><span class="pre">reversible_increment()</span></code>.
We first stored the array index to each thread ID in the forward pass, and now we retrieve the array index for each thread ID in the backward pass.
That way, the backward pass can reproduce the same addition operation as in the forward pass with exactly the same operands per thread.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The function signature of the custom replay code must match the forward function signature.</p>
</div>
<p>To use our function we write the following kernel:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@wp</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span> <span class="nf">test_add_diff</span><span class="p">(</span>
    <span class="n">counter</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">),</span>
    <span class="n">thread_ids</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">),</span>
    <span class="nb">input</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">),</span>
    <span class="n">output</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
<span class="p">):</span>
    <span class="n">tid</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">tid</span><span class="p">()</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">reversible_increment</span><span class="p">(</span><span class="n">counter</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">thread_ids</span><span class="p">,</span> <span class="n">tid</span><span class="p">)</span>
    <span class="n">output</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">input</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
</pre></div>
</div>
<p>Running the <code class="docutils literal notranslate"><span class="pre">test_add_diff</span></code> kernel via the previous <code class="docutils literal notranslate"><span class="pre">main</span></code> function with <code class="docutils literal notranslate"><span class="pre">use_reversible_increment</span> <span class="pre">=</span> <span class="pre">True</span></code>, we now compute correct gradients
for the input array:</p>
<div class="highlight-js notranslate"><div class="highlight"><pre><span></span><span class="nx">counter</span><span class="o">:</span><span class="w">     </span><span class="p">[</span><span class="mf">8</span><span class="p">]</span>
<span class="nx">thread_ids</span><span class="o">:</span><span class="w">  </span><span class="p">[</span><span class="mf">0</span><span class="w"> </span><span class="mf">1</span><span class="w"> </span><span class="mf">2</span><span class="w"> </span><span class="mf">3</span><span class="w"> </span><span class="mf">4</span><span class="w"> </span><span class="mf">5</span><span class="w"> </span><span class="mf">6</span><span class="w"> </span><span class="mf">7</span><span class="p">]</span>
<span class="nx">input</span><span class="o">:</span><span class="w">       </span><span class="p">[</span><span class="mf">1.</span><span class="w"> </span><span class="mf">2.</span><span class="w"> </span><span class="mf">3.</span><span class="w"> </span><span class="mf">4.</span><span class="w"> </span><span class="mf">5.</span><span class="w"> </span><span class="mf">6.</span><span class="w"> </span><span class="mf">7.</span><span class="w"> </span><span class="mf">8.</span><span class="p">]</span>
<span class="nx">output</span><span class="o">:</span><span class="w">      </span><span class="p">[</span><span class="mf">1.</span><span class="w">   </span><span class="mf">1.4142135</span><span class="w">   </span><span class="mf">1.7320508</span><span class="w">   </span><span class="mf">2.</span><span class="w">    </span><span class="mf">2.236068</span><span class="w">   </span><span class="mf">2.4494898</span><span class="w">   </span><span class="mf">2.6457512</span><span class="w">   </span><span class="mf">2.828427</span><span class="w">  </span><span class="p">]</span>
<span class="nx">input</span><span class="p">.</span><span class="nx">grad</span><span class="o">:</span><span class="w">  </span><span class="p">[</span><span class="mf">0.5</span><span class="w">  </span><span class="mf">0.35355338</span><span class="w">  </span><span class="mf">0.28867513</span><span class="w">  </span><span class="mf">0.25</span><span class="w">  </span><span class="mf">0.2236068</span><span class="w">  </span><span class="mf">0.20412414</span><span class="w">  </span><span class="mf">0.18898225</span><span class="w">  </span><span class="mf">0.17677669</span><span class="p">]</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="custom-native-functions">
<h2>Custom Native Functions<a class="headerlink" href="#custom-native-functions" title="Link to this heading">#</a></h2>
<p>Users may insert native C++/CUDA code in Warp kernels using <code class="docutils literal notranslate"><span class="pre">&#64;func_native</span></code> decorated functions.
These accept native code as strings that get compiled after code generation, and are called within <code class="docutils literal notranslate"><span class="pre">&#64;wp.kernel</span></code> functions.
For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">snippet</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    __shared__ int s[128];</span>

<span class="s2">    s[tid] = d[tid];</span>
<span class="s2">    __syncthreads();</span>
<span class="s2">    d[tid] = s[N - tid - 1];</span>
<span class="s2">    &quot;&quot;&quot;</span>

<span class="nd">@wp</span><span class="o">.</span><span class="n">func_native</span><span class="p">(</span><span class="n">snippet</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">reverse</span><span class="p">(</span><span class="n">d</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">),</span> <span class="n">N</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">tid</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="o">...</span>

<span class="nd">@wp</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span> <span class="nf">reverse_kernel</span><span class="p">(</span><span class="n">d</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">),</span> <span class="n">N</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="n">tid</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">tid</span><span class="p">()</span>
    <span class="n">reverse</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">tid</span><span class="p">)</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">reverse_kernel</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p>Notice the use of shared memory here: the Warp library does not expose shared memory as a feature, but the CUDA compiler will
readily accept the above snippet. This means CUDA features not exposed in Warp are still accessible in Warp scripts.
Warp kernels meant for the CPU won’t be able to leverage CUDA features of course, but this same mechanism supports pure C++ snippets as well.</p>
<p>Please bear in mind the following: the thread index in your snippet should be computed in a <code class="docutils literal notranslate"><span class="pre">&#64;wp.kernel</span></code> and passed to your snippet,
as in the above example. This means your <code class="docutils literal notranslate"><span class="pre">&#64;wp.func_native</span></code> function signature should include the variables used in your snippet,
as well as a thread index of type <code class="docutils literal notranslate"><span class="pre">int</span></code>. The function body itself should be stubbed with <code class="docutils literal notranslate"><span class="pre">...</span></code> (the snippet will be inserted during compilation).</p>
<p>Should you wish to record your native function on the tape and then subsequently rewind the tape, you must include an adjoint snippet
alongside your snippet as an additional input to the decorator, as in the following example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">snippet</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">out[tid] = a * x[tid] + y[tid];</span>
<span class="s2">&quot;&quot;&quot;</span>
<span class="n">adj_snippet</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">adj_a = x[tid] * adj_out[tid];</span>
<span class="s2">adj_x[tid] = a * adj_out[tid];</span>
<span class="s2">adj_y[tid] = adj_out[tid];</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="nd">@wp</span><span class="o">.</span><span class="n">func_native</span><span class="p">(</span><span class="n">snippet</span><span class="p">,</span> <span class="n">adj_snippet</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">saxpy</span><span class="p">(</span>
    <span class="n">a</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
    <span class="n">out</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
    <span class="n">tid</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="p">):</span>
    <span class="o">...</span>

<span class="nd">@wp</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span> <span class="nf">saxpy_kernel</span><span class="p">(</span>
    <span class="n">a</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
    <span class="n">out</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="p">):</span>
    <span class="n">tid</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">tid</span><span class="p">()</span>
    <span class="n">saxpy</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">tid</span><span class="p">)</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">a</span> <span class="o">=</span> <span class="mf">2.0</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">adj_out</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="n">tape</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Tape</span><span class="p">()</span>

<span class="k">with</span> <span class="n">tape</span><span class="p">:</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">saxpy_kernel</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">out</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="n">tape</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">grads</span><span class="o">=</span><span class="p">{</span><span class="n">out</span><span class="p">:</span> <span class="n">adj_out</span><span class="p">})</span>
</pre></div>
</div>
<p>You may also include a custom replay snippet, to be executed as part of the adjoint (see <a class="reference internal" href="#custom-gradient-functions">Custom Gradient Functions</a> for a full explanation).
Consider the following example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_custom_replay_grad</span><span class="p">():</span>
    <span class="n">num_threads</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">counter</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">thread_values</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_threads</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">wp</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_threads</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

<span class="n">snippet</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    int next_index = atomicAdd(counter, 1);</span>
<span class="s2">    thread_values[tid] = next_index;</span>
<span class="s2">    &quot;&quot;&quot;</span>
<span class="n">replay_snippet</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

<span class="nd">@wp</span><span class="o">.</span><span class="n">func_native</span><span class="p">(</span><span class="n">snippet</span><span class="p">,</span> <span class="n">replay_snippet</span><span class="o">=</span><span class="n">replay_snippet</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">reversible_increment</span><span class="p">(</span>
    <span class="n">counter</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">),</span> <span class="n">thread_values</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">),</span> <span class="n">tid</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">):</span>
    <span class="o">...</span>

<span class="nd">@wp</span><span class="o">.</span><span class="n">kernel</span>
<span class="k">def</span> <span class="nf">run_atomic_add</span><span class="p">(</span>
    <span class="nb">input</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">),</span>
    <span class="n">counter</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">),</span>
    <span class="n">thread_values</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">),</span>
    <span class="n">output</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">),</span>
<span class="p">):</span>
    <span class="n">tid</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">tid</span><span class="p">()</span>
    <span class="n">reversible_increment</span><span class="p">(</span><span class="n">counter</span><span class="p">,</span> <span class="n">thread_values</span><span class="p">,</span> <span class="n">tid</span><span class="p">)</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">thread_values</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span>
    <span class="n">output</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">**</span> <span class="mf">2.0</span>

<span class="n">tape</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Tape</span><span class="p">()</span>
<span class="k">with</span> <span class="n">tape</span><span class="p">:</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span>
        <span class="n">run_atomic_add</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">num_threads</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">inputs</span><span class="p">,</span> <span class="n">counter</span><span class="p">,</span> <span class="n">thread_values</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">outputs</span><span class="p">]</span>
    <span class="p">)</span>

<span class="n">tape</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">grads</span><span class="o">=</span><span class="p">{</span><span class="n">outputs</span><span class="p">:</span> <span class="n">wp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_threads</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))})</span>
</pre></div>
</div>
<p>By default, <code class="docutils literal notranslate"><span class="pre">snippet</span></code> would be called in the backward pass, but in this case, we have a custom replay snippet defined, which is called instead.
In this case, <code class="docutils literal notranslate"><span class="pre">replay_snippet</span></code> is a no-op, which is all that we require, since <code class="docutils literal notranslate"><span class="pre">thread_values</span></code> are cached in the forward pass.
If we did not have a <code class="docutils literal notranslate"><span class="pre">replay_snippet</span></code> defined, <code class="docutils literal notranslate"><span class="pre">thread_values</span></code> would be overwritten with counter values that exceed the input array size in the backward pass.</p>
</section>
<section id="profiling">
<h2>Profiling<a class="headerlink" href="#profiling" title="Link to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">wp.ScopedTimer</span></code> objects can be used to gain some basic insight into the performance of Warp applications:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">wp</span><span class="o">.</span><span class="n">ScopedTimer</span><span class="p">(</span><span class="s2">&quot;grid build&quot;</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">grid</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">point_radius</span><span class="p">)</span>
</pre></div>
</div>
<p>This results in a printout at runtime to the standard output stream like:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">grid build took 0.06 ms</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">wp.ScopedTimer</span></code> object does not synchronize (e.g. by calling <code class="docutils literal notranslate"><span class="pre">wp.synchronize()</span></code>)
upon exiting the <code class="docutils literal notranslate"><span class="pre">with</span></code> statement, so this can lead to misleading numbers if the body
of the <code class="docutils literal notranslate"><span class="pre">with</span></code> statement launches device kernels.</p>
<p>When a <code class="docutils literal notranslate"><span class="pre">wp.ScopedTimer</span></code> object is passed <code class="docutils literal notranslate"><span class="pre">use_nvtx=True</span></code> as an argument, the timing functionality is replaced by calls
to <code class="docutils literal notranslate"><span class="pre">nvtx.start_range()</span></code> and <code class="docutils literal notranslate"><span class="pre">nvtx.end_range()</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">wp</span><span class="o">.</span><span class="n">ScopedTimer</span><span class="p">(</span><span class="s2">&quot;grid build&quot;</span><span class="p">,</span> <span class="n">use_nvtx</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;cyan&quot;</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">grid</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">point_radius</span><span class="p">)</span>
</pre></div>
</div>
<p>These range annotations can then be collected by a tool like <a class="reference external" href="https://developer.nvidia.com/nsight-systems">NVIDIA Nsight Systems</a>
for visualization on a timeline, e.g.:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>nsys<span class="w"> </span>profile<span class="w"> </span>python<span class="w"> </span>warp_application.py
</pre></div>
</div>
<p>This code snippet also demonstrates the use of the <code class="docutils literal notranslate"><span class="pre">color</span></code> argument to specify a color
for the range, which may be a number representing the ARGB value or a recognized string
(refer to <a class="reference external" href="https://github.com/NVIDIA/NVTX/blob/release-v3/python/nvtx/colors.py">colors.py</a> for
additional color examples).
The <a class="reference external" href="https://github.com/NVIDIA/NVTX">nvtx module</a> must be
installed in the Python environment for this capability to work.
An equivalent way to create an NVTX range without using <code class="docutils literal notranslate"><span class="pre">wp.ScopedTimer</span></code> is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nvtx</span>

<span class="k">with</span> <span class="n">nvtx</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s2">&quot;grid build&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;cyan&quot;</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">grid</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">point_radius</span><span class="p">)</span>
</pre></div>
</div>
<p>This form may be more convenient if the user does not need to frequently switch
between timer and NVTX capabilities of <code class="docutils literal notranslate"><span class="pre">wp.ScopedTimer</span></code>.</p>
<dl class="py class">
<dt class="sig sig-object py" id="warp.ScopedTimer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">warp.</span></span><span class="sig-name descname"><span class="pre">ScopedTimer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">active</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">print</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">detailed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_nvtx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">color</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'rapids'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">synchronize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.ScopedTimer" title="Link to this definition">#</a></dt>
<dd><p>Context manager object for a timer</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – Name of timer</p></li>
<li><p><strong>active</strong> (<a class="reference internal" href="functions.html#warp.bool" title="warp.bool"><em>bool</em></a>) – Enables this timer</p></li>
<li><p><strong>print</strong> (<a class="reference internal" href="functions.html#warp.bool" title="warp.bool"><em>bool</em></a>) – At context manager exit, print elapsed time to sys.stdout</p></li>
<li><p><strong>detailed</strong> (<a class="reference internal" href="functions.html#warp.bool" title="warp.bool"><em>bool</em></a>) – Collects additional profiling data using cProfile and calls <code class="docutils literal notranslate"><span class="pre">print_stats()</span></code> at context exit</p></li>
<li><p><strong>dict</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.12)"><em>dict</em></a>) – A dictionary of lists to which the elapsed time will be appended using <code class="docutils literal notranslate"><span class="pre">name</span></code> as a key</p></li>
<li><p><strong>use_nvtx</strong> (<a class="reference internal" href="functions.html#warp.bool" title="warp.bool"><em>bool</em></a>) – If true, timing functionality is replaced by an NVTX range</p></li>
<li><p><strong>color</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a>) – ARGB value (e.g. 0x00FFFF) or color name (e.g. ‘cyan’) associated with the NVTX range</p></li>
<li><p><strong>synchronize</strong> (<a class="reference internal" href="functions.html#warp.bool" title="warp.bool"><em>bool</em></a>) – Synchronize the CPU thread with any outstanding CUDA work to return accurate GPU timings</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="warp.ScopedTimer.elapsed">
<span class="sig-name descname"><span class="pre">elapsed</span></span><a class="headerlink" href="#warp.ScopedTimer.elapsed" title="Link to this definition">#</a></dt>
<dd><p>The duration of the <code class="docutils literal notranslate"><span class="pre">with</span></code> block used with this object</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)">float</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="functions.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Kernel Reference</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="../faq.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">FAQ</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2022-2024, NVIDIA
            </div>
            Made with 
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              <a class="muted-link " href="https://github.com/NVIDIA/warp" aria-label="GitHub">
            <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16">
                <path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path>
            </svg>
        </a>
              
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Runtime Reference</a><ul>
<li><a class="reference internal" href="#kernels">Kernels</a><ul>
<li><a class="reference internal" href="#warp.launch"><code class="docutils literal notranslate"><span class="pre">launch()</span></code></a></li>
<li><a class="reference internal" href="#large-kernel-launches">Large Kernel Launches</a></li>
<li><a class="reference internal" href="#runtime-kernel-specialization">Runtime Kernel Specialization</a></li>
</ul>
</li>
<li><a class="reference internal" href="#arrays">Arrays</a><ul>
<li><a class="reference internal" href="#warp.array"><code class="docutils literal notranslate"><span class="pre">array</span></code></a><ul>
<li><a class="reference internal" href="#warp.array.grad"><code class="docutils literal notranslate"><span class="pre">array.grad</span></code></a></li>
<li><a class="reference internal" href="#warp.array.requires_grad"><code class="docutils literal notranslate"><span class="pre">array.requires_grad</span></code></a></li>
<li><a class="reference internal" href="#warp.array.zero_"><code class="docutils literal notranslate"><span class="pre">array.zero_()</span></code></a></li>
<li><a class="reference internal" href="#warp.array.fill_"><code class="docutils literal notranslate"><span class="pre">array.fill_()</span></code></a></li>
<li><a class="reference internal" href="#warp.array.assign"><code class="docutils literal notranslate"><span class="pre">array.assign()</span></code></a></li>
<li><a class="reference internal" href="#warp.array.numpy"><code class="docutils literal notranslate"><span class="pre">array.numpy()</span></code></a></li>
<li><a class="reference internal" href="#warp.array.cptr"><code class="docutils literal notranslate"><span class="pre">array.cptr()</span></code></a></li>
<li><a class="reference internal" href="#warp.array.list"><code class="docutils literal notranslate"><span class="pre">array.list()</span></code></a></li>
<li><a class="reference internal" href="#warp.array.to"><code class="docutils literal notranslate"><span class="pre">array.to()</span></code></a></li>
<li><a class="reference internal" href="#warp.array.flatten"><code class="docutils literal notranslate"><span class="pre">array.flatten()</span></code></a></li>
<li><a class="reference internal" href="#warp.array.reshape"><code class="docutils literal notranslate"><span class="pre">array.reshape()</span></code></a></li>
<li><a class="reference internal" href="#warp.array.view"><code class="docutils literal notranslate"><span class="pre">array.view()</span></code></a></li>
<li><a class="reference internal" href="#warp.array.contiguous"><code class="docutils literal notranslate"><span class="pre">array.contiguous()</span></code></a></li>
<li><a class="reference internal" href="#warp.array.transpose"><code class="docutils literal notranslate"><span class="pre">array.transpose()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#multi-dimensional-arrays">Multi-dimensional Arrays</a><ul>
<li><a class="reference internal" href="#warp.zeros"><code class="docutils literal notranslate"><span class="pre">zeros()</span></code></a></li>
<li><a class="reference internal" href="#warp.zeros_like"><code class="docutils literal notranslate"><span class="pre">zeros_like()</span></code></a></li>
<li><a class="reference internal" href="#warp.full"><code class="docutils literal notranslate"><span class="pre">full()</span></code></a></li>
<li><a class="reference internal" href="#warp.full_like"><code class="docutils literal notranslate"><span class="pre">full_like()</span></code></a></li>
<li><a class="reference internal" href="#warp.empty"><code class="docutils literal notranslate"><span class="pre">empty()</span></code></a></li>
<li><a class="reference internal" href="#warp.empty_like"><code class="docutils literal notranslate"><span class="pre">empty_like()</span></code></a></li>
<li><a class="reference internal" href="#warp.copy"><code class="docutils literal notranslate"><span class="pre">copy()</span></code></a></li>
<li><a class="reference internal" href="#warp.clone"><code class="docutils literal notranslate"><span class="pre">clone()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#matrix-multiplication">Matrix Multiplication</a><ul>
<li><a class="reference internal" href="#warp.matmul"><code class="docutils literal notranslate"><span class="pre">matmul()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#data-types">Data Types</a><ul>
<li><a class="reference internal" href="#scalar-types">Scalar Types</a></li>
<li><a class="reference internal" href="#vectors">Vectors</a></li>
<li><a class="reference internal" href="#matrices">Matrices</a></li>
<li><a class="reference internal" href="#quaternions">Quaternions</a></li>
<li><a class="reference internal" href="#transforms">Transforms</a></li>
<li><a class="reference internal" href="#structs">Structs</a><ul>
<li><a class="reference internal" href="#example-using-a-custom-struct-in-gradient-computation">Example: Using a custom struct in gradient computation</a></li>
</ul>
</li>
<li><a class="reference internal" href="#type-conversions">Type Conversions</a></li>
</ul>
</li>
<li><a class="reference internal" href="#constants">Constants</a><ul>
<li><a class="reference internal" href="#warp.constant"><code class="docutils literal notranslate"><span class="pre">constant</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#operators">Operators</a><ul>
<li><a class="reference internal" href="#boolean-operators">Boolean Operators</a></li>
<li><a class="reference internal" href="#comparison-operators">Comparison Operators</a></li>
<li><a class="reference internal" href="#arithmetic-operators">Arithmetic Operators</a></li>
</ul>
</li>
<li><a class="reference internal" href="#graphs">Graphs</a><ul>
<li><a class="reference internal" href="#warp.capture_begin"><code class="docutils literal notranslate"><span class="pre">capture_begin()</span></code></a></li>
<li><a class="reference internal" href="#warp.capture_end"><code class="docutils literal notranslate"><span class="pre">capture_end()</span></code></a></li>
<li><a class="reference internal" href="#warp.capture_launch"><code class="docutils literal notranslate"><span class="pre">capture_launch()</span></code></a></li>
<li><a class="reference internal" href="#warp.ScopedCapture"><code class="docutils literal notranslate"><span class="pre">ScopedCapture</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#bounding-value-hierarchies-bvh">Bounding Value Hierarchies (BVH)</a><ul>
<li><a class="reference internal" href="#warp.Bvh"><code class="docutils literal notranslate"><span class="pre">Bvh</span></code></a><ul>
<li><a class="reference internal" href="#warp.Bvh.id"><code class="docutils literal notranslate"><span class="pre">Bvh.id</span></code></a></li>
<li><a class="reference internal" href="#warp.Bvh.device"><code class="docutils literal notranslate"><span class="pre">Bvh.device</span></code></a></li>
<li><a class="reference internal" href="#warp.Bvh.refit"><code class="docutils literal notranslate"><span class="pre">Bvh.refit()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#example-bvh-ray-traversal">Example: BVH Ray Traversal</a></li>
<li><a class="reference internal" href="#example-bvh-volume-traversal">Example: BVH Volume Traversal</a></li>
</ul>
</li>
<li><a class="reference internal" href="#meshes">Meshes</a><ul>
<li><a class="reference internal" href="#warp.Mesh"><code class="docutils literal notranslate"><span class="pre">Mesh</span></code></a><ul>
<li><a class="reference internal" href="#warp.Mesh.id"><code class="docutils literal notranslate"><span class="pre">Mesh.id</span></code></a></li>
<li><a class="reference internal" href="#warp.Mesh.device"><code class="docutils literal notranslate"><span class="pre">Mesh.device</span></code></a></li>
<li><a class="reference internal" href="#warp.Mesh.refit"><code class="docutils literal notranslate"><span class="pre">Mesh.refit()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#hash-grids">Hash Grids</a><ul>
<li><a class="reference internal" href="#warp.HashGrid"><code class="docutils literal notranslate"><span class="pre">HashGrid</span></code></a><ul>
<li><a class="reference internal" href="#warp.HashGrid.id"><code class="docutils literal notranslate"><span class="pre">HashGrid.id</span></code></a></li>
<li><a class="reference internal" href="#warp.HashGrid.device"><code class="docutils literal notranslate"><span class="pre">HashGrid.device</span></code></a></li>
<li><a class="reference internal" href="#warp.HashGrid.build"><code class="docutils literal notranslate"><span class="pre">HashGrid.build()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#volumes">Volumes</a><ul>
<li><a class="reference internal" href="#warp.Volume"><code class="docutils literal notranslate"><span class="pre">Volume</span></code></a><ul>
<li><a class="reference internal" href="#warp.Volume.CLOSEST"><code class="docutils literal notranslate"><span class="pre">Volume.CLOSEST</span></code></a></li>
<li><a class="reference internal" href="#warp.Volume.LINEAR"><code class="docutils literal notranslate"><span class="pre">Volume.LINEAR</span></code></a></li>
<li><a class="reference internal" href="#warp.Volume.array"><code class="docutils literal notranslate"><span class="pre">Volume.array()</span></code></a></li>
<li><a class="reference internal" href="#warp.Volume.get_tiles"><code class="docutils literal notranslate"><span class="pre">Volume.get_tiles()</span></code></a></li>
<li><a class="reference internal" href="#warp.Volume.get_voxel_size"><code class="docutils literal notranslate"><span class="pre">Volume.get_voxel_size()</span></code></a></li>
<li><a class="reference internal" href="#warp.Volume.load_from_nvdb"><code class="docutils literal notranslate"><span class="pre">Volume.load_from_nvdb()</span></code></a></li>
<li><a class="reference internal" href="#warp.Volume.load_from_numpy"><code class="docutils literal notranslate"><span class="pre">Volume.load_from_numpy()</span></code></a></li>
<li><a class="reference internal" href="#warp.Volume.allocate"><code class="docutils literal notranslate"><span class="pre">Volume.allocate()</span></code></a></li>
<li><a class="reference internal" href="#warp.Volume.allocate_by_tiles"><code class="docutils literal notranslate"><span class="pre">Volume.allocate_by_tiles()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#differentiability">Differentiability</a><ul>
<li><a class="reference internal" href="#warp.Tape"><code class="docutils literal notranslate"><span class="pre">Tape</span></code></a><ul>
<li><a class="reference internal" href="#warp.Tape.backward"><code class="docutils literal notranslate"><span class="pre">Tape.backward()</span></code></a></li>
<li><a class="reference internal" href="#warp.Tape.record_func"><code class="docutils literal notranslate"><span class="pre">Tape.record_func()</span></code></a></li>
<li><a class="reference internal" href="#warp.Tape.reset"><code class="docutils literal notranslate"><span class="pre">Tape.reset()</span></code></a></li>
<li><a class="reference internal" href="#warp.Tape.zero"><code class="docutils literal notranslate"><span class="pre">Tape.zero()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#jacobians">Jacobians</a></li>
<li><a class="reference internal" href="#custom-gradient-functions">Custom Gradient Functions</a><ul>
<li><a class="reference internal" href="#example-1-custom-grad-function">Example 1: Custom Grad Function</a></li>
<li><a class="reference internal" href="#example-2-custom-replay-function">Example 2: Custom Replay Function</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#custom-native-functions">Custom Native Functions</a></li>
<li><a class="reference internal" href="#profiling">Profiling</a><ul>
<li><a class="reference internal" href="#warp.ScopedTimer"><code class="docutils literal notranslate"><span class="pre">ScopedTimer</span></code></a><ul>
<li><a class="reference internal" href="#warp.ScopedTimer.elapsed"><code class="docutils literal notranslate"><span class="pre">ScopedTimer.elapsed</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=1ed6394b"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=32e29ea5"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=fd10adb8"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    </body>
</html>