<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Generics" href="generics.html" /><link rel="prev" title="Allocators" href="allocators.html" />

    <!-- Generated with Sphinx 7.2.6 and Furo 2024.01.29 -->
        <title>Concurrency - Warp 1.0.2</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=135e06be" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=36a5483c" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=a91381f3" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  --admonition-title-font-size: 100%;
  --admonition-font-size: 100%;
  --color-api-pre-name: #4e9a06;
  --color-api-name: #4e9a06;
  --color-admonition-title--seealso: #ffffff;
  --color-admonition-title-background--seealso: #448aff;
  --color-admonition-title-background--note: #76b900;
  --color-admonition-title--note: #ffffff;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-admonition-title-background--note: #535353;
  --color-admonition-title--note: #ffffff;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-admonition-title-background--note: #535353;
  --color-admonition-title--note: #ffffff;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">Warp 1.0.2</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo only-light" src="../_static/logo-light-mode.png" alt="Light Logo"/>
    <img class="sidebar-logo only-dark" src="../_static/logo-dark-mode.png" alt="Dark Logo"/>
  </div>
  
  <span class="sidebar-brand-text">Warp 1.0.2</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">User's Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basics.html">Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="devices.html">Devices</a></li>
<li class="toctree-l1"><a class="reference internal" href="allocators.html">Allocators</a></li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">Concurrency</a></li>
<li class="toctree-l1"><a class="reference internal" href="generics.html">Generics</a></li>
<li class="toctree-l1"><a class="reference internal" href="interoperability.html">Interoperability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../configuration.html">Runtime Settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../debugging.html">Debugging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../limitations.html">Limitations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Core Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="runtime.html">Runtime Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="functions.html">Kernel Reference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Simulation Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="sim.html">warp.sim</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse.html">warp.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="fem.html">warp.fem</a></li>
<li class="toctree-l1"><a class="reference internal" href="render.html">warp.render</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Project Links</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/NVIDIA/warp">GitHub</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pypi.org/project/warp-lang">PyPI</a></li>
<li class="toctree-l1"><a class="reference external" href="https://discord.com/channels/827959428476174346/953756751977648148">Discord</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="concurrency">
<h1>Concurrency<a class="headerlink" href="#concurrency" title="Link to this heading">#</a></h1>
<section id="asynchronous-operations">
<h2>Asynchronous Operations<a class="headerlink" href="#asynchronous-operations" title="Link to this heading">#</a></h2>
<section id="kernel-launches">
<h3>Kernel Launches<a class="headerlink" href="#kernel-launches" title="Link to this heading">#</a></h3>
<p>Kernels launched on a CUDA device are asynchronous with respect to the host (CPU Python thread).  Launching a kernel schedules
its execution on the CUDA device, but the <a class="reference internal" href="runtime.html#warp.launch" title="warp.launch"><code class="xref py py-func docutils literal notranslate"><span class="pre">wp.launch()</span></code></a> function can return before the kernel execution
completes.  This allows us to run some CPU computations while the CUDA kernel is executing, which is an
easy way to introduce parallelism into our programs.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">kernel1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>

<span class="c1"># do some CPU work while the CUDA kernel is running</span>
<span class="n">do_cpu_work</span><span class="p">()</span>
</pre></div>
</div>
<p>Kernels launched on different CUDA devices can execute concurrently.  This can be used to tackle independent sub-tasks in parallel on different GPUs while using the CPU to do other useful work:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># launch concurrent kernels on different devices</span>
<span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">kernel1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
<span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">kernel2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a1</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:1&quot;</span><span class="p">)</span>

<span class="c1"># do CPU work while kernels are running on both GPUs</span>
<span class="n">do_cpu_work</span><span class="p">()</span>
</pre></div>
</div>
<p>Launching kernels on the CPU is currently a synchronous operation.  In other words, <a class="reference internal" href="runtime.html#warp.launch" title="warp.launch"><code class="xref py py-func docutils literal notranslate"><span class="pre">wp.launch()</span></code></a> will return only after the kernel has finished executing on the CPU.  To run a CUDA kernel and a CPU kernel concurrently, the CUDA kernel should be launched first:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># schedule a kernel on a CUDA device</span>
<span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">kernel1</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>

<span class="c1"># run a kernel on the CPU while the CUDA kernel is running</span>
<span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">kernel2</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="graph-launches">
<h3>Graph Launches<a class="headerlink" href="#graph-launches" title="Link to this heading">#</a></h3>
<p>The concurrency rules for CUDA graph launches are similar to CUDA kernel launches, except that graphs are not available on the CPU.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># capture work on cuda:0 in a graph</span>
<span class="k">with</span> <span class="n">wp</span><span class="o">.</span><span class="n">ScopedCapture</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">capture0</span><span class="p">:</span>
    <span class="n">do_gpu0_work</span><span class="p">()</span>

<span class="c1"># capture work on cuda:1 in a graph</span>
<span class="k">with</span> <span class="n">wp</span><span class="o">.</span><span class="n">ScopedCapture</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:1&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">capture1</span><span class="p">:</span>
    <span class="n">do_gpu1_work</span><span class="p">()</span>

<span class="c1"># launch captured graphs on the respective devices concurrently</span>
<span class="n">wp</span><span class="o">.</span><span class="n">capture_launch</span><span class="p">(</span><span class="n">capture0</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
<span class="n">wp</span><span class="o">.</span><span class="n">capture_launch</span><span class="p">(</span><span class="n">capture1</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>

<span class="c1"># do some CPU work while the CUDA graphs are running</span>
<span class="n">do_cpu_work</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="array-creation">
<h3>Array Creation<a class="headerlink" href="#array-creation" title="Link to this heading">#</a></h3>
<p>Creating CUDA arrays is also asynchronous with respect to the host.  It involves allocating memory on the device
and initializing it, which is done under the hood using a kernel launch or an asynchronous CUDA memset operation.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">a0</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
<span class="n">b0</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>

<span class="n">a1</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:1&quot;</span><span class="p">)</span>
<span class="n">b1</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mf">42.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:1&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>In this snippet, arrays <code class="docutils literal notranslate"><span class="pre">a0</span></code> and <code class="docutils literal notranslate"><span class="pre">b0</span></code> are created on device <code class="docutils literal notranslate"><span class="pre">cuda:0</span></code> and arrays <code class="docutils literal notranslate"><span class="pre">a1</span></code> and <code class="docutils literal notranslate"><span class="pre">b1</span></code> are created
on device <code class="docutils literal notranslate"><span class="pre">cuda:1</span></code>.  The operations on the same device are sequential, but each device executes them independently of the
other device, so they can run concurrently.</p>
</section>
<section id="array-copying">
<h3>Array Copying<a class="headerlink" href="#array-copying" title="Link to this heading">#</a></h3>
<p>Copying arrays between devices can also be asynchronous, but there are some details to be aware of.</p>
<p>Copying from host memory to a CUDA device and copying from a CUDA device to host memory is asynchronous only if the host array is pinned.
Pinned memory allows the CUDA driver to use direct memory transfers (DMA), which are generally faster and can be done without involving the CPU.
There are a couple of drawbacks to using pinned memory: allocation and deallocation is usually slower and there are system-specific limits
on how much pinned memory can be allocated on the system.  For this reason, Warp CPU arrays are not pinned by default.  You can request a pinned
allocation by passing the <code class="docutils literal notranslate"><span class="pre">pinned=True</span></code> flag when creating a CPU array.  This is a good option for arrays that are used to copy data
between host and device, especially if asynchronous transfers are desired.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">h</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="n">pinned</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>

<span class="c1"># host-to-device copy</span>
<span class="n">wp</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>  <span class="c1"># synchronous</span>
<span class="n">wp</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>  <span class="c1"># asynchronous</span>

<span class="c1"># device-to-host copy</span>
<span class="n">wp</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>  <span class="c1"># synchronous</span>
<span class="n">wp</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>  <span class="c1"># asynchronous</span>

<span class="c1"># wait for asynchronous operations to complete</span>
<span class="n">wp</span><span class="o">.</span><span class="n">synchronize_device</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Copying between CUDA arrays on the same device is always asynchronous with respect to the host, since it does not involve the CPU:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>

<span class="c1"># asynchronous device-to-device copy</span>
<span class="n">wp</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<span class="c1"># wait for transfer to complete</span>
<span class="n">wp</span><span class="o">.</span><span class="n">synchronize_device</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Copying between CUDA arrays on different devices is also asynchronous with respect to the host.  Peer-to-peer transfers require
extra care, because CUDA devices are also asynchronous with respect to each other.  When copying an array from one GPU to another,
the destination GPU is used to perform the copy, so we need to ensure that prior work on the source GPU completes before the transfer.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">a0</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
<span class="n">a1</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:1&quot;</span><span class="p">)</span>

<span class="c1"># wait for outstanding work on the source device to complete to ensure the source array is ready</span>
<span class="n">wp</span><span class="o">.</span><span class="n">synchronize_device</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>

<span class="c1"># asynchronous peer-to-peer copy</span>
<span class="n">wp</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">a1</span><span class="p">,</span> <span class="n">a0</span><span class="p">)</span>

<span class="c1"># wait for the copy to complete on the destination device</span>
<span class="n">wp</span><span class="o">.</span><span class="n">synchronize_device</span><span class="p">(</span><span class="s2">&quot;cuda:1&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Note that peer-to-peer transfers can be accelerated using <a class="reference internal" href="allocators.html#mempool-access"><span class="std std-ref">memory pool access</span></a> or <a class="reference internal" href="devices.html#peer-access"><span class="std std-ref">peer access</span></a>, which enables DMA transfers between CUDA devices on supported systems.</p>
</section>
</section>
<section id="streams">
<span id="id1"></span><h2>Streams<a class="headerlink" href="#streams" title="Link to this heading">#</a></h2>
<p>A CUDA stream is a sequence of operations that execute in order on the GPU.  Operations from different streams may run concurrently
and may be interleaved by the device scheduler.</p>
<p>Warp automatically creates a stream for each CUDA device during initialization.  This becomes the current stream for the device.
All kernel launches and memory operations issued on that device are placed on the current stream.</p>
<section id="creating-streams">
<h3>Creating Streams<a class="headerlink" href="#creating-streams" title="Link to this heading">#</a></h3>
<p>A stream is tied to a particular CUDA device.  New streams can be created using the <code class="xref py py-class docutils literal notranslate"><span class="pre">wp.Stream</span></code> constructor:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">s1</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Stream</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>  <span class="c1"># create a stream on a specific CUDA device</span>
<span class="n">s2</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Stream</span><span class="p">()</span>          <span class="c1"># create a stream on the default device</span>
</pre></div>
</div>
<p>If the device parameter is omitted, the default device will be used, which can be managed using <code class="xref py py-class docutils literal notranslate"><span class="pre">wp.ScopedDevice</span></code>.</p>
<p>For interoperation with external code, it is possible to pass a CUDA stream handle to wrap an external stream:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">s3</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Stream</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">,</span> <span class="n">cuda_stream</span><span class="o">=</span><span class="n">stream_handle</span><span class="p">)</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">cuda_stream</span></code> argument must be a native stream handle (<code class="docutils literal notranslate"><span class="pre">cudaStream_t</span></code> or <code class="docutils literal notranslate"><span class="pre">CUstream</span></code>) passed as a Python integer.
This mechanism is used internally for sharing streams with external frameworks like PyTorch or DLPack.  The caller is responsible for ensuring
that the external stream does not get destroyed while it is referenced by a <code class="docutils literal notranslate"><span class="pre">wp.Stream</span></code> object.</p>
</section>
<section id="using-streams">
<h3>Using Streams<a class="headerlink" href="#using-streams" title="Link to this heading">#</a></h3>
<p>Use <code class="xref py py-class docutils literal notranslate"><span class="pre">wp.ScopedStream</span></code> to temporarily change the current stream on a device and schedule a sequence of operations on that stream:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">stream</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Stream</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">wp</span><span class="o">.</span><span class="n">ScopedStream</span><span class="p">(</span><span class="n">stream</span><span class="p">):</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">])</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
</pre></div>
</div>
<p>Since streams are tied to a particular device, <code class="xref py py-class docutils literal notranslate"><span class="pre">wp.ScopedStream</span></code> subsumes the functionality of <code class="xref py py-class docutils literal notranslate"><span class="pre">wp.ScopedDevice</span></code>.  That’s why we don’t need to explicitly specify the <code class="docutils literal notranslate"><span class="pre">device</span></code> argument to each of the calls.</p>
<p>An important benefit of streams is that they can be used to overlap compute and data transfer operations on the same device,
which can improve the overall throughput of a program by doing those operations in parallel.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">wp</span><span class="o">.</span><span class="n">ScopedDevice</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">):</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="n">pinned</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">compute_stream</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Stream</span><span class="p">()</span>
    <span class="n">transfer_stream</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Stream</span><span class="p">()</span>

    <span class="c1"># asynchronous kernel launch on a stream</span>
    <span class="k">with</span> <span class="n">wp</span><span class="o">.</span><span class="n">ScopedStream</span><span class="p">(</span><span class="n">compute_stream</span><span class="p">)</span>
        <span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">a</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">])</span>

    <span class="c1"># asynchronous host-to-device copy on another stream</span>
    <span class="k">with</span> <span class="n">wp</span><span class="o">.</span><span class="n">ScopedStream</span><span class="p">(</span><span class="n">transfer_stream</span><span class="p">)</span>
        <span class="n">wp</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
</pre></div>
</div>
<p>The <code class="xref py py-func docutils literal notranslate"><span class="pre">wp.get_stream()</span></code> function can be used to get the current stream on a device:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">s1</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">get_stream</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>  <span class="c1"># get the current stream on a specific device</span>
<span class="n">s2</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">get_stream</span><span class="p">()</span>          <span class="c1"># get the current stream on the default device</span>
</pre></div>
</div>
<p>The <code class="xref py py-func docutils literal notranslate"><span class="pre">wp.set_stream()</span></code> function can be used to set the current stream on a device:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">wp</span><span class="o">.</span><span class="n">set_stream</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>  <span class="c1"># set the stream on a specific device</span>
<span class="n">wp</span><span class="o">.</span><span class="n">set_stream</span><span class="p">(</span><span class="n">stream</span><span class="p">)</span>                   <span class="c1"># set the stream on the default device</span>
</pre></div>
</div>
<p>In general, we recommend using <code class="xref py py-class docutils literal notranslate"><span class="pre">wp.ScopedStream</span></code> rather than <code class="xref py py-func docutils literal notranslate"><span class="pre">wp.set_stream()</span></code>.</p>
</section>
<section id="synchronization">
<h3>Synchronization<a class="headerlink" href="#synchronization" title="Link to this heading">#</a></h3>
<p>The <code class="xref py py-func docutils literal notranslate"><span class="pre">wp.synchronize_stream()</span></code> function can be used to block the host thread until the given stream completes:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">wp</span><span class="o">.</span><span class="n">synchronize_stream</span><span class="p">(</span><span class="n">stream</span><span class="p">)</span>
</pre></div>
</div>
<p>In a program that uses multiple streams, this gives a more fine-grained level of control over synchronization behavior
than <code class="xref py py-func docutils literal notranslate"><span class="pre">wp.synchronize_device()</span></code>, which synchronizes all streams on the device.
For example, if a program has multiple compute and transfer streams, the host might only want to wait for one transfer stream
to complete, without waiting for the other streams.  By synchronizing only one stream, we allow the others to continue running
concurrently with the host thread.</p>
</section>
<section id="events">
<h3>Events<a class="headerlink" href="#events" title="Link to this heading">#</a></h3>
<p>Functions like <code class="xref py py-func docutils literal notranslate"><span class="pre">wp.synchronize_device()</span></code> or <code class="xref py py-func docutils literal notranslate"><span class="pre">wp.synchronize_stream()</span></code> block the CPU thread until work completes on a CUDA device, but they’re not intended to synchronize multiple CUDA streams with each other.</p>
<p>CUDA events provide a mechanism for device-side synchronization between streams.
This kind of synchronization does not block the host thread, but it allows one stream to wait for work on another stream
to complete.</p>
<p>Like streams, events are tied to a particular device:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">e1</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Event</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>  <span class="c1"># create an event on a specific CUDA device</span>
<span class="n">e2</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Event</span><span class="p">()</span>          <span class="c1"># create an event on the default device</span>
</pre></div>
</div>
<p>To wait for a stream to complete some work, we first record the event on that stream.  Then we make another stream
wait on that event:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">stream1</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Stream</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
<span class="n">stream2</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Stream</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
<span class="n">event</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Event</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>

<span class="n">stream1</span><span class="o">.</span><span class="n">record_event</span><span class="p">(</span><span class="n">event</span><span class="p">)</span>
<span class="n">stream2</span><span class="o">.</span><span class="n">wait_event</span><span class="p">(</span><span class="n">event</span><span class="p">)</span>
</pre></div>
</div>
<p>Note that when recording events, the event must be from the same device as the recording stream.
When waiting for events, the waiting stream can be from another device.  This allows using events to synchronize streams
on different GPUs.</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">record_event()</span></code> method is called without an event argument, a temporary event will be created, recorded, and returned:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">event</span> <span class="o">=</span> <span class="n">stream1</span><span class="o">.</span><span class="n">record_event</span><span class="p">()</span>
<span class="n">stream2</span><span class="o">.</span><span class="n">wait_event</span><span class="p">(</span><span class="n">event</span><span class="p">)</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">wait_stream()</span></code> method combines the acts of recording and waiting on an event in one call:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">stream2</span><span class="o">.</span><span class="n">wait_stream</span><span class="p">(</span><span class="n">stream1</span><span class="p">)</span>
</pre></div>
</div>
<p>Warp also provides global functions <code class="xref py py-func docutils literal notranslate"><span class="pre">wp.record_event()</span></code>, <code class="xref py py-func docutils literal notranslate"><span class="pre">wp.wait_event()</span></code>, and <code class="xref py py-func docutils literal notranslate"><span class="pre">wp.wait_stream()</span></code> which operate on the current
stream of the default device:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">wp</span><span class="o">.</span><span class="n">record_event</span><span class="p">(</span><span class="n">event</span><span class="p">)</span>  <span class="c1"># record an event on the current stream</span>
<span class="n">wp</span><span class="o">.</span><span class="n">wait_event</span><span class="p">(</span><span class="n">event</span><span class="p">)</span>    <span class="c1"># make the current stream wait for an event</span>
<span class="n">wp</span><span class="o">.</span><span class="n">wait_stream</span><span class="p">(</span><span class="n">stream</span><span class="p">)</span>  <span class="c1"># make the current stream wait for another stream</span>
</pre></div>
</div>
<p>These variants are convenient to use inside of <code class="xref py py-class docutils literal notranslate"><span class="pre">wp.ScopedStream</span></code> and <code class="xref py py-class docutils literal notranslate"><span class="pre">wp.ScopedDevice</span></code> managers.</p>
<p>Here is a more complete example with a producer stream that copies data into an array and a consumer stream
that uses the array in a kernel:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">wp</span><span class="o">.</span><span class="n">ScopedDevice</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">):</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="n">pinned</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">producer_stream</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Stream</span><span class="p">()</span>
    <span class="n">consumer_stream</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Stream</span><span class="p">()</span>

    <span class="k">with</span> <span class="n">wp</span><span class="o">.</span><span class="n">ScopedStream</span><span class="p">(</span><span class="n">producer_stream</span><span class="p">)</span>
        <span class="c1"># asynchronous host-to-device copy</span>
        <span class="n">wp</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

        <span class="c1"># record an event to create a synchronization point for the consumer stream</span>
        <span class="n">event</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">record_event</span><span class="p">()</span>

        <span class="c1"># do some unrelated work in the producer stream</span>
        <span class="n">do_other_producer_work</span><span class="p">()</span>

    <span class="k">with</span> <span class="n">wp</span><span class="o">.</span><span class="n">ScopedStream</span><span class="p">(</span><span class="n">consumer_stream</span><span class="p">)</span>
        <span class="c1"># do some unrelated work in the consumer stream</span>
        <span class="n">do_other_consumer_work</span><span class="p">()</span>

        <span class="c1"># wait for the producer copy to complete</span>
        <span class="n">wp</span><span class="o">.</span><span class="n">wait_event</span><span class="p">(</span><span class="n">event</span><span class="p">)</span>

        <span class="c1"># consume the array in a kernel</span>
        <span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">a</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">])</span>
</pre></div>
</div>
<p>The function <code class="xref py py-func docutils literal notranslate"><span class="pre">wp.synchronize_event()</span></code> can be used to block the host thread until a recorded event completes.  This is useful when the host wants to wait for a specific synchronization point on a stream, while allowing subsequent stream operations to continue executing asynchronously.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">wp</span><span class="o">.</span><span class="n">ScopedDevice</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">):</span>
    <span class="c1"># CPU buffers for readback</span>
    <span class="n">a_host</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">pinned</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">b_host</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">pinned</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">with</span> <span class="n">wp</span><span class="o">.</span><span class="n">ScopedDevice</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">):</span>
    <span class="n">stream</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">get_stream</span><span class="p">()</span>

    <span class="c1"># initialize first GPU array</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="c1"># asynchronous readback</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">a_host</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
    <span class="c1"># record event</span>
    <span class="n">a_event</span> <span class="o">=</span> <span class="n">stream</span><span class="o">.</span><span class="n">record_event</span><span class="p">()</span>

    <span class="c1"># initialize second GPU array</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">42</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="c1"># asynchronous readback</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">b_host</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="c1"># record event</span>
    <span class="n">b_event</span> <span class="o">=</span> <span class="n">stream</span><span class="o">.</span><span class="n">record_event</span><span class="p">()</span>

    <span class="c1"># wait for first array readback to complete</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">synchronize_event</span><span class="p">(</span><span class="n">a_event</span><span class="p">)</span>
    <span class="c1"># process first array on the CPU</span>
    <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">a_host</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="mf">17.0</span><span class="p">))</span>

    <span class="c1"># wait for second array readback to complete</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">synchronize_event</span><span class="p">(</span><span class="n">b_event</span><span class="p">)</span>
    <span class="c1"># process second array on the CPU</span>
    <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">b_host</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="mf">42.0</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="cuda-default-stream">
<h3>CUDA Default Stream<a class="headerlink" href="#cuda-default-stream" title="Link to this heading">#</a></h3>
<p>Warp avoids using the synchronous CUDA default stream, which is a special stream that synchronizes with all other streams
on the same device.  This stream is currently only used during readback operations that are provided for convenience, such as <code class="docutils literal notranslate"><span class="pre">array.numpy()</span></code> and <code class="docutils literal notranslate"><span class="pre">array.list()</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">stream1</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Stream</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
<span class="n">stream2</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Stream</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">wp</span><span class="o">.</span><span class="n">ScopedStream</span><span class="p">(</span><span class="n">stream1</span><span class="p">):</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>

<span class="k">with</span> <span class="n">wp</span><span class="o">.</span><span class="n">ScopedStream</span><span class="p">(</span><span class="n">stream2</span><span class="p">):</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
<p>In the snippet above, there are two arrays that are initialized on different CUDA streams.  Printing those arrays triggers
a readback, which is done using the <code class="docutils literal notranslate"><span class="pre">array.numpy()</span></code> method.  This readback happens on the synchronous CUDA default stream,
which means that no explicit synchronization is required.  The reason for this is convenience - printing an array is useful
for debugging purposes, so it’s nice not to worry about synchronization.</p>
<p>The drawback of this approach is that the CUDA default stream (and any methods that use it) cannot be used during graph capture.
The regular <a class="reference internal" href="runtime.html#warp.copy" title="warp.copy"><code class="xref py py-func docutils literal notranslate"><span class="pre">wp.copy()</span></code></a> function should be used to capture readback operations in a graph.</p>
</section>
<section id="explicit-streams-arguments">
<h3>Explicit Streams Arguments<a class="headerlink" href="#explicit-streams-arguments" title="Link to this heading">#</a></h3>
<p>Several Warp functions accept optional <code class="docutils literal notranslate"><span class="pre">stream</span></code> arguments.  This allows directly specifying the stream without
using a <code class="xref py py-class docutils literal notranslate"><span class="pre">wp.ScopedStream</span></code> manager.  There are benefits and drawbacks to both approaches, which will be discussed below.
Functions that accept stream arguments directly include <a class="reference internal" href="runtime.html#warp.launch" title="warp.launch"><code class="xref py py-func docutils literal notranslate"><span class="pre">wp.launch()</span></code></a>, <a class="reference internal" href="runtime.html#warp.capture_launch" title="warp.capture_launch"><code class="xref py py-func docutils literal notranslate"><span class="pre">wp.capture_launch()</span></code></a>, and <a class="reference internal" href="runtime.html#warp.copy" title="warp.copy"><code class="xref py py-func docutils literal notranslate"><span class="pre">wp.copy()</span></code></a>.</p>
<p>To launch a kernel on a specific stream:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="o">...</span><span class="p">],</span> <span class="n">stream</span><span class="o">=</span><span class="n">my_stream</span><span class="p">)</span>
</pre></div>
</div>
<p>When launching a kernel with an explicit <code class="docutils literal notranslate"><span class="pre">stream</span></code> argument, the <code class="docutils literal notranslate"><span class="pre">device</span></code> argument should be omitted, since the device is inferred
from the stream.  If both <code class="docutils literal notranslate"><span class="pre">stream</span></code> and <code class="docutils literal notranslate"><span class="pre">device</span></code> are specified, the <code class="docutils literal notranslate"><span class="pre">stream</span></code> argument takes precedence.</p>
<p>To launch a graph on a specific stream:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">wp</span><span class="o">.</span><span class="n">capture_launch</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="n">my_stream</span><span class="p">)</span>
</pre></div>
</div>
<p>For both kernel and graph launches, specifying the stream directly can be faster than using <code class="xref py py-class docutils literal notranslate"><span class="pre">wp.ScopedStream</span></code>.
While <code class="xref py py-class docutils literal notranslate"><span class="pre">wp.ScopedStream</span></code> is useful for scheduling a sequence of operations on a specific stream, there is some overhead
in setting and restoring the current stream on the device.  This overhead is negligible for larger workloads,
but performance-sensitive code may benefit from specifying the stream directly instead of using <code class="xref py py-class docutils literal notranslate"><span class="pre">wp.ScopedStream</span></code>, especially
for a single kernel or graph launch.</p>
<p>In addition to these performance considerations, specifying the stream directly can be useful when copying arrays between
two CUDA devices.  By default, Warp uses the following rules to determine which stream will be used for the copy:</p>
<ul class="simple">
<li><p>If the destination array is on a CUDA device, use the current stream on the destination device.</p></li>
<li><p>Otherwise, if the source array is on a CUDA device, use the current stream on the source device.</p></li>
</ul>
<p>In the case of peer-to-peer copies, specifying the <code class="docutils literal notranslate"><span class="pre">stream</span></code> argument allows overriding these rules, and the copy can
be performed on a stream from any device.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">stream0</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">get_stream</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
<span class="n">stream1</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">get_stream</span><span class="p">(</span><span class="s2">&quot;cuda:1&quot;</span><span class="p">)</span>

<span class="n">a0</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
<span class="n">a1</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:1&quot;</span><span class="p">)</span>

<span class="c1"># wait for the destination array to be ready</span>
<span class="n">stream0</span><span class="o">.</span><span class="n">wait_stream</span><span class="p">(</span><span class="n">stream1</span><span class="p">)</span>

<span class="c1"># use the source device stream to do the copy</span>
<span class="n">wp</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">a1</span><span class="p">,</span> <span class="n">a0</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="n">stream0</span><span class="p">)</span>
</pre></div>
</div>
<p>Notice that we use event synchronization to make the source stream wait for the destination stream prior to the copy.
This is due to the <a class="reference internal" href="allocators.html#mempool-allocators"><span class="std std-ref">stream-ordered memory pool allocators</span></a> introduced in Warp 0.14.0.  The allocation of the
empty array <code class="docutils literal notranslate"><span class="pre">a1</span></code> is scheduled on stream <code class="docutils literal notranslate"><span class="pre">stream1</span></code>.  To avoid use-before-alloc errors, we need to wait until the
allocation completes before using that array on a different stream.</p>
</section>
<section id="stream-usage-guidance">
<h3>Stream Usage Guidance<a class="headerlink" href="#stream-usage-guidance" title="Link to this heading">#</a></h3>
<p>Stream synchronization can be a tricky business, even for experienced CUDA developers.  Consider the following code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>

<span class="n">s</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Stream</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>

<span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">a</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">],</span> <span class="n">stream</span><span class="o">=</span><span class="n">s</span><span class="p">)</span>
</pre></div>
</div>
<p>This snippet has a stream synchronization problem that is difficult to detect at first glance.
It’s quite possible that the code will work just fine, but it introduces undefined behaviour,
which may lead to incorrect results that manifest only once in a while.  The issue is that the kernel is launched
on stream <code class="docutils literal notranslate"><span class="pre">s</span></code>, which is different than the stream used for creating array <code class="docutils literal notranslate"><span class="pre">a</span></code>.  The array is allocated and
initialized on the current stream of device <code class="docutils literal notranslate"><span class="pre">cuda:0</span></code>, which means that it might not be ready when stream <code class="docutils literal notranslate"><span class="pre">s</span></code>
begins executing the kernel that consumes the array.</p>
<p>The solution is to synchronize the streams, which can be done like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>

<span class="n">s</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Stream</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>

<span class="c1"># wait for the current stream on cuda:0 to finish initializing the array</span>
<span class="n">s</span><span class="o">.</span><span class="n">wait_stream</span><span class="p">(</span><span class="n">wp</span><span class="o">.</span><span class="n">get_stream</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">))</span>

<span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">a</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">],</span> <span class="n">stream</span><span class="o">=</span><span class="n">s</span><span class="p">)</span>
</pre></div>
</div>
<p>The <code class="xref py py-class docutils literal notranslate"><span class="pre">wp.ScopedStream</span></code> manager is designed to alleviate this common problem.  It synchronizes the new stream with the
previous stream on the device.  Its behavior is equivalent to inserting the <code class="docutils literal notranslate"><span class="pre">wait_stream()</span></code> call as shown above.
With <code class="xref py py-class docutils literal notranslate"><span class="pre">wp.ScopedStream</span></code>, we don’t need to explicitly sync the new stream with the previous stream:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>

<span class="n">s</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Stream</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">wp</span><span class="o">.</span><span class="n">ScopedStream</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">a</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">])</span>
</pre></div>
</div>
<p>This makes <code class="xref py py-class docutils literal notranslate"><span class="pre">wp.ScopedStream</span></code> the recommended way of getting started with streams in Warp.  Using explicit stream arguments
might be slightly more performant, but it requires more attention to stream synchronization mechanics.
If you are a stream novice, consider the following trajectory for integrating streams into your Warp programs:</p>
<ul class="simple">
<li><p>Level 1:  Don’t.  You don’t need to use streams to use Warp.  Avoiding streams is a perfectly valid and respectable way to live.  Many interesting and sophisticated algorithms can be developed without fancy stream juggling.  Often it’s better to focus on solving a problem in a simple and elegant way, unencumbered by the vagaries of low-level stream management.</p></li>
<li><p>Level 2:  Use <code class="xref py py-class docutils literal notranslate"><span class="pre">wp.ScopedStream</span></code>.  It helps to avoid some common hard-to-catch issues.  There’s a little bit of overhead, but it should be negligible if the GPU workloads are large enough.  Consider adding streams into your program as a form of targeted optimization, especially if some areas like memory transfers (“feeding the beast”) are a known bottleneck.  Streams are great for overlapping memory transfers with compute workloads.</p></li>
<li><p>Level 3:  Use explicit stream arguments for kernel launches, array copying, etc.  This will be the most performant approach that can get you close to the speed of light.  You will need to take care of all stream synchronization yourself, but the results can be rewarding in the benchmarks.</p></li>
</ul>
</section>
</section>
<section id="synchronization-guidance">
<span id="id2"></span><h2>Synchronization Guidance<a class="headerlink" href="#synchronization-guidance" title="Link to this heading">#</a></h2>
<p>The general rule with synchronization is to use as little of it as possible, but not less.</p>
<p>Excessive synchronization can severely limit the performance of programs.  Synchronization means that a stream or thread
is waiting for something else to complete.  While it’s waiting, it’s not doing any useful work, which means that any
outstanding work cannot start until the synchronization point is reached.  This limits parallel execution, which is
often important for squeezing the most juice out of the collection of hardware components.</p>
<p>On the other hand, insufficient synchronization can lead to errors or incorrect results if operations execute out-of-order.
A fast program is no good if it can’t guarantee correct results.</p>
<section id="host-side-synchronization">
<h3>Host-side Synchronization<a class="headerlink" href="#host-side-synchronization" title="Link to this heading">#</a></h3>
<p>Host-side synchronization blocks the host thread (Python) until GPU work completes.  This is necessary when
you are waiting for some GPU work to complete so that you can access the results on the CPU.</p>
<p><code class="xref py py-func docutils literal notranslate"><span class="pre">wp.synchronize()</span></code> is the most heavy-handed synchronization function, since it synchronizes all the devices in the system.  It is almost never the right function to call if performance is important.  However, it can sometimes be useful when debugging synchronization-related issues.</p>
<p><code class="xref py py-func docutils literal notranslate"><span class="pre">wp.synchronize_device(device)</span></code> synchronizes a single device, which is generally better and faster.  This synchronizes all the streams on the specified device, including streams created by Warp and those created by any other framework.</p>
<p><code class="xref py py-func docutils literal notranslate"><span class="pre">wp.synchronize_stream(stream)</span></code> synchronizes a single stream, which is better still.  If the program uses multiple streams, you can wait for a specific one to finish without waiting for the others.  This is handy if you have a readback stream that is copying data from the GPU to the CPU.  You can wait for the transfer to complete and start processing it on the CPU while other streams are still chugging along on the GPU, in parallel with the host code.</p>
<p><code class="xref py py-func docutils literal notranslate"><span class="pre">wp.synchronize_event(event)</span></code> is the most specific host synchronization function.  It blocks the host until an event previously recorded on a CUDA stream completes.  This can be used to wait for a specific stream synchronization point to be reached, while allowing subsequent operations on that stream to continue asynchronously.</p>
</section>
<section id="device-side-synchronization">
<h3>Device-side Synchronization<a class="headerlink" href="#device-side-synchronization" title="Link to this heading">#</a></h3>
<p>Device-side synchronization uses CUDA events to make one stream wait for a synchronization point recorded on another stream (<code class="xref py py-func docutils literal notranslate"><span class="pre">wp.record_event()</span></code>, <code class="xref py py-func docutils literal notranslate"><span class="pre">wp.wait_event()</span></code>, <code class="xref py py-func docutils literal notranslate"><span class="pre">wp.wait_stream()</span></code>).</p>
<p>These functions don’t block the host thread, so the CPU can stay busy doing useful work, like preparing the next batch of data
to feed the beast.  Events can be used to synchronize streams on the same device or even different CUDA devices, so you can
choreograph very sophisticated multi-stream and multi-device workloads that execute entirely on the available GPUs.
This allows keeping host-side synchronization to a minimum, perhaps only when reading back the final results.</p>
</section>
<section id="synchronization-and-graph-capture">
<h3>Synchronization and Graph Capture<a class="headerlink" href="#synchronization-and-graph-capture" title="Link to this heading">#</a></h3>
<p>A CUDA graph captures a sequence of operations on a CUDA stream that can be replayed multiple times with low overhead.
During capture, certain CUDA functions are not allowed, which includes host-side synchronization functions.  Using the synchronous
CUDA default stream is also not allowed.  The only form of synchronization allowed in CUDA graphs is event-based synchronization.</p>
<p>A CUDA graph capture must start and end on the same stream, but multiple streams can be used in the middle.  This allows CUDA graphs to encompass multiple streams and even multiple GPUs.  Events play a crucial role with multi-stream graph capture because they are used to fork and join new streams to the main capture stream, in addition to their regular synchronization duties.</p>
<p>Here’s an example of capturing a multi-GPU graph using a stream on each device:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">stream0</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Stream</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
<span class="n">stream1</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">Stream</span><span class="p">(</span><span class="s2">&quot;cuda:1&quot;</span><span class="p">)</span>

<span class="c1"># use stream0 as the main capture stream</span>
<span class="k">with</span> <span class="n">wp</span><span class="o">.</span><span class="n">ScopedCapture</span><span class="p">(</span><span class="n">stream</span><span class="o">=</span><span class="n">stream0</span><span class="p">)</span> <span class="k">as</span> <span class="n">capture</span><span class="p">:</span>

    <span class="c1"># fork stream1, which adds it to the set of streams being captured</span>
    <span class="n">stream1</span><span class="o">.</span><span class="n">wait_stream</span><span class="p">(</span><span class="n">stream0</span><span class="p">)</span>

    <span class="c1"># launch a kernel on stream0</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="n">stream0</span><span class="p">)</span>

    <span class="c1"># launch a kernel on stream1</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="n">stream1</span><span class="p">)</span>

    <span class="c1"># join stream1</span>
    <span class="n">stream0</span><span class="o">.</span><span class="n">wait_stream</span><span class="p">(</span><span class="n">stream1</span><span class="p">)</span>

<span class="c1"># launch the multi-GPU graph, which can execute the captured kernels concurrently</span>
<span class="n">wp</span><span class="o">.</span><span class="n">capture_launch</span><span class="p">(</span><span class="n">capture</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="generics.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Generics</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="allocators.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Allocators</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2022-2024, NVIDIA
            </div>
            Made with 
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              <a class="muted-link " href="https://github.com/NVIDIA/warp" aria-label="GitHub">
            <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16">
                <path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path>
            </svg>
        </a>
              
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Concurrency</a><ul>
<li><a class="reference internal" href="#asynchronous-operations">Asynchronous Operations</a><ul>
<li><a class="reference internal" href="#kernel-launches">Kernel Launches</a></li>
<li><a class="reference internal" href="#graph-launches">Graph Launches</a></li>
<li><a class="reference internal" href="#array-creation">Array Creation</a></li>
<li><a class="reference internal" href="#array-copying">Array Copying</a></li>
</ul>
</li>
<li><a class="reference internal" href="#streams">Streams</a><ul>
<li><a class="reference internal" href="#creating-streams">Creating Streams</a></li>
<li><a class="reference internal" href="#using-streams">Using Streams</a></li>
<li><a class="reference internal" href="#synchronization">Synchronization</a></li>
<li><a class="reference internal" href="#events">Events</a></li>
<li><a class="reference internal" href="#cuda-default-stream">CUDA Default Stream</a></li>
<li><a class="reference internal" href="#explicit-streams-arguments">Explicit Streams Arguments</a></li>
<li><a class="reference internal" href="#stream-usage-guidance">Stream Usage Guidance</a></li>
</ul>
</li>
<li><a class="reference internal" href="#synchronization-guidance">Synchronization Guidance</a><ul>
<li><a class="reference internal" href="#host-side-synchronization">Host-side Synchronization</a></li>
<li><a class="reference internal" href="#device-side-synchronization">Device-side Synchronization</a></li>
<li><a class="reference internal" href="#synchronization-and-graph-capture">Synchronization and Graph Capture</a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=1ed6394b"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=32e29ea5"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=fd10adb8"></script>
    </body>
</html>