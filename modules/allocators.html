<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Concurrency" href="concurrency.html" /><link rel="prev" title="Devices" href="devices.html" />

    <!-- Generated with Sphinx 7.2.6 and Furo 2024.01.29 -->
        <title>Allocators - Warp 1.0.2</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=135e06be" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=36a5483c" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=a91381f3" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  --admonition-title-font-size: 100%;
  --admonition-font-size: 100%;
  --color-api-pre-name: #4e9a06;
  --color-api-name: #4e9a06;
  --color-admonition-title--seealso: #ffffff;
  --color-admonition-title-background--seealso: #448aff;
  --color-admonition-title-background--note: #76b900;
  --color-admonition-title--note: #ffffff;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-admonition-title-background--note: #535353;
  --color-admonition-title--note: #ffffff;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-admonition-title-background--note: #535353;
  --color-admonition-title--note: #ffffff;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">Warp 1.0.2</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo only-light" src="../_static/logo-light-mode.png" alt="Light Logo"/>
    <img class="sidebar-logo only-dark" src="../_static/logo-dark-mode.png" alt="Dark Logo"/>
  </div>
  
  <span class="sidebar-brand-text">Warp 1.0.2</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">User's Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basics.html">Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="devices.html">Devices</a></li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">Allocators</a></li>
<li class="toctree-l1"><a class="reference internal" href="concurrency.html">Concurrency</a></li>
<li class="toctree-l1"><a class="reference internal" href="generics.html">Generics</a></li>
<li class="toctree-l1"><a class="reference internal" href="interoperability.html">Interoperability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../configuration.html">Runtime Settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../debugging.html">Debugging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../limitations.html">Limitations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Core Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="runtime.html">Runtime Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="functions.html">Kernel Reference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Simulation Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="sim.html">warp.sim</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse.html">warp.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="fem.html">warp.fem</a></li>
<li class="toctree-l1"><a class="reference internal" href="render.html">warp.render</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Project Links</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/NVIDIA/warp">GitHub</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pypi.org/project/warp-lang">PyPI</a></li>
<li class="toctree-l1"><a class="reference external" href="https://discord.com/channels/827959428476174346/953756751977648148">Discord</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="allocators">
<h1>Allocators<a class="headerlink" href="#allocators" title="Link to this heading">#</a></h1>
<section id="stream-ordered-memory-pool-allocators">
<span id="mempool-allocators"></span><h2>Stream-Ordered Memory Pool Allocators<a class="headerlink" href="#stream-ordered-memory-pool-allocators" title="Link to this heading">#</a></h2>
<section id="introduction">
<h3>Introduction<a class="headerlink" href="#introduction" title="Link to this heading">#</a></h3>
<p>Warp 0.14.0 added support for <a class="reference external" href="https://developer.nvidia.com/blog/using-cuda-stream-ordered-memory-allocator-part-1">stream-ordered memory pool allocators for CUDA arrays</a>.  As of Warp 0.15.0, these allocators are enabled by default on
all CUDA devices that support them.  “Stream-ordered memory pool allocator” is quite a mouthful, so let’s unpack it one bit at a time.</p>
<p>Whenever you create an array, the memory needs to be allocated on the device:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mf">42.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Each of the calls above allocates a block of device memory large enough to hold the array and optionally initializes the contents with
the specified values.  <code class="docutils literal notranslate"><span class="pre">wp.empty()</span></code> is the only function that does not initialize the contents in any way, it just allocates the memory.</p>
<p>Memory pool allocators grab a block of memory from a larger pool of reserved memory, which is generally faster than asking
the operating system for a brand new chunk of storage.  This is an important benefit of these pooled allocators - they are faster.</p>
<p>Stream-ordered means that each allocation is scheduled on a <a class="reference internal" href="concurrency.html#streams"><span class="std std-ref">CUDA stream</span></a>, which represents a sequence of instructions that execute in order on the GPU.  The main benefit is that it allows memory to be allocated in CUDA graphs, which was previously not possible:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">wp</span><span class="o">.</span><span class="n">ScopedCapture</span><span class="p">()</span> <span class="k">as</span> <span class="n">capture</span><span class="p">:</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">a</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">])</span>

<span class="n">wp</span><span class="o">.</span><span class="n">capture_launch</span><span class="p">(</span><span class="n">capture</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
</pre></div>
</div>
<p>From now on, we will refer to these allocators as mempool allocators, for short.</p>
</section>
<section id="configuration">
<h3>Configuration<a class="headerlink" href="#configuration" title="Link to this heading">#</a></h3>
<p>Mempool allocators are a feature of CUDA that is supported on most modern devices and operating systems.  However,
there can be systems where they are not supported, such as certain virtual machine setups.  Warp is designed with resiliency in mind,
so existing code written prior to the introduction of these new allocators should continue to function regardless of whether they
are supported by the underlying system or not.</p>
<p>Warp’s startup message gives the status of these allocators, for example:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Warp 0.15.1 initialized:
CUDA Toolkit 11.5, Driver 12.2
Devices:
    &quot;cpu&quot;      : &quot;x86_64&quot;
    &quot;cuda:0&quot;   : &quot;NVIDIA GeForce RTX 4090&quot; (24 GiB, sm_89, mempool enabled)
    &quot;cuda:1&quot;   : &quot;NVIDIA GeForce RTX 3090&quot; (24 GiB, sm_86, mempool enabled)
</pre></div>
</div>
<p>Note the <code class="docutils literal notranslate"><span class="pre">mempool</span> <span class="pre">enabled</span></code> text next to each CUDA device.  This means that memory pools are enabled on the device.  Whenever you create
an array on that device, it will be allocated using the mempool allocator.  If you see <code class="docutils literal notranslate"><span class="pre">mempool</span> <span class="pre">supported</span></code>, it means that memory
pools are supported but were not enabled on startup.  If you see <code class="docutils literal notranslate"><span class="pre">mempool</span> <span class="pre">not</span> <span class="pre">supported</span></code>, it means that memory pools can’t be used
on this device.</p>
<p>There is a configuration flag that controls whether memory pools should be automatically enabled during <code class="docutils literal notranslate"><span class="pre">wp.init()</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warp</span> <span class="k">as</span> <span class="nn">wp</span>

<span class="n">wp</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">enable_mempools_at_init</span> <span class="o">=</span> <span class="kc">False</span>

<span class="n">wp</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
</pre></div>
</div>
<p>The flag defaults to <code class="docutils literal notranslate"><span class="pre">True</span></code>, but can be set to <code class="docutils literal notranslate"><span class="pre">False</span></code> if desired.  Changing this configuration flag after <code class="docutils literal notranslate"><span class="pre">wp.init()</span></code> is called has no effect.</p>
<p>After <code class="docutils literal notranslate"><span class="pre">wp.init()</span></code>, you can check if the memory pool is enabled on each device like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">wp</span><span class="o">.</span><span class="n">is_mempool_enabled</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">):</span>
    <span class="o">...</span>
</pre></div>
</div>
<p>You can also independently control enablement on each device:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">wp</span><span class="o">.</span><span class="n">is_mempool_supported</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">):</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">set_mempool_enabled</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>It’s possible to temporarily enable or disable memory pools using a scoped manager:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">wp</span><span class="o">.</span><span class="n">ScopedMempool</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">wp</span><span class="o">.</span><span class="n">ScopedMempool</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>In the snippet above, array <code class="docutils literal notranslate"><span class="pre">a</span></code> will be allocated using the mempool allocator and array <code class="docutils literal notranslate"><span class="pre">b</span></code> will be allocated using the default allocator.</p>
<p>In most cases, it shouldn’t be necessary to fiddle with these enablement functions, but they are there if you need them.
By default, Warp will enable memory pools on startup if they are supported, which will bring the benefits of improved allocation speed automatically.
Most Warp code should continue to function with or without mempool allocators, with the exception of memory allocations
during graph capture, which will raise an exception if memory pools are not enabled.</p>
<dl class="py function">
<dt class="sig sig-object py" id="warp.is_mempool_supported">
<span class="sig-prename descclassname"><span class="pre">warp.</span></span><span class="sig-name descname"><span class="pre">is_mempool_supported</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.is_mempool_supported" title="Link to this definition">#</a></dt>
<dd><p>Check if CUDA memory pool allocators are available on the device.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>device</strong> (<a class="reference internal" href="devices.html#warp.context.Device" title="warp.context.Device"><em>Device</em></a><em> | </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em> | </em><em>None</em>) – </p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="warp.is_mempool_enabled">
<span class="sig-prename descclassname"><span class="pre">warp.</span></span><span class="sig-name descname"><span class="pre">is_mempool_enabled</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.is_mempool_enabled" title="Link to this definition">#</a></dt>
<dd><p>Check if CUDA memory pool allocators are enabled on the device.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>device</strong> (<a class="reference internal" href="devices.html#warp.context.Device" title="warp.context.Device"><em>Device</em></a><em> | </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em> | </em><em>None</em>) – </p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="warp.set_mempool_enabled">
<span class="sig-prename descclassname"><span class="pre">warp.</span></span><span class="sig-name descname"><span class="pre">set_mempool_enabled</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.set_mempool_enabled" title="Link to this definition">#</a></dt>
<dd><p>Enable or disable CUDA memory pool allocators on the device.</p>
<p>Pooled allocators are typically faster and allow allocating memory during graph capture.</p>
<p>They should generally be enabled, but there is a rare caveat.  Copying data between different GPUs
may fail during graph capture if the memory was allocated using pooled allocators and memory pool
access is not enabled between the two GPUs.  This is an internal CUDA limitation that is not related
to Warp.  The preferred solution is to enable memory pool access using <cite>warp.set_mempool_access_enabled()</cite>.
If peer access is not supported, then the default CUDA allocators must be used to pre-allocate the memory
prior to graph capture.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<a class="reference internal" href="devices.html#warp.context.Device" title="warp.context.Device"><em>Device</em></a><em> | </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em> | </em><em>None</em>) – </p></li>
<li><p><strong>enable</strong> (<a class="reference internal" href="functions.html#warp.bool" title="warp.bool"><em>bool</em></a>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="allocation-performance">
<h3>Allocation Performance<a class="headerlink" href="#allocation-performance" title="Link to this heading">#</a></h3>
<p>Allocating and releasing memory are rather expensive operations that can add overhead to a program.  We can’t avoid them, since we need to allocate storage for our data somewhere, but there are some simple strategies that can reduce the overall impact of allocations on performance.</p>
<p>Consider the following example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">a</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>On each iteration of the loop, we allocate an array and run a kernel on the data.  This program has 100 allocations and 100 deallocations.  When we assign a new value to <code class="docutils literal notranslate"><span class="pre">a</span></code>, the previous value gets garbage collected by Python, which triggers the deallocation.</p>
<section id="reusing-memory">
<h4>Reusing Memory<a class="headerlink" href="#reusing-memory" title="Link to this heading">#</a></h4>
<p>If the size of the array remains fixed, consider reusing the memory on subsequent iterations.  We can allocate the array only once and just re-initialize its contents on each iteration:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># pre-allocate the array</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="c1"># reset the contents</span>
    <span class="n">a</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">a</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>This works well if the array size does not change on each iteration.  If the size changes but the upper bound is known, we can still pre-allocate a buffer large enough to store all the elements at any iteration.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># pre-allocate a big enough buffer</span>
<span class="n">buffer</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">MAX_N</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="c1"># get a buffer slice of size n &lt;= MAX_N</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">get_size</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">buffer</span><span class="p">[:</span><span class="n">n</span><span class="p">]</span>
    <span class="c1"># reset the contents</span>
    <span class="n">a</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">a</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Reusing memory this way can improve performance, but may also add undesirable complexity to our code.  The mempool allocators have a useful feature that can improve allocation performance without modifying our original code in any way.</p>
</section>
<section id="release-threshold">
<h4>Release Threshold<a class="headerlink" href="#release-threshold" title="Link to this heading">#</a></h4>
<p>The memory pool release threshold determines how much reserved memory the allocator should hold on to before releasing it back to the operating system.  For programs that frequenty allocate and release memory, setting a higher release threshold can improve the performance of allocations.</p>
<p>By default, the release threshold is set to 0.  Setting it to a higher number will reduce the cost of allocations if memory was previously acquired and returned to the pool.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># set the release threshold to reduce re-allocation overhead</span>
<span class="n">wp</span><span class="o">.</span><span class="n">set_mempool_release_threshold</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">,</span> <span class="mi">1024</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">a</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">a</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Threshold values between 0 and 1 are interpreted as fractions of available memory.  For example, 0.5 means half of the device’s physical memory and 1.0 means all of the memory.  Greater values are interpreted as an absolute number of bytes.  For example, 1024**3 means one GiB of memory.</p>
<p>This is a simple optimization that can improve the performance of programs without modifying the existing code in any way.</p>
<dl class="py function">
<dt class="sig sig-object py" id="warp.set_mempool_release_threshold">
<span class="sig-prename descclassname"><span class="pre">warp.</span></span><span class="sig-name descname"><span class="pre">set_mempool_release_threshold</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.set_mempool_release_threshold" title="Link to this definition">#</a></dt>
<dd><p>Set the CUDA memory pool release threshold on the device.</p>
<p>This is the amount of reserved memory to hold onto before trying to release memory back to the OS.
When more than this amount of bytes is held by the memory pool, the allocator will try to release
memory back to the OS on the next call to stream, event, or device synchronize.</p>
<p>Values between 0 and 1 are interpreted as fractions of available memory.  For example, 0.5 means
half of the device’s physical memory.  Greater values are interpreted as an absolute number of bytes.
For example, 1024**3 means one GiB of memory.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<a class="reference internal" href="devices.html#warp.context.Device" title="warp.context.Device"><em>Device</em></a><em> | </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em> | </em><em>None</em>) – </p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em> | </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
</section>
<section id="graph-allocations">
<h3>Graph Allocations<a class="headerlink" href="#graph-allocations" title="Link to this heading">#</a></h3>
<p>Mempool allocators can be used in CUDA graphs, which means that you can capture Warp code that creates arrays:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">wp</span><span class="o">.</span><span class="n">ScopedCapture</span><span class="p">()</span> <span class="k">as</span> <span class="n">capture</span><span class="p">:</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">42</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>

<span class="n">wp</span><span class="o">.</span><span class="n">capture_launch</span><span class="p">(</span><span class="n">capture</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
</pre></div>
</div>
<p>Capturing allocations is similar to capturing other operations like kernel launches or memory copies.  During capture, the operations don’t actually execute, but are recorded.  To execute the captured operations, we must launch the graph using <code class="xref py py-func docutils literal notranslate"><span class="pre">wp.capture_launch()</span></code>.  This is important to keep in mind if you want to use an array that was allocated during graph capture.  The array doesn’t actually exist until the captured graph is launched.  In the snippet above, we would get an error if we tried to print the array before calling <code class="xref py py-func docutils literal notranslate"><span class="pre">wp.capture_launch()</span></code>.</p>
<p>More generally, the ability to allocate memory during graph capture greatly increases the range of code that can be captured in a graph.  This includes any code that creates temporary allocations.  CUDA graphs can be used to re-run operations with minimal CPU overhead, which can yield dramatic performance improvements.</p>
</section>
<section id="memory-pool-access">
<span id="mempool-access"></span><h3>Memory Pool Access<a class="headerlink" href="#memory-pool-access" title="Link to this heading">#</a></h3>
<p>On multi-GPU systems that support <a class="reference internal" href="devices.html#peer-access"><span class="std std-ref">peer access</span></a>, we can enable directly accessing a memory pool from a different device:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">wp</span><span class="o">.</span><span class="n">is_mempool_access_supported</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">,</span> <span class="s2">&quot;cuda:1&quot;</span><span class="p">):</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">set_mempool_access_enabled</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">,</span> <span class="s2">&quot;cuda:1&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
</pre></div>
</div>
<p>This will allow the memory pool of device <code class="docutils literal notranslate"><span class="pre">cuda:0</span></code> to be directly accessed on device <code class="docutils literal notranslate"><span class="pre">cuda:1</span></code>.  Memory pool access is directional, which means that enabling access to <code class="docutils literal notranslate"><span class="pre">cuda:0</span></code> from <code class="docutils literal notranslate"><span class="pre">cuda:1</span></code> does not automatically enable access to <code class="docutils literal notranslate"><span class="pre">cuda:1</span></code> from <code class="docutils literal notranslate"><span class="pre">cuda:0</span></code>.</p>
<p>The benefit of enabling memory pool access is that it allows direct memory transfers (DMA) between the devices.  This is generally a faster way to copy data, since otherwise the transfer needs to be done using a CPU staging buffer.</p>
<p>The drawback is that enabling memory pool access can slightly reduce the performance of allocations and deallocations.  However, for applications that rely on copying memory between devices, there should be a net benefit.</p>
<p>It’s possible to temporarily enable or disable memory pool access using a scoped manager:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">wp</span><span class="o">.</span><span class="n">ScopedMempoolAccess</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">,</span> <span class="s2">&quot;cuda:1&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
    <span class="n">a0</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
    <span class="n">a1</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:1&quot;</span><span class="p">)</span>

    <span class="c1"># use direct memory transfer between GPUs</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">a1</span><span class="p">,</span> <span class="n">a0</span><span class="p">)</span>
</pre></div>
</div>
<p>Note that memory pool access only applies to memory allocated using mempool allocators.  For memory allocated using default CUDA allocators, we can enable CUDA peer access to get similar benefits.</p>
<p>Because enabling memory pool access can have drawbacks, Warp does not automatically enable it, even if it’s supported.  Programs that don’t require copying data between GPUs are therefore not affected in any way.</p>
<dl class="py function">
<dt class="sig sig-object py" id="warp.is_mempool_access_supported">
<span class="sig-prename descclassname"><span class="pre">warp.</span></span><span class="sig-name descname"><span class="pre">is_mempool_access_supported</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">peer_device</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.is_mempool_access_supported" title="Link to this definition">#</a></dt>
<dd><p>Check if <cite>peer_device</cite> can directly access the memory pool of <cite>target_device</cite>.</p>
<p>If mempool access is possible, it can be managed using <cite>set_mempool_access_enabled()</cite> and <cite>is_mempool_access_enabled()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A Boolean value indicating if this memory pool access is supported by the system.</p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>target_device</strong> (<a class="reference internal" href="devices.html#warp.context.Device" title="warp.context.Device"><em>Device</em></a><em> | </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em> | </em><em>None</em>) – </p></li>
<li><p><strong>peer_device</strong> (<a class="reference internal" href="devices.html#warp.context.Device" title="warp.context.Device"><em>Device</em></a><em> | </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em> | </em><em>None</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="warp.is_mempool_access_enabled">
<span class="sig-prename descclassname"><span class="pre">warp.</span></span><span class="sig-name descname"><span class="pre">is_mempool_access_enabled</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">peer_device</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.is_mempool_access_enabled" title="Link to this definition">#</a></dt>
<dd><p>Check if <cite>peer_device</cite> can currently access the memory pool of <cite>target_device</cite>.</p>
<p>This applies to memory allocated using CUDA pooled allocators.  For memory allocated using
default CUDA allocators, use <cite>is_peer_access_enabled()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A Boolean value indicating if this peer access is currently enabled.</p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>target_device</strong> (<a class="reference internal" href="devices.html#warp.context.Device" title="warp.context.Device"><em>Device</em></a><em> | </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em> | </em><em>None</em>) – </p></li>
<li><p><strong>peer_device</strong> (<a class="reference internal" href="devices.html#warp.context.Device" title="warp.context.Device"><em>Device</em></a><em> | </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em> | </em><em>None</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="warp.set_mempool_access_enabled">
<span class="sig-prename descclassname"><span class="pre">warp.</span></span><span class="sig-name descname"><span class="pre">set_mempool_access_enabled</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">peer_device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#warp.set_mempool_access_enabled" title="Link to this definition">#</a></dt>
<dd><p>Enable or disable access from <cite>peer_device</cite> to the memory pool of <cite>target_device</cite>.</p>
<p>This applies to memory allocated using CUDA pooled allocators.  For memory allocated using
default CUDA allocators, use <cite>set_peer_access_enabled()</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target_device</strong> (<a class="reference internal" href="devices.html#warp.context.Device" title="warp.context.Device"><em>Device</em></a><em> | </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em> | </em><em>None</em>) – </p></li>
<li><p><strong>peer_device</strong> (<a class="reference internal" href="devices.html#warp.context.Device" title="warp.context.Device"><em>Device</em></a><em> | </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em> | </em><em>None</em>) – </p></li>
<li><p><strong>enable</strong> (<a class="reference internal" href="functions.html#warp.bool" title="warp.bool"><em>bool</em></a>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="limitations">
<h3>Limitations<a class="headerlink" href="#limitations" title="Link to this heading">#</a></h3>
<section id="mempool-to-mempool-copies-between-gpus-during-graph-capture">
<h4>Mempool-to-Mempool Copies Between GPUs During Graph Capture<a class="headerlink" href="#mempool-to-mempool-copies-between-gpus-during-graph-capture" title="Link to this heading">#</a></h4>
<p>Copying data between different GPUs will fail during graph capture if the source and destination are allocated using mempool allocators and mempool access is not enabled between devices.  Note that this only applies to capturing mempool-to-mempool copies in a graph; copies done outside of graph capture are not affected.  Copies within the same mempool (i.e., same device) are also not affected.</p>
<p>There are two workarounds.  If mempool access is supported, you can simply enable mempool access between the devices prior to graph capture, as shown in <a class="reference internal" href="#mempool-access"><span class="std std-ref">Memory Pool Access</span></a>.</p>
<p>If mempool access is not supported, you will need to pre-allocate the arrays involved in the copy using the default CUDA allocators.  This will need to be done before capture begins:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># pre-allocate the arrays with mempools disabled</span>
<span class="k">with</span> <span class="n">wp</span><span class="o">.</span><span class="n">ScopedMempool</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
    <span class="n">a0</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>
<span class="k">with</span> <span class="n">wp</span><span class="o">.</span><span class="n">ScopedMempool</span><span class="p">(</span><span class="s2">&quot;cuda:1&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
    <span class="n">a1</span> <span class="o">=</span> <span class="n">wp</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:1&quot;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">wp</span><span class="o">.</span><span class="n">ScopedCapture</span><span class="p">(</span><span class="s2">&quot;cuda:1&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">capture</span><span class="p">:</span>
    <span class="n">wp</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">a1</span><span class="p">,</span> <span class="n">a0</span><span class="p">)</span>

<span class="n">wp</span><span class="o">.</span><span class="n">capture_launch</span><span class="p">(</span><span class="n">capture</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
</pre></div>
</div>
<p>This is due to a limitation in CUDA, which we envision being fixed in the future.</p>
</section>
</section>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="concurrency.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Concurrency</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="devices.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Devices</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2022-2024, NVIDIA
            </div>
            Made with 
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              <a class="muted-link " href="https://github.com/NVIDIA/warp" aria-label="GitHub">
            <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16">
                <path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path>
            </svg>
        </a>
              
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Allocators</a><ul>
<li><a class="reference internal" href="#stream-ordered-memory-pool-allocators">Stream-Ordered Memory Pool Allocators</a><ul>
<li><a class="reference internal" href="#introduction">Introduction</a></li>
<li><a class="reference internal" href="#configuration">Configuration</a><ul>
<li><a class="reference internal" href="#warp.is_mempool_supported"><code class="docutils literal notranslate"><span class="pre">is_mempool_supported()</span></code></a></li>
<li><a class="reference internal" href="#warp.is_mempool_enabled"><code class="docutils literal notranslate"><span class="pre">is_mempool_enabled()</span></code></a></li>
<li><a class="reference internal" href="#warp.set_mempool_enabled"><code class="docutils literal notranslate"><span class="pre">set_mempool_enabled()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#allocation-performance">Allocation Performance</a><ul>
<li><a class="reference internal" href="#reusing-memory">Reusing Memory</a></li>
<li><a class="reference internal" href="#release-threshold">Release Threshold</a><ul>
<li><a class="reference internal" href="#warp.set_mempool_release_threshold"><code class="docutils literal notranslate"><span class="pre">set_mempool_release_threshold()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#graph-allocations">Graph Allocations</a></li>
<li><a class="reference internal" href="#memory-pool-access">Memory Pool Access</a><ul>
<li><a class="reference internal" href="#warp.is_mempool_access_supported"><code class="docutils literal notranslate"><span class="pre">is_mempool_access_supported()</span></code></a></li>
<li><a class="reference internal" href="#warp.is_mempool_access_enabled"><code class="docutils literal notranslate"><span class="pre">is_mempool_access_enabled()</span></code></a></li>
<li><a class="reference internal" href="#warp.set_mempool_access_enabled"><code class="docutils literal notranslate"><span class="pre">set_mempool_access_enabled()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#limitations">Limitations</a><ul>
<li><a class="reference internal" href="#mempool-to-mempool-copies-between-gpus-during-graph-capture">Mempool-to-Mempool Copies Between GPUs During Graph Capture</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=1ed6394b"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=32e29ea5"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=fd10adb8"></script>
    </body>
</html>